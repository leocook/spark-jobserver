/*
 Navicat Premium Data Transfer

 Source Server         : 52.131.218.110
 Source Server Type    : MySQL
 Source Server Version : 50651
 Source Host           : 52.131.218.110:3306
 Source Schema         : superior

 Target Server Type    : MySQL
 Target Server Version : 50651
 File Encoding         : 65001

 Date: 18/10/2022 18:01:35
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for meta_cluster_compute
-- ----------------------------
DROP TABLE IF EXISTS `meta_cluster_compute`;
CREATE TABLE `meta_cluster_compute` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `code` varchar(64) COLLATE utf8_bin NOT NULL COMMENT 'code',
  `name` varchar(128) COLLATE utf8_bin NOT NULL COMMENT 'name',
  `storage_code` varchar(64) COLLATE utf8_bin NOT NULL COMMENT 'storage_code',
  `jobs` varchar(256) COLLATE utf8_bin DEFAULT NULL COMMENT '可运行作业类型，多选，逗号分割',
  `compute_type` varchar(45) COLLATE utf8_bin DEFAULT 'spark' COMMENT '集群类型：spark & flink',
  `scheduler_type` varchar(45) COLLATE utf8_bin DEFAULT 'YARN' COMMENT '调度框架:YARN、K8S',
  `cluster_type` varchar(45) COLLATE utf8_bin DEFAULT NULL COMMENT '集群类型：batch、stream、datax',
  `compute_version` varchar(45) COLLATE utf8_bin DEFAULT NULL COMMENT 'flink 或者spark 版本',
  `jobserver_config` longtext COLLATE utf8_bin COMMENT 'common config',
  `spark_config` longtext COLLATE utf8_bin COMMENT 'spark config',
  `thriftserver_config` longtext COLLATE utf8_bin COMMENT 'spark config',
  `yarn_config` longtext COLLATE utf8_bin COMMENT 'yarn-site配置',
  `mapred_config` longtext COLLATE utf8_bin COMMENT 'mapreduce 配置',
  `k8s_config` longtext COLLATE utf8_bin COMMENT 'k8s_config',
  `default_cluster` smallint(6) DEFAULT '0' COMMENT '默认集群，0：否，1：是',
  `status` smallint(6) DEFAULT '1' COMMENT '0：无效，1：有效',
  `thrift_server_count` int(11) NOT NULL DEFAULT '2' COMMENT '启动thrift server 数量',
  `thrift_server_enabled` smallint(6) DEFAULT '0' COMMENT '是否启动thrift server, 1: 启动',
  `creater` varchar(45) COLLATE utf8_bin NOT NULL COMMENT 'creater',
  `modifier` varchar(45) COLLATE utf8_bin DEFAULT NULL COMMENT 'modifier',
  `gmt_created` datetime NOT NULL COMMENT 'gmt_create',
  `gmt_modified` datetime DEFAULT NULL COMMENT 'gmt_modify',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `code_UNIQUE` (`code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='计算集群管理';

-- ----------------------------
-- Records of meta_cluster_compute
-- ----------------------------
BEGIN;
INSERT INTO `meta_cluster_compute` VALUES (5, 1, 'hangzhou-spark-3.2', 'Spark-3.2集群', 'hangzhou-hdfs-cdh', 'spark_sql,spark_jar,spark_python', 'spark', 'yarn', 'batch', '3.2', 'jobserver.spark.home = /mnt/spark-3.3.0-bin-3.0.0-cdh6.3.1\r\njobserver.driver.home = /user/superior/jobserver\r\njobserver.driver.jar.name = spark-jobserver-driver-3.3.0.jar\r\njobserver.driver.datatunnel.jars.dir = datatunnel-3.3.0\r\njobserver.spark.versionn = 3.3.0\r\n\r\njobserver.python.home = /mnt/anaconda3/bin/python\r\njobserver.pyspark.path= /mnt/pyspark/3.3.0/pyspark.zip:/mnt/pyspark/3.3.0/py4j-0.10.9.5-src.zip\r\n\r\njobserver.kerberos.user = admin/admin@DZTECH.COM\r\njobserver.driver.hadoop.user.name=hdfs\r\n\r\n#dataworker 地址\r\njobserver.parquet.write.users = huaixin;\r\njobserver.superadmin = huaixin\r\n\r\njobserver.insert.values.max.count = 100\r\n\r\n#资源约束\r\njobserver.restrict.executor.memory=10g\r\njobserver.restrict.driver.memory=10g\r\njobserver.restrict.dev.executor.memory=10g\r\njobserver.restrict.dev.driver.memory=10g\r\njobserver.restrict.driver.cores=2\r\n\r\n# shuffle 最大写入量，单位T\r\njobserver.shuffle.write.max.value = 10\r\n\r\n#自定义spark参数\r\nspark.datawork.column.authorization.enabled = true\r\n\r\njobserver.concurrent.submit.max.num = 1\r\njobserver.idle.max.time.second = 1800\r\njobserver.min.driver.enabled= true\r\njobserver.min.driver.count = 1\r\njobserver.max.driver.count = 1\r\njobserver.driver.run.max.instance.count = 100\r\njobserver.yarn.min.memory.mb = 4096\r\njobserver.yarn.min.cpu.cores = 3\r\n\r\njobserver.git.url = http://10.1.20.102\r\n\r\nhoodie.datasource.write.hive_style_partitioning = true\r\nhoodie.datasource.write.payload.class = org.apache.hudi.common.model.DefaultHoodieRecordPayload\r\n#hoodie.datasource.hive_sync.mode = HMS\r\n#hoodie.datasource.hive_sync.sync_comment = false\r\n#hoodie.datasource.hive_sync.create_managed_table = true\r\n\r\n\r\n# 下面两个配置只能放在这里\r\n#spark.executor.extraJavaOptions = -XX:+UseCompressedOops -Dlog4j.configuration=log4j.xml -Dfile.encoding=UTF-8\r\n#spark.driver.extraJavaOptions = -XX:MaxMetaspaceSize=512m -XX:+UseCompressedOops -Dfile.encoding=UTF-8\r\n\r\n#end', 'spark.serializer = org.apache.spark.serializer.KryoSerializer\r\nspark.ui.killEnabled = false\r\nspark.sql.legacy.setCommandRejectsSparkCoreConfs = false\r\nspark.streaming.sink.console.dataworker.enabled = true\r\n\r\nspark.sql.ansi.enabled = false\r\nspark.sql.streaming.metricsEnabled = true\r\nspark.hadoop.hoodie.metadata.enable = true\r\n\r\nspark.eventLog.enabled = true\r\n\r\n\r\n#spark调度参数\r\nspark.submit.tasks.threshold.enabled = false\r\nspark.submit.tasks.threshold = 10000\r\nspark.updatejar.enabled = true\r\nspark.locality.wait = 0s\r\n\r\nspark.eventLog.logStageExecutorMetrics.enabled = true\r\nspark.eventLog.logStageExecutorProcessTreeMetrics.enabled = true\r\n\r\n# hudi\r\nspark.sql.extensions = com.github.melin.superior.jobserver.extensions.SuperiorSparkExtensions,com.superior.datatunnel.core.DataTunnelExtensions,org.apache.spark.sql.hudi.HoodieSparkSessionExtension\r\nspark.sql.catalog.spark_catalog = org.apache.spark.sql.hudi.catalog.HoodieCatalog\r\n\r\n#spark执行参数\r\nspark.default.parallelism = 200\r\nspark.files.useFetchCache = true\r\nspark.files.overwrite =  true\r\nspark.files.maxPartitionBytes = 134217728\r\nspark.kryoserializer.buffer.max = 256m\r\nspark.kryoserializer.buffer = 128k\r\nspark.excludeOnFailure.enabled = true\r\nspark.master = yarn\r\n\r\n#memory\r\nspark.executor.memory = 2g\r\n#spark.executor.memoryOverhead = 1g\r\nspark.driver.memory = 1g\r\nspark.driver.memoryOverhead = 1g\r\nspark.python.worker.memory = 1g\r\nspark.memory.fraction = 0.6\r\nspark.memory.storageFraction = 0.4\r\nspark.executor.cores = 3\r\nspark.driver.cores = 1\r\n\r\n#sparksql参数\r\nspark.sql.shuffle.partitions = 100\r\nspark.sql.parquet.compression.codec =  zstd\r\nspark.sql.parquet.mergeSchema = false\r\nspark.hadoop.hive.exec.max.dynamic.partitions = 5000\r\nspark.shuffle.registration.timeout = 2000\r\nspark.sql.autoBroadcastJoinThreshold = 10485760\r\nspark.hadoop.ipc.client.fallback-to-simple-auth-allowed = true\r\n\r\nspark.sql.adaptive.enabled = true\r\nspark.sql.adaptive.forceApply=false\r\nspark.sql.adaptive.logLevel=info\r\nspark.sql.adaptive.coalescePartitions.enabled = true\r\nspark.sql.adaptive.advisoryPartitionSizeInBytes=256m\r\nspark.sql.adaptive.coalescePartitions.minPartitionSize=1\r\nspark.sql.adaptive.coalescePartitions.initialPartitionNum=2048\r\nspark.sql.adaptive.fetchShuffleBlocksInBatch=true\r\nspark.sql.adaptive.localShuffleReader.enabled=true\r\nspark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.2\r\n\r\nspark.sql.adaptive.skewJoin.enabled=true\r\nspark.sql.adaptive.skewJoin.skewedPartitionFactor=5\r\nspark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=256M\r\nspark.sql.adaptive.advisoryPartitionSizeInBytes=64M\r\nspark.sql.autoBroadcastJoinThreshold = -1\r\nspark.sql.broadcastTimeout=600s\r\n\r\nspark.sql.execution.arrow.pyspark.enabled=true\r\nspark.sql.execution.arrow.pyspark.fallback.enabled=true\r\n\r\n#spark动态分配参数\r\nspark.shuffle.service.enabled = false\r\nspark.dynamicAllocation.enabled = true\r\nspark.dynamicAllocation.shuffleTracking.enabled =	true\r\nspark.shuffle.service.port        =          7337\r\nspark.dynamicAllocation.initialExecutors = 1\r\nspark.dynamicAllocation.minExecutors = 1\r\nspark.dynamicAllocation.maxExecutors = 2\r\nspark.sql.sources.parallelPartitionDiscovery.parallelism = 60\r\nspark.dynamicAllocation.executorIdleTimeout = 600s\r\nspark.dynamicAllocation.cachedExecutorIdleTimeout = 1800s\r\n\r\nspark.sql.legacy.charVarcharAsString = true\r\nspark.sql.charAsVarchar=true\r\n\r\n#----------------\r\n\r\nspark.port.maxRetries = 50\r\nspark.locality.wait = 0s\r\n\r\nspark.network.timeout        =   600s\r\nspark.yarn.am.waitTime       =   600s\r\nspark.rpc.message.maxSize    =   200\r\n\r\nspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version = 2\r\nspark.hadoop.fs.hdfs.impl.disable.cache = true\r\n\r\n# shuffle \r\nspark.network.maxRemoteBlockSizeFetchToMem = 100m\r\nspark.shuffle.io.maxRetries   = 6\r\nspark.shuffle.io.retryWait    = 10s\r\nspark.debug.maxToStringFields = 600\r\n\r\nspark.executor.extraJavaOptions = -XX:+UseCompressedOops -Dlog4j.configuration=log4j.xml -Dfile.encoding=UTF-8\r\nspark.driver.extraJavaOptions = -XX:MaxMetaspaceSize=512m -XX:+UseCompressedOops -Dfile.encoding=UTF-8\r\n\r\n#end', 'spark.master = yarn\r\nspark.driver.memory = 1g\r\nspark.driver.cores = 1\r\nspark.executor.cores = 1\r\n\r\nspark.dynamicAllocation.enabled = true\r\nspark.shuffle.service.enabled = true\r\nspark.dynamicAllocation.minExecutors = 0\r\nspark.dynamicAllocation.initialExecutors = 0\r\nspark.dynamicAllocation.maxExecutors = 1\r\n\r\n\r\nspark.sql.extensions = com.github.melin.superior.jobserver.extensions.SuperiorSparkExtensions,com.superior.datatunnel.core.DataTunnelExtensions,org.apache.spark.sql.hudi.HoodieSparkSessionExtension\r\nspark.sql.catalog.spark_catalog = org.apache.spark.sql.hudi.catalog.HoodieCatalog', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<!--Autogenerated by Cloudera Manager-->\n<configuration>\n  <property>\n    <name>yarn.acl.enable</name>\n    <value>true</value>\n  </property>\n  <property>\n    <name>yarn.admin.acl</name>\n    <value>*</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.address</name>\n    <value>cneutascrdvm10:8032</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.admin.address</name>\n    <value>cneutascrdvm10:8033</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.address</name>\n    <value>cneutascrdvm10:8030</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.resource-tracker.address</name>\n    <value>cneutascrdvm10:8031</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.webapp.address</name>\n    <value>cneutascrdvm10:8088</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.webapp.https.address</name>\n    <value>cneutascrdvm10:8090</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.client.thread-count</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.client.thread-count</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.admin.client.thread-count</name>\n    <value>1</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.minimum-allocation-mb</name>\n    <value>1024</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.increment-allocation-mb</name>\n    <value>512</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.maximum-allocation-mb</name>\n    <value>5949</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.minimum-allocation-vcores</name>\n    <value>1</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.increment-allocation-vcores</name>\n    <value>1</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.maximum-allocation-vcores</name>\n    <value>4</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.amliveliness-monitor.interval-ms</name>\n    <value>1000</value>\n  </property>\n  <property>\n    <name>yarn.am.liveness-monitor.expiry-interval-ms</name>\n    <value>600000</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.am.max-attempts</name>\n    <value>2</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.container.liveness-monitor.interval-ms</name>\n    <value>600000</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.nm.liveness-monitor.interval-ms</name>\n    <value>1000</value>\n  </property>\n  <property>\n    <name>yarn.nm.liveness-monitor.expiry-interval-ms</name>\n    <value>600000</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.resource-tracker.client.thread-count</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.application.classpath</name>\n    <value>$HADOOP_CLIENT_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.class</name>\n    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.resource-calculator</name>\n    <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.max-completed-applications</name>\n    <value>10000</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>/tmp/logs</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir-suffix</name>\n    <value>logs</value>\n  </property>\n</configuration>', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<!--Autogenerated by Cloudera Manager-->\n<configuration>\n    <property>\n        <name>mapreduce.framework.name</name>\n        <value>yarn</value>\n    </property>\n    \n    <property>\n        <name>yarn.resourcemanager.principal</name>\n        <value>yarn/_HOST@DZTECH.COM</value>\n    </property>\n\n</configuration>', '', 1, 1, 1, 1, '千潇#qianxiao', '不玄#buxuan', '2021-08-30 09:45:18', '2022-10-11 20:39:29');
INSERT INTO `meta_cluster_compute` VALUES (6, 1, 'spark3.2-stream-cluster', 'Spark-3.2流计算集群', 'hangzhou-hdfs-cdh', 'spark_stream_sql,spark_stream_jar,spark_stream_python', 'spark', 'yarn', 'stream', '3.2', 'jobserver.spark.home = /mnt/spark-3.3.0-bin-3.0.0-cdh6.3.1\r\njobserver.driver.home = /user/superior/jobserver\r\njobserver.driver.jar.name = spark-jobserver-driver-3.3.0.jar\r\njobserver.driver.datatunnel.jars.dir = datatunnel-3.3.0\r\njobserver.spark.version=3.3.0\r\n\r\njobserver.python.home=/mnt/anaconda3/bin/python\r\njobserver.pyspark.path=/mnt/pyspark/3.3.0/pyspark.zip:/mnt/pyspark/3.3.0/py4j-0.10.9.5-src.zip:/mnt/pyspark/3.3.0/graphframes-0.8.2.zip\r\n\r\njobserver.kerberos.user = admin/admin@DZTECH.COM\r\njobserver.driver.hadoop.user.name=hdfs\r\n\r\n#dataworker 地址\r\njobserver.parquet.write.users = huaixin;\r\njobserver.superadmin = huaixin\r\n\r\njobserver.insert.values.max.count = 100\r\n\r\n#资源约束\r\njobserver.restrict.executor.memory=10g\r\njobserver.restrict.driver.memory=10g\r\njobserver.restrict.dev.executor.memory=10g\r\njobserver.restrict.dev.driver.memory=10g\r\njobserver.restrict.driver.cores=2\r\n\r\n# shuffle 最大写入量，单位T\r\njobserver.shuffle.write.max.value = 60\r\n\r\n#自定义spark参数\r\nspark.datawork.column.authorization.enabled = true\r\n\r\n#集群提交限制 ts\r\njobserver.concurrent.submit.max.num = 2\r\njobserver.idle.max.time.second = 1800\r\njobserver.driver.min.count = 0\r\njobserver.driver.max.count = 5\r\njobserver.driver.max.idle.time.seconds = 300\r\njobserver.yarn.min.memory.mb = 4096\r\njobserver.yarn.min.cpu.cores = 5\r\n\r\nhoodie.datasource.write.hive_style_partitioning = true\r\nhoodie.datasource.write.payload.class = org.apache.hudi.common.model.DefaultHoodieRecordPayload\r\nhoodie.datasource.hive_sync.mode = HMS\r\nhoodie.datasource.hive_sync.sync_comment = false\r\nhoodie.datasource.hive_sync.create_managed_table = true\r\n\r\n\r\n# 下面两个配置只能放在这里\r\nspark.executor.extraJavaOptions = -XX:+UseCompressedOops -Dlog4j.configuration=log4j.xml -Dfile.encoding=UTF-8\r\nspark.driver.extraJavaOptions = -XX:MaxMetaspaceSize=512m -XX:+UseCompressedOops -Dfile.encoding=UTF-8\r\n\r\n#end', 'spark.serializer = org.apache.spark.serializer.KryoSerializer\nspark.ui.killEnabled = false\nspark.sql.legacy.setCommandRejectsSparkCoreConfs = false\nspark.streaming.sink.console.dataworker.enabled = true\n\nspark.eventLog.enabled = true\n\nspark.sql.streaming.metricsEnabled = true\nspark.sql.ansi.enabled = false\nspark.merge.small.file.enabled = true\n\n#spark调度参数\nspark.shuffle.service.enabled = false\nspark.submit.tasks.threshold.enabled = false\nspark.submit.tasks.threshold = 10000\nspark.updatejar.enabled = true\nspark.locality.wait = 0s\n\nspark.eventLog.logStageExecutorMetrics.enabled = true\nspark.eventLog.logStageExecutorProcessTreeMetrics.enabled = true\n\n#spark.sql.extensions = org.apache.spark.sql.hudi.HoodieSparkSessionExtension\n#spark.sql.catalog.spark_catalog = org.apache.spark.sql.hudi.catalog.HoodieCatalog\n\n#spark执行参数\nspark.default.parallelism = 200\nspark.files.useFetchCache = true\nspark.files.overwrite  true\nspark.files.maxPartitionBytes = 134217728\nspark.kryoserializer.buffer.max = 256m\nspark.kryoserializer.buffer = 128k\nspark.files.overwrite = true\nspark.excludeOnFailure.enabled = true\nspark.master = yarn\n\nspark.sql.execution.arrow.pyspark.enabled=true\nspark.sql.execution.arrow.pyspark.fallback.enabled=true\n\n#memory\nspark.executor.memory = 1g\nspark.driver.memory = 1g\nspark.python.worker.memory = 1g\nspark.memory.fraction = 0.6\nspark.memory.storageFraction = 0.4\nspark.executor.cores = 2\nspark.driver.cores = 2\n\n#sparksql参数\nspark.sql.files.maxPartitionBytes = 256m\nspark.io.compression.codec = zstd\nspark.sql.shuffle.partitions = 100\nspark.sql.parquet.compression.codec = zstd\nspark.sql.parquet.mergeSchema = false\nspark.hadoop.hive.exec.max.dynamic.partitions = 5000\nspark.hadoop.orc.overwrite.output.file = true\nspark.shuffle.registration.timeout = 2000\n\nspark.sql.legacy.charVarcharAsString = true\nspark.sql.charAsVarchar=true\n\nspark.sql.orc.compression.codec = snappy\nspark.sql.sources.parallelPartitionDiscovery.parallelism = 189\n\n#----------------\n\nspark.port.maxRetries = 50\nspark.locality.wait = 0s\nspark.network.timeout = 300s\nspark.rpc.message.maxSize = 200\n\nspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version = 2\nspark.hadoop.fs.hdfs.impl.disable.cache = true\n\n# shuffle \nspark.network.maxRemoteBlockSizeFetchToMem = 100m\nspark.shuffle.io.maxRetries = 6\nspark.shuffle.io.retryWait = 10s\nspark.debug.maxToStringFields = 600\n\n#end', 'spark.master yarn\r\nspark.driver.memory  6g\r\nspark.driver.cores  1\r\nspark.executor.cores 1\r\n\r\nspark.dynamicAllocation.enabled  true\r\nspark.shuffle.service.enabled  true\r\nspark.dynamicAllocation.minExecutors  0\r\nspark.dynamicAllocation.initialExecutors  0\r\nspark.dynamicAllocation.maxExecutors  1', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<!--Autogenerated by Cloudera Manager-->\n<configuration>\n  <property>\n    <name>yarn.acl.enable</name>\n    <value>true</value>\n  </property>\n  <property>\n    <name>yarn.admin.acl</name>\n    <value>*</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.address</name>\n    <value>cneutascrdvm10:8032</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.admin.address</name>\n    <value>cneutascrdvm10:8033</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.address</name>\n    <value>cneutascrdvm10:8030</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.resource-tracker.address</name>\n    <value>cneutascrdvm10:8031</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.webapp.address</name>\n    <value>cneutascrdvm10:8088</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.webapp.https.address</name>\n    <value>cneutascrdvm10:8090</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.client.thread-count</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.client.thread-count</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.admin.client.thread-count</name>\n    <value>1</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.minimum-allocation-mb</name>\n    <value>1024</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.increment-allocation-mb</name>\n    <value>512</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.maximum-allocation-mb</name>\n    <value>5949</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.minimum-allocation-vcores</name>\n    <value>1</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.increment-allocation-vcores</name>\n    <value>1</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.maximum-allocation-vcores</name>\n    <value>4</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.amliveliness-monitor.interval-ms</name>\n    <value>1000</value>\n  </property>\n  <property>\n    <name>yarn.am.liveness-monitor.expiry-interval-ms</name>\n    <value>600000</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.am.max-attempts</name>\n    <value>2</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.container.liveness-monitor.interval-ms</name>\n    <value>600000</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.nm.liveness-monitor.interval-ms</name>\n    <value>1000</value>\n  </property>\n  <property>\n    <name>yarn.nm.liveness-monitor.expiry-interval-ms</name>\n    <value>600000</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.resource-tracker.client.thread-count</name>\n    <value>50</value>\n  </property>\n  <property>\n    <name>yarn.application.classpath</name>\n    <value>$HADOOP_CLIENT_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.scheduler.class</name>\n    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>\n  </property>\n  <property>\n    <name>yarn.scheduler.capacity.resource-calculator</name>\n    <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>\n  </property>\n  <property>\n    <name>yarn.resourcemanager.max-completed-applications</name>\n    <value>10000</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir</name>\n    <value>/tmp/logs</value>\n  </property>\n  <property>\n    <name>yarn.nodemanager.remote-app-log-dir-suffix</name>\n    <value>logs</value>\n  </property>\n</configuration>', '', '', 0, 1, 2, 0, '千潇#qianxiao', '不玄#buxuan', '2021-09-14 22:19:52', '2022-10-11 20:39:38');
COMMIT;

-- ----------------------------
-- Table structure for meta_cluster_storage
-- ----------------------------
DROP TABLE IF EXISTS `meta_cluster_storage`;
CREATE TABLE `meta_cluster_storage` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `tenant_id` int(11) DEFAULT NULL,
  `code` varchar(64) COLLATE utf8_bin NOT NULL COMMENT 'code',
  `name` varchar(128) COLLATE utf8_bin NOT NULL COMMENT 'name',
  `storage_type` varchar(45) COLLATE utf8_bin DEFAULT 'HDFS' COMMENT '存储类型:HDFS、OBS、OSS、S3等文件系统',
  `kerberos_enabled` smallint(6) DEFAULT '0' COMMENT '是否启用kerberos 0：关闭，1：开启',
  `kerberos_keytab` longblob COMMENT 'kerberos keytab',
  `kerberos_file_name` varchar(255) COLLATE utf8_bin DEFAULT NULL,
  `kerberos_config` longtext COLLATE utf8_bin COMMENT 'kerberos conf',
  `kerberos_user` varchar(128) COLLATE utf8_bin DEFAULT NULL COMMENT 'kerberos用户',
  `kerberos_jdbc_user` varchar(128) COLLATE utf8_bin DEFAULT NULL COMMENT '连接thriftserver 账号',
  `core_config` longtext COLLATE utf8_bin COMMENT 'core-site配置',
  `hdfs_config` longtext COLLATE utf8_bin COMMENT 'hdfs-site配置',
  `hive_config` longtext COLLATE utf8_bin COMMENT 'hive-site配置',
  `mapred_config` longtext COLLATE utf8_bin COMMENT 'mapred_config',
  `storage_config` longtext COLLATE utf8_bin COMMENT '对象存储配置',
  `visual` smallint(6) NOT NULL DEFAULT '0' COMMENT '0：物理存储，1：虚拟存储',
  `status` smallint(6) DEFAULT '1' COMMENT '0：无效，1：有效',
  `creater` varchar(45) COLLATE utf8_bin NOT NULL COMMENT 'creater',
  `modifier` varchar(45) COLLATE utf8_bin DEFAULT NULL COMMENT 'modifier',
  `gmt_created` datetime NOT NULL COMMENT 'gmt_create',
  `gmt_modified` datetime DEFAULT NULL COMMENT 'gmt_modify',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `code_UNIQUE` (`code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='存储集群管理';

-- ----------------------------
-- Records of meta_cluster_storage
-- ----------------------------
BEGIN;
INSERT INTO `meta_cluster_storage` VALUES (1, 1, 'hangzhou-hdfs-cdh', '杭州CDH5.15集群', 'hdfs', 0, 0x05020000004D0002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C6020012002017E28CB2A5FF7F90DFB5AD2CC8D72FB445619E82EB8863EA787C977FB8AE630E000000020000003D0002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C60200110010067DEDC83AC0129FD004CE8173E7B72E00000002000000450002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C60200100018D57AAEC4BA94A1F7CDA40ECBF2AEF84C2A5DC1458C5BFB8F000000020000003D0002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C602001700104A9BC03AC9FDD998552D3B9FC33A5CB4000000020000004D0002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C602001A0020CA0B797A4F3062DC747887B3352E0B415AEA2268695D927A058D483E22BAB901000000020000003D0002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C60200190010DB60629B65D1FD8C4682D79721C738FD00000002000000350002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C60200080008DA15A731E5C2670D00000002000000350002000A445A544543482E434F4D000561646D696E000561646D696E0000000160DFC1C60200030008F791BC8073ABC4CE00000002, 'admin.keytab', '', 'admin/admin@DZTECH.COM', 'hive/_HOST@DZTECH.COM', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n\r\n<!--Autogenerated by Cloudera Manager-->\r\n<configuration>\r\n  <property>\r\n    <name>fs.defaultFS</name>\r\n    <value>hdfs://cneutascrdvm10:8020</value>\r\n  </property>\r\n  <property>\r\n    <name>fs.trash.interval</name>\r\n    <value>1</value>\r\n  </property>\r\n  <property>\r\n    <name>io.compression.codecs</name>\r\n    <value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.security.authentication</name>\r\n    <value>simple</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.security.authorization</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.rpc.protection</name>\r\n    <value>authentication</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.security.auth_to_local</name>\r\n    <value>DEFAULT</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.oozie.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.oozie.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.flume.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.flume.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.HTTP.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.HTTP.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.hive.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.hive.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.hue.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.hue.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.httpfs.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.httpfs.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.hdfs.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.hdfs.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.yarn.hosts</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.proxyuser.yarn.groups</name>\r\n    <value>*</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.security.group.mapping</name>\r\n    <value>org.apache.hadoop.security.ShellBasedUnixGroupsMapping</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.security.instrumentation.requires.admin</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>net.topology.script.file.name</name>\r\n    <value>/etc/hadoop/conf.cloudera.yarn/topology.py</value>\r\n  </property>\r\n  <property>\r\n    <name>io.file.buffer.size</name>\r\n    <value>65536</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.ssl.enabled</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.ssl.require.client.cert</name>\r\n    <value>false</value>\r\n    <final>true</final>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.ssl.keystores.factory.class</name>\r\n    <value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>\r\n    <final>true</final>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.ssl.server.conf</name>\r\n    <value>ssl-server.xml</value>\r\n    <final>true</final>\r\n  </property>\r\n  <property>\r\n    <name>hadoop.ssl.client.conf</name>\r\n    <value>ssl-client.xml</value>\r\n    <final>true</final>\r\n  </property>\r\n</configuration>', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n\r\n<!--Autogenerated by Cloudera Manager-->\r\n<configuration>\r\n  <property>\r\n    <name>dfs.namenode.name.dir</name>\r\n    <value>file:///mnt/resource/dfs/nn</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.namenode.servicerpc-address</name>\r\n    <value>cneutascrdvm10:8022</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.https.address</name>\r\n    <value>cneutascrdvm10:9871</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.https.port</name>\r\n    <value>9871</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.namenode.http-address</name>\r\n    <value>cneutascrdvm10:9870</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.replication</name>\r\n    <value>3</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.blocksize</name>\r\n    <value>134217728</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.client.use.datanode.hostname</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>fs.permissions.umask-mode</name>\r\n    <value>022</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.client.block.write.locateFollowingBlock.retries</name>\r\n    <value>7</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.namenode.acls.enabled</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.client.read.shortcircuit</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.domain.socket.path</name>\r\n    <value>/var/run/hdfs-sockets/dn</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.client.read.shortcircuit.skip.checksum</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.client.domain.socket.data.traffic</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>\r\n    <value>true</value>\r\n  </property>\r\n</configuration>', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n\r\n<!--Autogenerated by Cloudera Manager-->\r\n<configuration>\r\n  <property>\r\n    <name>hive.metastore.uris</name>\r\n    <value>thrift://cneutascrdvm10:9083</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.metastore.client.socket.timeout</name>\r\n    <value>300</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.metastore.warehouse.dir</name>\r\n    <value>/user/hive/warehouse</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.warehouse.subdir.inherit.perms</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.auto.convert.join</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.auto.convert.join.noconditionaltask.size</name>\r\n    <value>20971520</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.optimize.bucketmapjoin.sortedmerge</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.smbjoin.cache.rows</name>\r\n    <value>10000</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.server2.logging.operation.enabled</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.server2.logging.operation.log.location</name>\r\n    <value>/var/log/hive/operation_logs</value>\r\n  </property>\r\n  <property>\r\n    <name>mapred.reduce.tasks</name>\r\n    <value>-1</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.exec.reducers.bytes.per.reducer</name>\r\n    <value>67108864</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.exec.copyfile.maxsize</name>\r\n    <value>33554432</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.exec.reducers.max</name>\r\n    <value>1099</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.groupby.checkinterval</name>\r\n    <value>4096</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.groupby.flush.percent</name>\r\n    <value>0.1</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.compute.query.using.stats</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.execution.enabled</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.execution.reduce.enabled</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.use.vectorized.input.format</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.use.checked.expressions</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.use.vector.serde.deserialize</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.adaptor.usage.mode</name>\r\n    <value>chosen</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.vectorized.input.format.excludes</name>\r\n    <value>org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.merge.mapfiles</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.merge.mapredfiles</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.cbo.enable</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.fetch.task.conversion</name>\r\n    <value>minimal</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.fetch.task.conversion.threshold</name>\r\n    <value>268435456</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.limit.pushdown.memory.usage</name>\r\n    <value>0.1</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.merge.sparkfiles</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.merge.smallfiles.avgsize</name>\r\n    <value>16777216</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.merge.size.per.task</name>\r\n    <value>268435456</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.optimize.reducededuplication</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.optimize.reducededuplication.min.reducer</name>\r\n    <value>4</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.map.aggr</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.map.aggr.hash.percentmemory</name>\r\n    <value>0.5</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.optimize.sort.dynamic.partition</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.execution.engine</name>\r\n    <value>mr</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.executor.memory</name>\r\n    <value>912680550b</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.driver.memory</name>\r\n    <value>966367641b</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.executor.cores</name>\r\n    <value>4</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.yarn.driver.memoryOverhead</name>\r\n    <value>102m</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.yarn.executor.memoryOverhead</name>\r\n    <value>153m</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.dynamicAllocation.enabled</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.dynamicAllocation.initialExecutors</name>\r\n    <value>1</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.dynamicAllocation.minExecutors</name>\r\n    <value>1</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.dynamicAllocation.maxExecutors</name>\r\n    <value>2147483647</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.metastore.execute.setugi</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.support.concurrency</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.zookeeper.quorum</name>\r\n    <value>cneutascrdvm10,cneutascrdvm12,cneutascrdvm11</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.zookeeper.client.port</name>\r\n    <value>2181</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.zookeeper.namespace</name>\r\n    <value>hive_zookeeper_namespace_hive</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.cluster.delegation.token.store.class</name>\r\n    <value>org.apache.hadoop.hive.thrift.MemoryTokenStore</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.server2.enable.doAs</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.server2.use.SSL</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>spark.shuffle.service.enabled</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.strict.checks.orderby.no.limit</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.strict.checks.no.partition.filter</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.strict.checks.type.safety</name>\r\n    <value>true</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.strict.checks.cartesian.product</name>\r\n    <value>false</value>\r\n  </property>\r\n  <property>\r\n    <name>hive.strict.checks.bucketing</name>\r\n    <value>true</value>\r\n  </property>\r\n</configuration>', '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n\r\n<!--Autogenerated by Cloudera Manager-->\r\n<configuration>\r\n    <property>\r\n        <name>mapreduce.framework.name</name>\r\n        <value>yarn</value>\r\n    </property>\r\n    \r\n    <property>\r\n    <name>yarn.resourcemanager.principal</name>\r\n    <value>yarn/_HOST@DZTECH.COM</value>\r\n  </property>\r\n\r\n</configuration>', '', 0, 1, '管理员#amin', '不玄#buxuan', '2020-06-07 22:34:42', '2022-10-11 20:40:52');
COMMIT;

-- ----------------------------
-- Table structure for meta_config
-- ----------------------------
DROP TABLE IF EXISTS `meta_config`;
CREATE TABLE `meta_config` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `appname` varchar(64) NOT NULL,
  `profile` varchar(64) NOT NULL,
  `config_text` longtext,
  `version` int(11) DEFAULT '0' COMMENT 'version',
  `creater` varchar(45) NOT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `gmt_created` datetime NOT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `appname_UNIQUE` (`appname`,`profile`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=12 DEFAULT CHARSET=utf8mb4 COMMENT='系统参数配置';

-- ----------------------------
-- Records of meta_config
-- ----------------------------
BEGIN;
INSERT INTO `meta_config` VALUES (1, 'superior', 'dev', 'superior.super.administrators=huaixin\r\nsuperior.data.center = hangzhou\r\nsuperior.data.center.name = {hangzhou: \'杭州数据中心\'}\r\nsuperior.data.center.hive.database = {hangzhou: \'hive23\'}\r\n\r\nsuperior.data.warehouse.administrators=huaixin\r\n\r\n# resourcemanager + yarn.resourcemanager.webapp.address \r\nsuperior.data.center.yarn.urls = {hangzhou: \'http://10.5.20.10:8088\'} \r\nsuperior.data.center.yarn.proxy.urls = {hangzhou: \'http://10.5.20.10:8088\'}  \r\nsuperior.data.center.spark.jdbc.urls = {hangzhou: \'10.5.20.12:10000\'}\r\nsuperior.spark.jobserver.url = http://10.5.20.12:7002 \r\n\r\nsuperior.python.code.complete.enabled = true\r\nsuperior.python.code.complete.url = http://10.10.9.12:9110\r\n\r\nsuperior.gitlab.url=http://10.1.21.81:20011\r\n\r\nsuperior.export.data.enabled = true\r\nsuperior.stream.job.enabled = true\r\nsuperior.alert.msg.send.enabled = false\r\n\r\n# 数据交换配置 start =====================================================\r\ndatax.admin.users = admin\r\ndatax.replace.pipdata = true\r\ndatax.allow.mysql.to.hive = true\r\ndatax.yarn.queue =\r\n\r\n\r\n# 数据交换配置 end =====================================================', 111, '管理员#admin', '管理员#admin', '2017-06-26 13:40:16', '2022-07-31 19:48:45');
INSERT INTO `meta_config` VALUES (3, 'jobserver', 'dev', '# jobserver.driver 和 spark 前缀配置，在jobserver driver 中使用\r\n\r\njobserver.datacenter = hangzhou\r\n\r\njobserver.datawork.url = http://10.5.20.11:8181\r\n\r\njobserver.run.max.instance.count = 60\r\n\r\njobserver.min.job.server.id = 0\r\n\r\njobserver.hefei.submit.timeout = 600000\r\n\r\njobserver.spark.launcher.verbose=true\r\n\r\n//允许用户自定义的参数\r\njobserver.user.parameters = spark.serializer;\\\r\n    spark.sql.cbo.enabled;\\\r\n    spark.yarn.job.jars;\\\r\n    spark.yarn.dist.jars; \\\r\n    spark.executor.memory;\\\r\n    spark.driver.memory;\\\r\n    spark.driver.cores;\\\r\n    spark.yarn.driver.memoryOverhead;\\\r\n    spark.driver.memoryOverhead;\\\r\n    spark.yarn.executor.memoryOverhead;\\\r\n    spark.executor.memoryOverhead;\\\r\n    spark.memory.fraction;\\\r\n    spark.memory.storageFraction;\\\r\n    spark.job.driver.extraJavaOptions;\\\r\n    spark.job.executor.extraJavaOptions;\\\r\n    spark.memory.offHeap.enabled;\\\r\n    spark.memory.offHeap.size;\\\r\n    spark.memory.useLegacyMode;\\\r\n    spark.storage.memoryFraction;\\\r\n    spark.sql.autoBroadcastJoinThreshold;\\\r\n    spark.kryoserializer.buffer.max;\\\r\n    spark.kryo.classesToRegister;\\\r\n    spark.io.compression.codec;\\\r\n    spark.sql.parquet.mergeSchema;\\\r\n    spark.sql.execution.arrow.maxRecordsPerBatch;\\\r\n    spark.sql.parquet.columnarReaderBatchSize;\\\r\n    spark.sql.inMemoryColumnarStorage.batchSize;\\\r\n    spark.sql.tungsten.enabled;\\\r\n    spark.sql.parquet.enableVectorizedReader;\\\r\n    spark.ml.angel.enabled;spark.ps.cores;\\\r\n    spark.ps.instances;spark.ps.memory;\r\n    \r\n\r\njobserver.driver.extraJavaOptions = -XX:+UseG1GC -XX:+UseCompressedOops -Dfile.encoding=UTF-8\r\njobserver.executor.extraJavaOptions = -XX:+UseG1GC -Dlog4j.configuration=log4j.properties -Dfile.encoding=UTF-8 -XX:+UseCompressedOops\r\njobserver.superadmin = admin\r\njobserver.submit.waitresource.timeout = 3600000\r\n\r\njobserver.submit.memAvailable = 150000\r\n\r\njobserver.driver.sql.query.max.records = 1000\r\njobserver.driver.values.max.count = 3\r\n\r\n\r\n//end', 25, '管理员#admin', '管理员#admin', '2017-07-06 14:26:03', '2021-12-23 14:22:19');
INSERT INTO `meta_config` VALUES (5, 'dzlog', 'dev', 'dzlog.data.center.kafka.brokers = {hangzhou: \"10.5.20.16:9092,10.5.20.17:9092,10.5.20.18:9092\"}\ndzlog.data.center.kerberos.principal = {hangzhou: \"admin/admin@DZTECH.COM\"}\ndzlog.data.center.kerberos.hive.principal = {hangzhou: \"hive/_HOST@DZTECH.COM\"}\ndzlog.data.center.spark.jdbc.urls = {hangzhou: \'hadoop-test-nn2-9-12:10000\'}\n\n#end', 1, '管理员#admin', '管理员#admin', '2018-01-08 19:26:03', '2021-08-26 10:57:49');
INSERT INTO `meta_config` VALUES (7, 'superior', 'production', 'superior.super.administrators=huaixin,buxuan,suzhi,xuanwu\r\nsuperior.data.center = hangzhou\r\nsuperior.data.center.name = {hangzhou: \'杭州数据中心\'}\r\nsuperior.data.center.hive.database = {hangzhou: \'hive\'}\r\n\r\nsuperior.data.warehouse.administrators=huaixin\r\nsuperior.skip.table.auth.check.users=\r\n\r\nsuperior.hive.table.default.compression=snappy\r\n\r\nsuperior.allow.exec.job.min.score = 10\r\n\r\n\r\nsuperior.python.code.complete.enabled = false\r\nsuperior.python.code.complete.url = http://10.10.9.12:9110\r\n\r\nsuperior.gitlab.url=http://10.1.21.81:20011\r\n\r\nsuperior.export.data.enabled = true\r\nsuperior.stream.job.enabled = true\r\nsuperior.alert.msg.send.enabled = false\r\n\r\n# 数据交换配置 start =====================================================\r\ndatax.admin.users = admin\r\ndatax.replace.pipdata = true\r\ndatax.allow.mysql.to.hive = true\r\ndatax.yarn.queue =\r\n\r\n\r\n# 数据交换配置 end =====================================================', 401, '管理员#admin', '管理员#admin', '2018-09-12 09:25:02', '2022-09-10 19:24:00');
INSERT INTO `meta_config` VALUES (8, 'jobserver', 'production', 'jobserver.datacenter = hangzhou\r\n\r\njobserver.superior.url = http://10.0.2.104:8181\r\n\r\njobserver.yarn.location = /data/hadoop-3.3.1/bin/yarn\r\n\r\njobserver.run.max.instance.count = 100\r\n\r\njobserver.min.job.server.id = 0\r\n\r\njobserver.hangzhou.submit.timeout = 600000\r\n\r\njobserver.spark.launcher.verbose=false\r\n\r\njobserver.debug.driver.enabled=true\r\n\r\njobserver.allow.insert.hive.whitelist.jobs = \r\n\r\n//允许用户自定义的参数\r\njobserver.user.parameters = spark.serializer;\\\r\n    spark.sql.cbo.enabled;\\\r\n    spark.yarn.job.jars;\\\r\n    spark.yarn.dist.jars; \\\r\n    spark.executor.memory;\\\r\n    spark.driver.memory;\\\r\n    spark.driver.cores;\\\r\n    spark.yarn.driver.memoryOverhead;\\\r\n    spark.driver.memoryOverhead;\\\r\n    spark.yarn.executor.memoryOverhead;\\\r\n    spark.executor.memoryOverhead;\\\r\n    spark.memory.fraction;\\\r\n    spark.memory.storageFraction;\\\r\n    spark.job.driver.extraJavaOptions;\\\r\n    spark.job.executor.extraJavaOptions;\\\r\n    spark.memory.offHeap.enabled;\\\r\n    spark.memory.offHeap.size;\\\r\n    spark.memory.useLegacyMode;\\\r\n    spark.storage.memoryFraction;\\\r\n    spark.sql.autoBroadcastJoinThreshold;\\\r\n    spark.dynamicAllocation.maxExecutors;\\\r\n    spark.kryoserializer.buffer.max;\\\r\n    spark.kryo.classesToRegister;\\\r\n    spark.io.compression.codec;\\\r\n    spark.sql.parquet.mergeSchema;\\\r\n    spark.sql.execution.arrow.maxRecordsPerBatch;\\\r\n    spark.sql.parquet.columnarReaderBatchSize;\\\r\n    spark.sql.inMemoryColumnarStorage.batchSize;\\\r\n    spark.job.dev.failure.notify.enabled\r\n    \r\n    \r\n#允许自定义最大executo个数的作业\r\njobserver.dynamicAllocation.jobNames = \r\n\r\njobserver.driver.extraJavaOptions = -XX:+UseG1GC -XX:+UseCompressedOops -Dfile.encoding=UTF-8\r\njobserver.executor.extraJavaOptions = -XX:+UseG1GC -Dlog4j.configuration=log4j.properties -Dfile.encoding=UTF-8 -XX:+UseCompressedOops\r\njobserver.superadmin = admin\r\n\r\n# jobserver.driver. 前缀的参数上传递给jobserver-driver\r\n# 流作业插入hive表作业白名单\r\njobserver.driver.allow.insert.hive.whitelist.jobs = \r\njobserver.driver.sql.query.max.records = 1000\r\njobserver.driver.values.max.count = 3\r\n\r\n\r\n//end', 108, '管理员#admin', '管理员#admin', '2018-09-12 09:28:02', '2022-09-06 14:14:12');
INSERT INTO `meta_config` VALUES (11, 'dzlog', 'production', 'dzlog.data.center.kafka.brokers = {hangzhou: \"10.5.20.16:9092,10.5.20.17:9092,10.5.20.18:9092\"}\ndzlog.data.center.kerberos.principal = {hangzhou: \"admin/admin@DZTECH.COM\"}\ndzlog.data.center.kerberos.hive.principal = {hangzhou: \"hive/_HOST@DZTECH.COM\"}\ndzlog.data.center.spark.jdbc.urls = {hangzhou: \'10.5.20.12:10000\'}\n\n#end', 40, '管理员#admin', '管理员#admin', '2019-02-21 15:36:51', '2021-12-22 15:29:43');
COMMIT;

-- ----------------------------
-- Table structure for meta_datasource
-- ----------------------------
DROP TABLE IF EXISTS `meta_datasource`;
CREATE TABLE `meta_datasource` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `code` varchar(64) DEFAULT NULL COMMENT 'Code，随机字符8位长',
  `name` varchar(128) DEFAULT NULL COMMENT '数据源名称',
  `jdbc_type` varchar(45) DEFAULT NULL COMMENT 'mysql, db2, pg等',
  `user` varchar(45) DEFAULT NULL COMMENT '数据库账号',
  `password` varchar(45) DEFAULT NULL COMMENT '密码',
  `host_name` varchar(45) DEFAULT NULL COMMENT 'host',
  `port` int(11) DEFAULT NULL COMMENT '端口',
  `database_name` varchar(45) DEFAULT NULL COMMENT '数据库名',
  `connection_type` varchar(64) DEFAULT NULL COMMENT '链接类型',
  `description` varchar(512) DEFAULT NULL COMMENT '数据源描述',
  `config` varchar(4096) DEFAULT NULL COMMENT '数据源配置信息',
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '修改人',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建者',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8mb4 COMMENT='数据源管理';

-- ----------------------------
-- Records of meta_datasource
-- ----------------------------
BEGIN;
INSERT INTO `meta_datasource` VALUES (4, 'superior', 'Mysql数据库', 'MySQL', 'superior', 'YMs-iPQ2wJsyLmEKl2vY0w==', '139.217.237.72', 3306, '', NULL, '', '', '怀信#huaixin', '怀信#huaixin', '2022-09-08 23:10:01', '2022-09-08 23:10:01', 1);
INSERT INTO `meta_datasource` VALUES (8, 'clickhouse_demo', 'clickhouse 测试', 'ClickHouse', 'default', 'vtnyK8CwU-hI90t7oLcW2g==', '40.73.102.235', 8123, '', NULL, '', '', '怀信#huaixin', '怀信#huaixin', '2022-09-13 22:00:13', '2022-09-13 22:07:12', 1);
INSERT INTO `meta_datasource` VALUES (9, 'postgres_demo', 'pg 测试', 'PostgreSQL', 'postgres', '_GjBf7Mn5v-WqZo2gTUGWg==', '40.73.102.235', 5432, 'postgres', NULL, '', '', '怀信#huaixin', '怀信#huaixin', '2022-09-13 22:15:00', '2022-09-14 22:55:40', 1);
INSERT INTO `meta_datasource` VALUES (10, 'aotele', '奥特乐', 'MySQL', 'optimus_dev', 'DOqbyN59u5Qz0n0tliP3YA==', '8.136.133.76', 23306, 'pevc_reviw', 'Service Name', '', '', '不玄#buxuan', '不玄#buxuan', '2022-09-21 14:33:53', '2022-09-23 15:30:14', 1);
INSERT INTO `meta_datasource` VALUES (12, 'asdfas', 'Oracle测试', 'Oracle', 'asdf', 'PW7CLY6-bBeCHnHmkMc3pA==', 'asdfa', 1521, 'sdfas', 'Service Name', '', '', '怀信#huaixin', '怀信#huaixin', '2022-09-22 23:01:26', '2022-09-22 23:17:39', 1);
INSERT INTO `meta_datasource` VALUES (13, 'new_server', '数据中台数据库', 'MySQL', 'root', '4D4Q-6SPxoo1_9PL5OYUKQ==', '40.72.114.55', 3306, '', NULL, '', '', '不玄#buxuan', '不玄#buxuan', '2022-09-23 15:31:27', '2022-09-23 15:31:27', 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_dqc_rule
-- ----------------------------
DROP TABLE IF EXISTS `meta_dqc_rule`;
CREATE TABLE `meta_dqc_rule` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) NOT NULL COMMENT '数据库名',
  `table_name` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `type` varchar(45) NOT NULL COMMENT '规则类型：template、custom',
  `partition_expr` varchar(128) DEFAULT NULL COMMENT '分区表达式',
  `name` varchar(128) DEFAULT NULL COMMENT '规则名称',
  `intensity` varchar(45) DEFAULT NULL COMMENT '规则强度：strong、weak',
  `rule_column` varchar(45) DEFAULT NULL COMMENT '规则字段',
  `rule_template` varchar(45) DEFAULT NULL COMMENT '规则模板',
  `compare_method` int(11) DEFAULT NULL COMMENT '比较方式：绝对值、上升、下降',
  `orange_threshold` decimal(2,0) DEFAULT NULL COMMENT '橙色阈值',
  `red_threshold` decimal(3,0) DEFAULT NULL COMMENT '红色阈值',
  `desired_value` double DEFAULT NULL COMMENT '期望值',
  `description` varchar(256) DEFAULT NULL COMMENT '描述',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '修改人',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='DQC 规则定义表';

-- ----------------------------
-- Records of meta_dqc_rule
-- ----------------------------
BEGIN;
COMMIT;

-- ----------------------------
-- Table structure for meta_folder
-- ----------------------------
DROP TABLE IF EXISTS `meta_folder`;
CREATE TABLE `meta_folder` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `workspace_code` varchar(45) DEFAULT NULL COMMENT '项目code',
  `name` varchar(45) NOT NULL COMMENT '文件夹名称',
  `parent_id` int(11) NOT NULL COMMENT '父节点ID，根节点为：-1',
  `type` varchar(45) NOT NULL COMMENT '类型：作业任务、资源、函数，枚举值：job、res、fun',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=214 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_folder
-- ----------------------------
BEGIN;
INSERT INTO `meta_folder` VALUES (1, 'bigdata', '怀信', -1, 'job', '2021-06-22 20:35:33', '2022-05-07 00:01:04', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (2, 'bigdata', '发布作业', 1, 'job', '2021-06-24 16:41:37', '2021-06-24 16:41:37', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (6, 'bigdata', '函数资源', -1, 'res', '2021-07-09 22:30:48', '2021-08-23 23:06:51', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (7, 'bigdata', '作业资源', -1, 'res', '2021-07-09 22:31:38', '2021-07-09 22:31:38', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (8, 'bigdata', '自定义函数', -1, 'fun', '2021-07-12 14:20:01', '2021-07-12 14:20:01', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (9, 'bigdata', '字符串', 8, 'fun', '2021-07-12 14:20:13', '2021-07-12 14:20:13', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (10, 'bigdata', 'python', 1, 'job', '2021-07-12 14:49:15', '2021-08-23 23:06:25', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (12, 'bigdata', 'python库', -1, 'res', '2021-07-13 16:19:34', '2021-07-13 16:19:34', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (14, 'bigdata', '采集', 1, 'job', '2021-08-14 17:47:00', '2021-08-14 17:47:00', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (15, 'bigdata', 'datatunnel', 1, 'job', '2021-08-17 17:58:09', '2022-06-26 23:55:12', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (17, 'bigdata', 'sql', 1, 'job', '2021-09-01 09:38:19', '2021-09-01 09:38:19', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (18, 'bigdata', 'hudi', 1, 'job', '2021-09-03 10:44:17', '2021-09-03 10:44:17', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (19, 'stream_bigdata', '怀信', -1, 'job', '2021-09-11 14:29:35', '2021-09-11 14:29:35', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (83, 'bigdata', 'iceberg', 1, 'job', '2022-03-11 22:51:09', '2022-03-11 22:51:09', '怀信#huaixin', '怀信#huaixin', 1);
INSERT INTO `meta_folder` VALUES (84, 'bigdata', '不玄', -1, 'job', '2022-07-27 09:56:49', '2022-07-27 09:56:49', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (85, 'bigdata', 'datatunnel', 84, 'job', '2022-07-28 23:44:31', '2022-07-28 23:44:31', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (86, 'bigdata', '发布作业', 84, 'job', '2022-07-28 23:44:48', '2022-07-28 23:44:48', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (87, 'bigdata', 'zero', -1, 'job', '2022-08-01 15:52:09', '2022-08-01 15:52:09', '林庆贤#zerolin', '林庆贤#zerolin', 1);
INSERT INTO `meta_folder` VALUES (88, 'aoteledemo', 'TEST', -1, 'job', '2022-08-06 13:40:52', '2022-08-10 13:23:29', 'demo#demo', 'demo#demo', 1);
INSERT INTO `meta_folder` VALUES (112, 'aoteledemo', '供应链管理', -1, 'job', '2022-08-11 10:28:21', '2022-08-11 10:54:17', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (113, 'aoteledemo', '销售管理', -1, 'job', '2022-08-11 10:54:30', '2022-08-11 10:54:30', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (114, 'aoteledemo', '主数据', -1, 'job', '2022-08-11 10:54:42', '2022-08-11 10:54:42', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (115, 'aoteledemo', 'DIM', 114, 'job', '2022-08-11 10:55:41', '2022-08-11 10:55:41', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (116, 'aoteledemo', 'DDL', 115, 'job', '2022-08-11 10:55:59', '2022-08-11 10:55:59', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (117, 'aoteledemo', 'DATA_TRSF', 115, 'job', '2022-08-11 10:56:22', '2022-08-11 11:23:38', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (118, 'aoteledemo', 'ODS', 113, 'job', '2022-08-11 11:09:56', '2022-08-11 11:09:56', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (119, 'aoteledemo', 'CDM', 113, 'job', '2022-08-11 11:10:20', '2022-08-11 11:10:55', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (120, 'aoteledemo', 'ADS', 113, 'job', '2022-08-11 11:11:27', '2022-08-11 11:11:27', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (121, 'aoteledemo', 'DDL', 118, 'job', '2022-08-11 11:12:20', '2022-08-11 11:12:20', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (122, 'aoteledemo', 'DATA_IMP', 118, 'job', '2022-08-11 11:12:36', '2022-08-11 11:12:36', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (124, 'aoteledemo', 'DWD', 119, 'job', '2022-08-11 11:13:33', '2022-08-11 11:13:33', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (125, 'aoteledemo', 'DWS', 119, 'job', '2022-08-11 11:13:40', '2022-08-11 11:13:40', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (126, 'aoteledemo', 'DDL', 124, 'job', '2022-08-11 11:17:02', '2022-08-11 11:17:02', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (127, 'aoteledemo', 'DATA_TRSF', 124, 'job', '2022-08-11 11:18:02', '2022-08-11 11:18:02', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (128, 'aoteledemo', 'DDL', 125, 'job', '2022-08-11 11:18:22', '2022-08-11 11:18:22', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (129, 'aoteledemo', 'DATA_TRSF', 125, 'job', '2022-08-11 11:18:41', '2022-08-11 11:18:41', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (130, 'aoteledemo', 'DDL', 120, 'job', '2022-08-11 11:21:33', '2022-08-11 11:21:33', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (131, 'aoteledemo', 'DATA_TRSF', 120, 'job', '2022-08-11 11:22:41', '2022-08-11 11:22:41', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (132, 'aoteledemo', 'DATA_EXP', 120, 'job', '2022-08-11 11:24:21', '2022-08-11 11:24:21', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (133, 'aoteledemo', '采购管理', 112, 'job', '2022-08-11 11:32:02', '2022-08-11 11:32:02', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (134, 'aoteledemo', '库存管理', 112, 'job', '2022-08-11 11:32:16', '2022-08-11 11:32:16', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (135, 'aoteledemo', 'ODS', 133, 'job', '2022-08-11 11:34:10', '2022-08-11 11:34:10', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (136, 'aoteledemo', 'CDM', 133, 'job', '2022-08-11 11:34:18', '2022-08-11 11:34:18', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (137, 'aoteledemo', 'ADS', 133, 'job', '2022-08-11 11:34:26', '2022-08-11 11:34:26', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (138, 'aoteledemo', 'ODS', 134, 'job', '2022-08-11 11:34:35', '2022-08-11 11:34:35', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (139, 'aoteledemo', 'CDM', 134, 'job', '2022-08-11 11:34:41', '2022-08-11 11:34:41', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (140, 'aoteledemo', 'ADS', 134, 'job', '2022-08-11 11:34:58', '2022-08-11 11:34:58', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (141, 'aoteledemo', 'DWD', 139, 'job', '2022-08-11 11:35:25', '2022-08-11 11:35:25', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (142, 'aoteledemo', 'DWS', 139, 'job', '2022-08-11 11:35:34', '2022-08-11 11:35:34', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (143, 'aoteledemo', 'DWD', 136, 'job', '2022-08-11 11:35:55', '2022-08-11 11:35:55', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (144, 'aoteledemo', 'DWS', 136, 'job', '2022-08-11 11:36:00', '2022-08-11 11:36:00', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (145, 'aoteledemo', 'DDL', 135, 'job', '2022-08-11 11:36:34', '2022-08-11 11:36:34', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (146, 'aoteledemo', 'DATA_IMP', 135, 'job', '2022-08-11 11:36:54', '2022-08-11 11:36:54', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (147, 'aoteledemo', 'DDL', 143, 'job', '2022-08-11 11:37:08', '2022-08-11 11:37:08', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (148, 'aoteledemo', 'DATA_TRSF', 143, 'job', '2022-08-11 11:37:31', '2022-08-11 11:37:31', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (149, 'aoteledemo', 'DDL', 144, 'job', '2022-08-11 11:37:45', '2022-08-11 11:37:45', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (150, 'aoteledemo', 'DATA_TRSF', 144, 'job', '2022-08-11 11:37:54', '2022-08-11 11:37:54', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (151, 'aoteledemo', 'DDL', 137, 'job', '2022-08-11 11:38:16', '2022-08-11 11:38:16', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (152, 'aoteledemo', 'DATA_TRSF', 137, 'job', '2022-08-11 11:38:30', '2022-08-11 11:38:30', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (153, 'aoteledemo', 'DATA_EXP', 137, 'job', '2022-08-11 11:38:51', '2022-08-11 11:38:51', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (154, 'aoteledemo', 'DDL', 138, 'job', '2022-08-11 11:39:29', '2022-08-11 11:39:29', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (155, 'aoteledemo', 'DATA_IMP', 138, 'job', '2022-08-11 11:39:48', '2022-08-11 11:39:48', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (156, 'aoteledemo', 'DDL', 141, 'job', '2022-08-11 11:40:05', '2022-08-11 11:40:05', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (157, 'aoteledemo', 'DATA_TRSF', 141, 'job', '2022-08-11 11:40:18', '2022-08-11 11:40:18', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (158, 'aoteledemo', 'DDL', 142, 'job', '2022-08-11 11:40:31', '2022-08-11 11:40:31', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (159, 'aoteledemo', 'DATA_TRSF', 142, 'job', '2022-08-11 11:40:42', '2022-08-11 11:40:42', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (160, 'aoteledemo', 'DDL', 140, 'job', '2022-08-11 11:40:52', '2022-08-11 11:40:52', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (161, 'aoteledemo', 'DATA_TRSF', 140, 'job', '2022-08-11 11:41:40', '2022-08-11 11:41:40', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (162, 'aoteledemo', 'DATA_EXP', 140, 'job', '2022-08-11 11:41:50', '2022-08-11 11:41:50', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (163, '7or9', '供应链管理', -1, 'job', '2022-08-12 19:21:50', '2022-08-12 19:21:50', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (164, '7or9', '库存管理', 163, 'job', '2022-08-12 19:22:00', '2022-08-12 19:22:00', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (165, '7or9', 'ODS', 164, 'job', '2022-08-12 19:22:11', '2022-08-12 19:22:11', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (166, '7or9', 'CDM', 164, 'job', '2022-08-12 19:22:44', '2022-08-12 19:22:44', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (167, '7or9', 'ADS', 164, 'job', '2022-08-12 19:22:52', '2022-08-12 19:22:52', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (168, '7or9', 'DDL', 165, 'job', '2022-08-13 20:35:01', '2022-08-13 20:35:01', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (169, '7or9', 'DATA_IMP', 165, 'job', '2022-08-13 20:35:55', '2022-08-13 20:35:55', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (170, '7or9', 'DDL', 167, 'job', '2022-08-14 17:59:01', '2022-08-14 17:59:01', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (171, '7or9', 'dwd', 166, 'job', '2022-08-15 09:50:13', '2022-08-15 09:50:13', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (172, '7or9', 'DDL', 171, 'job', '2022-08-15 09:50:43', '2022-08-15 09:50:43', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (173, '7or9', 'DATA_IMP', 171, 'job', '2022-08-15 09:51:12', '2022-08-15 09:51:12', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (174, '7or9', 'DATA_IMP', 167, 'job', '2022-08-15 09:51:40', '2022-08-15 09:51:40', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (175, '7or9', 'DATA_EXP', 167, 'job', '2022-08-16 11:24:14', '2022-08-16 11:24:14', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (177, '7or9', '小红书', -1, 'job', '2022-08-16 11:26:57', '2022-08-16 11:26:57', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (178, '7or9', 'ODS', 177, 'job', '2022-08-16 11:27:12', '2022-08-16 11:27:12', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (179, '7or9', 'CDM', 177, 'job', '2022-08-16 11:27:19', '2022-08-16 11:28:54', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (180, '7or9', 'ADS', 177, 'job', '2022-08-16 11:27:31', '2022-08-16 11:27:31', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (181, '7or9', 'DWD', 179, 'job', '2022-08-16 11:29:04', '2022-08-16 11:29:04', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (182, '7or9', 'DDL', 178, 'job', '2022-08-16 11:29:16', '2022-08-16 11:29:16', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (183, '7or9', 'DDL', 181, 'job', '2022-08-16 11:29:28', '2022-08-16 11:29:28', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (184, '7or9', 'DDL', 180, 'job', '2022-08-16 11:29:34', '2022-08-16 11:29:34', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (185, '7or9', 'DATA_IMP', 178, 'job', '2022-08-16 11:30:02', '2022-08-16 11:30:02', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (186, '7or9', 'DATA_IMP', 181, 'job', '2022-08-16 11:30:32', '2022-08-16 11:30:32', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (187, '7or9', 'DATA_IMP', 180, 'job', '2022-08-16 11:31:00', '2022-08-16 11:31:00', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (188, '7or9', 'DATA_EXP', 180, 'job', '2022-08-16 11:31:28', '2022-08-16 11:31:28', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (189, '7or9', '毛利明细', -1, 'job', '2022-08-17 16:31:05', '2022-08-17 16:31:05', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (190, '7or9', 'ODS', 189, 'job', '2022-08-17 16:31:18', '2022-08-17 16:31:18', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (191, '7or9', 'DIM', 189, 'job', '2022-08-17 16:31:32', '2022-08-18 09:58:43', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (192, '7or9', 'DDL', 190, 'job', '2022-08-17 16:31:51', '2022-08-17 16:31:51', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (193, '7or9', 'DATA_IMP', 190, 'job', '2022-08-17 16:32:10', '2022-08-17 16:32:10', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (194, '7or9', 'DDL', 191, 'job', '2022-08-18 09:53:00', '2022-08-18 09:53:00', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (195, '7or9', 'DATA_IMP', 191, 'job', '2022-08-18 09:53:26', '2022-08-18 09:53:26', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (199, 'bigdata', 'fang', -1, 'job', '2022-08-24 09:09:38', '2022-08-24 09:09:38', '方楚生#fangchusheng', '方楚生#fangchusheng', 1);
INSERT INTO `meta_folder` VALUES (200, 'bigdata', '玄武', -1, 'job', '2022-09-12 16:17:56', '2022-09-12 16:17:56', '阿平#xuanwu', '阿平#xuanwu', 1);
INSERT INTO `meta_folder` VALUES (201, 'offline_sec', '人员内控', -1, 'job', '2022-09-13 16:55:38', '2022-09-13 16:55:38', '阿平#xuanwu', '阿平#xuanwu', 1);
INSERT INTO `meta_folder` VALUES (202, 'aoteledemo', '商品管理', -1, 'job', '2022-09-23 17:03:15', '2022-09-23 17:03:15', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (203, 'aoteledemo', 'ODS', 202, 'job', '2022-09-23 17:03:31', '2022-09-23 17:03:31', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (204, 'aoteledemo', 'CDM', 202, 'job', '2022-09-23 17:03:38', '2022-09-23 17:03:38', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (205, 'aoteledemo', 'ADS', 202, 'job', '2022-09-23 17:03:43', '2022-09-23 17:03:43', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (206, 'aoteledemo', 'DDL', 203, 'job', '2022-09-23 17:04:43', '2022-09-23 17:04:43', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (207, 'aoteledemo', 'DATA_IMP', 203, 'job', '2022-09-23 17:04:59', '2022-09-23 17:04:59', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (208, 'aoteledemo', 'DDL', 204, 'job', '2022-09-23 17:05:28', '2022-09-23 17:05:28', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (209, 'aoteledemo', 'DATA_TRSF', 204, 'job', '2022-09-23 17:05:53', '2022-09-23 17:05:53', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (210, 'aoteledemo', 'DDL', 205, 'job', '2022-09-23 17:06:09', '2022-09-23 17:06:09', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (211, 'aoteledemo', 'DATA_EXP', 205, 'job', '2022-09-23 17:06:19', '2022-09-23 17:06:19', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (212, 'bigdata', 'qqq', -1, 'job', '2022-09-29 17:03:38', '2022-09-29 17:03:38', '不玄#buxuan', '不玄#buxuan', 1);
INSERT INTO `meta_folder` VALUES (213, 'test001', 'test', -1, 'job', '2022-09-29 17:09:24', '2022-09-29 17:09:24', '不玄#buxuan', '不玄#buxuan', 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_function
-- ----------------------------
DROP TABLE IF EXISTS `meta_function`;
CREATE TABLE `meta_function` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `workspace_code` varchar(45) NOT NULL COMMENT '项目code',
  `folder_id` int(11) NOT NULL,
  `name` varchar(45) NOT NULL,
  `class_name` varchar(255) NOT NULL COMMENT '资源ID',
  `res_id` int(11) NOT NULL,
  `detail` varchar(2048) DEFAULT NULL,
  `current` smallint(6) DEFAULT '0' COMMENT '0：tree查询可见节点，1：tree查询不可见',
  `status` smallint(6) NOT NULL DEFAULT '0' COMMENT '发布状态，0为发布，1发布，3历史版本状态，5删除存入回收站',
  `trash` varchar(45) DEFAULT '0' COMMENT '1：数据引入回收站',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `name_UNIQUE` (`name`,`workspace_code`) USING BTREE,
  KEY `fk_dc_function_dc_folder1_idx` (`folder_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_function
-- ----------------------------
BEGIN;
INSERT INTO `meta_function` VALUES (4, 1, 'bigdata', 9, 'dz_encode_sha512', 'com.dataworker.udf.text.GenericUDFSha512Encrypt', 2, 'dd', 0, 0, '0', '2021-07-28 18:14:16', '2021-07-28 18:14:16', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_function` VALUES (5, 1, 'bigdata', 9, 'ac_contains_match', 'com.dataworker.udf.ac.TextContainsMatchUDF', 2, 'ac_contains_match', 0, 0, '0', '2021-08-12 16:58:39', '2021-08-12 16:58:39', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_function` VALUES (6, 1, 'bigdata', 9, 'list_table_of_sql', 'com.aloudata.ads.sqlanalysis.sqludf.pattern.ListTableOfSql', 7, '获取表名称  ', 0, 0, '0', '2021-12-29 14:52:03', '2021-12-30 10:26:27', '齐观#qiguan', '齐观#qiguan');
INSERT INTO `meta_function` VALUES (7, 1, 'bigdata', 9, 'list_pattern_of_sql', 'com.aloudata.ads.sqlanalysis.sqludf.pattern.ListPatternOfSql', 7, '解析Pattern', 0, 0, '0', '2021-12-30 11:34:43', '2021-12-30 11:34:43', '齐观#qiguan', '齐观#qiguan');
INSERT INTO `meta_function` VALUES (8, 1, 'bigdata', 9, 'get_prob_sql_of_pattern', 'com.aloudata.ads.sqlanalysis.sqludf.pattern.GetProbSqlOfPattern', 7, '生成探查SQL', 0, 0, '0', '2021-12-30 11:35:13', '2021-12-30 11:35:13', '齐观#qiguan', '齐观#qiguan');
INSERT INTO `meta_function` VALUES (9, 1, 'bigdata', 9, 'get_measure_fields_of_pattern', 'com.aloudata.ads.sqlanalysis.sqludf.pattern.GetMeasureFields', 7, '获取度量列', 0, 0, '0', '2021-12-31 14:43:42', '2021-12-31 14:43:48', '齐观#qiguan', '齐观#qiguan');
COMMIT;

-- ----------------------------
-- Table structure for meta_instance_count_statis
-- ----------------------------
DROP TABLE IF EXISTS `meta_instance_count_statis`;
CREATE TABLE `meta_instance_count_statis` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `workspace_code` varchar(45) DEFAULT NULL COMMENT '项目',
  `instance_type` varchar(45) DEFAULT NULL COMMENT '实例类型',
  `job_type` varchar(45) DEFAULT NULL COMMENT '作业类型',
  `instance_count` bigint(20) DEFAULT NULL COMMENT '实例数量',
  `statis_time` varchar(20) DEFAULT NULL COMMENT '统计时间',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '修改人',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=526 DEFAULT CHARSET=utf8mb4 COMMENT='实例数量统计表';

-- ----------------------------
-- Records of meta_instance_count_statis
-- ----------------------------
BEGIN;
INSERT INTO `meta_instance_count_statis` VALUES (506, 'bigdata', 'dev', 'spark_sql', 10, '2022-09-26', '2022-09-27 08:05:00', '2022-09-27 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (507, 'bigdata', 'dev', 'spark_sql', 37, '2022-09-28', '2022-09-29 08:05:00', '2022-09-29 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (508, 'bigdata', 'dev', 'spark_python', 2, '2022-09-28', '2022-09-29 08:05:00', '2022-09-29 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (509, 'aoteledemo', 'dev', 'spark_sql', 6, '2022-09-28', '2022-09-29 08:05:00', '2022-09-29 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (510, '7or9', 'dev', 'spark_sql', 2, '2022-09-28', '2022-09-29 08:05:00', '2022-09-29 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (511, 'bigdata', 'dev', 'spark_sql', 10, '2022-09-29', '2022-09-30 08:05:00', '2022-09-30 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (512, 'aoteledemo', 'dev', 'spark_sql', 6, '2022-09-29', '2022-09-30 08:05:00', '2022-09-30 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (513, 'test001', 'dev', 'spark_sql', 2, '2022-09-29', '2022-09-30 08:05:00', '2022-09-30 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (514, 'test001', 'dev', 'spark_sql', 25, '2022-09-30', '2022-10-01 08:05:00', '2022-10-01 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (515, 'bigdata', 'dev', 'spark_sql', 1, '2022-09-30', '2022-10-01 08:05:00', '2022-10-01 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (516, 'test001', 'schedule', 'spark_sql', 2, '2022-10-01', '2022-10-02 08:05:00', '2022-10-02 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (517, 'test001', 'schedule', 'spark_sql', 2, '2022-10-02', '2022-10-03 08:05:00', '2022-10-03 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (518, 'test001', 'schedule', 'spark_sql', 2, '2022-10-03', '2022-10-04 08:05:00', '2022-10-04 08:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (519, 'bigdata', 'dev', 'spark_sql', 24, '2022-10-15', '2022-10-16 00:05:00', '2022-10-16 00:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (520, 'bigdata', 'schedule', 'spark_python', 1, '2022-10-15', '2022-10-16 00:05:00', '2022-10-16 00:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (521, 'bigdata', 'schedule', 'spark_sql', 1, '2022-10-15', '2022-10-16 00:05:00', '2022-10-16 00:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (522, 'test001', 'schedule', 'spark_sql', 2, '2022-10-15', '2022-10-16 00:05:00', '2022-10-16 00:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (523, 'bigdata', 'schedule', 'spark_python', 1, '2022-10-16', '2022-10-17 00:05:00', '2022-10-17 00:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (524, 'bigdata', 'schedule', 'spark_sql', 2, '2022-10-16', '2022-10-17 00:05:00', '2022-10-17 00:05:00', '管理员#admin', '管理员#admin', 1);
INSERT INTO `meta_instance_count_statis` VALUES (525, 'test001', 'schedule', 'spark_sql', 2, '2022-10-16', '2022-10-17 00:05:00', '2022-10-17 00:05:00', '管理员#admin', '管理员#admin', 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_job
-- ----------------------------
DROP TABLE IF EXISTS `meta_job`;
CREATE TABLE `meta_job` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `workspace_code` varchar(45) DEFAULT NULL COMMENT '项目code',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `folder_id` int(11) NOT NULL COMMENT '所属文件夹ID',
  `name` varchar(128) NOT NULL COMMENT 'job名称',
  `code` varchar(45) NOT NULL,
  `cluster_code` varchar(64) DEFAULT NULL,
  `detail` varchar(2048) DEFAULT NULL,
  `content` longtext COMMENT '节点任务内容，例如：SQL',
  `type` varchar(45) NOT NULL COMMENT '做业务任务类型：sql，tmp_sql、sparkjob，mr',
  `params` varchar(1024) DEFAULT NULL COMMENT '用户设置参数例如：bizdate={yyyyMMdd-1}',
  `version` varchar(45) DEFAULT NULL COMMENT '版本号',
  `auditor` varchar(45) DEFAULT NULL COMMENT '作业发布审核人',
  `owner` varchar(64) DEFAULT NULL COMMENT '负责人',
  `proxy_user` varchar(64) DEFAULT NULL COMMENT '作业代理运行用户',
  `current` smallint(6) DEFAULT '0' COMMENT '0：tree查询可见节点，1：tree查询不可见',
  `status` smallint(6) NOT NULL DEFAULT '0' COMMENT '发布状态，0未发布，1待发布状态，2待审核，3审核通过，4审核不通过',
  `publish_time` datetime DEFAULT NULL COMMENT '发布时间',
  `immediately_schedule` smallint(6) DEFAULT '0' COMMENT '是否立即调度：0不立即调度，1立即调度',
  `dep_last_period` tinyint(1) DEFAULT NULL COMMENT '依赖上一周期',
  `schedule_type` varchar(32) NOT NULL DEFAULT '1' COMMENT '周期调度：period\n触发调度：trigger\n暂停调度：pause\n空跑调度：blank',
  `history` tinyint(1) DEFAULT '0' COMMENT '1: 表示历史审核通过以后的job',
  `trash` varchar(45) DEFAULT '0' COMMENT '1：数据进入回收站',
  `run_level` varchar(45) DEFAULT 'p2' COMMENT '作业运行等级\\np1: 线上依赖数据，不能延迟（告警）\\np2: 下游依赖数据，不能延迟 (告警)\\np3: 可延迟 （消息通知）',
  `auth_users` varchar(2048) DEFAULT NULL COMMENT '授权用户可以查看编辑作业',
  `schedule_mode` varchar(32) DEFAULT NULL COMMENT '调度模式',
  `wait_timeout_hour` int(11) DEFAULT '6' COMMENT '等待运行超时时间告警',
  `alarm_method` varchar(128) DEFAULT NULL COMMENT '告警方式：短信，钉钉，微信，电话',
  `alarm_max_count` int(11) DEFAULT NULL COMMENT '告警最大次数',
  `alarm_interval_minute` int(11) DEFAULT NULL COMMENT '告警间隔',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL COMMENT 'gmt_modified',
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `fk_dc_job_dc_folder_idx` (`folder_id`) USING BTREE,
  KEY `name_index` (`workspace_code`,`name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=380 DEFAULT CHARSET=utf8mb4 COMMENT='作业';

-- ----------------------------
-- Records of meta_job
-- ----------------------------
BEGIN;
INSERT INTO `meta_job` VALUES (1, 'bigdata', 1, 17, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 'hangzhou-spark-3.2', 'dd', 'show create table test_demo_test;\n\ndrop table if exists test_demo_dt;\n\nCREATE TABLE test_demo_dt (name string, age int, ds String)\nusing parquet\npartitioned by (ds) \nLIFECYCLE 10;\n\nINSERT INTO table test_demo_test1 VALUES ( null, 23);\nINSERT INTO table test_demo_test1 VALUES ( \'\', 25);\nINSERT INTO table test_demo_test1 VALUES ( \'zhangsan\', 23);\n\nANALYZE TABLE test_demo_test1 COMPUTE STATISTICS;\n\nDESC EXTENDED test_demo_test1;\n\nselect * from test_demo_test1\n\nINSERT INTO test_demo_test (age, name) VALUES(25, \'lisi\')\n\nset spark.sql.ansi.enabled=false;\nmerge table test_demo_test options(fileCount=1,compression=\'snappy\')\n\nselect CAST(-123456789 AS TIMESTAMP) as de\n\nselect CURRENT_DATE()\n\nset spark.dynamicAllocation.maxExecutors=40;\n\ndrop table if exists tdl_demo_test;\ncreate table tdl_demo_test\nexplain extended select name from test_demo_test\n\nshow create table tdl_demo_test111\n\nalter table bigdata.test_demo_test set TBLPROPERTIES (\'orc.compress\' = \'snappy\')\n\nshow create table bigdata.test_demo_dt\n\ncreate table tdl_demo_test as select * from bigdata.test_demo_test\n\n\nset spark.sql.ansi.enabled=false;\nselect cast(\'\' as float)\n\nset spark.sql.ansi.enabled=false;\nSELECT 2147483647 + 1;\n\nexplain select name from bigdata.test_child_dt where ds=\'20211119\'\n\ncreate view view_delta_users_dt_2 PARTITIONED ON(ds) as \nselect * from bigdata.test_demo_dt limit 10;\n\nshow partitions test_child_dt\n\nshow views\n\nshow create table demo_child_dt\n\ndrop table demo_child_dt;\ncreate table test_child_dt (\n    name string,\n    num int,\n    ds string\n) \nusing parquet \npartitioned by (ds) \nlifeCycle 2;\n\nINSERT INTO\n    TABLE demo_child_dt artition(ds)\nSELECT name, num * 10 AS num, ds\nFROM test_demo_dt\nWHERE ds = \'\';\n\nshow create table test_demo_dd\n\nselect * from test_child_dt where	ds=\'20211207\'\n\ncreate table test_child_lineage (\n	name	string	comment	\'\',\n	num	int	comment	\'\',\n	ds	string	comment	\'\'\n)\nlifeCycle 2;\n\n\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, 'sms,dingding', 2, 10, '2021-06-22 20:35:47', '2022-10-15 22:13:27', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (7, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert into table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-06-24 16:47:18', 0, NULL, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-06-24 16:44:08', '2021-08-23 22:57:40', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (8, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n\ndef main(sparkSession):\n    print(\"hello spark\")\n	sql = \"insert into table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n	sparkSession.sql(sql)\n	\n	sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n	', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-06-24 17:18:22', 0, NULL, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-06-24 16:49:20', '2021-06-24 17:19:29', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (10, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert into table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-06-24 17:19:26', 0, NULL, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-06-24 17:19:07', '2021-08-23 22:57:40', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (12, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-06-24 18:28:27', 0, NULL, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-06-24 18:28:16', '2021-09-16 11:10:56', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (26, 'bigdata', 1, 1, 'spark_jar_task', 'job-2ae9694f-ff71-481f-b5e2-592f31e5f6a4', 'hangzhou-spark-3.2', 'dataworker-job-demo-1.0.0.jar', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-07-09 22:51:37\n--********************************************************************--\n\n\nspark-jobserver-examples-3.2.0-SNAPSHOT.jar com.github.melin.superior.jobserver.examples.SparkJobDemo qianxiao JavaJobDemo kk\n\n', 'spark_jar', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-09 22:51:37', '2022-09-23 18:11:42', '怀信#huaixin', '王凯#wangkai');
INSERT INTO `meta_job` VALUES (33, 'bigdata', 1, 17, 'udf-demo', 'job-c0596ed2-bdb2-4e0d-a08d-178ab5eb3ea3', 'hangzhou-spark-3.2', 'udf demo', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-07-12 14:29:28\n--********************************************************************--\n\nselect bigdata.dz_encode_sha512(\"hello\", \"salt\")', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-12 14:29:28', '2021-12-04 22:41:42', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (41, 'bigdata', 1, 10, 'read_write_file', 'job-d1c70d20-217f-4a0f-abca-483f7ce41ea8', 'hangzhou-spark-3.2', 'read write file', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-07-13 09:38:52\n#********************************************************************\n\ndef main(sparkSession):\n    info(\"=-----\")\n	file1 = open(\"hello.txt\", \'w\')\n	file1.write(\"hello\\n\")\n	#本地文件保存到【我的资源】下，存储路径：/user/datawork/users/{当前登录用户名}，保存文件可以不添加路径前缀，系统会自动添加\n	saveFile(file1, \"/hello.txt\", True) # /hello.txt 等同于 /user/datawork/users/qianxiao/hello.txt\n	\n	\n	file = openFile(\"/user/datawork/users/qianxiao/hello.txt\", \'r\') # /hello.txt 等同于 /user/datawork/users/qianxiao/hello.txt\n	print(file.read())\n	\n	#deleteFile(\"/hello.txt\") # /hello.txt 等同于 /user/datawork/users/qianxiao/hello.txt\n\n\n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-13 09:38:52', '2021-08-30 16:05:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (47, 'bigdata', 1, 10, 'python_3th_pkg', 'job-a539cfb7-dceb-4766-9dfc-663ed135bf1f', 'hangzhou-spark-3.2', 'python_3th_pkg', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-07-13 16:20:52\n#********************************************************************\n\n# addPkg hello.zip\n\nimport helloworld\n\ndef main(sparkSession):\n	helloworld.show()\n	info(\'sds\')\n\n\n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-13 16:20:52', '2021-08-30 11:47:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (64, 'bigdata', 1, 17, 'export_load_test', 'job-012e4cd5-b758-4237-86c4-f05bae6fa7b4', 'hangzhou-spark-3.2', 'export load test', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-07-16 11:03:50\n--********************************************************************--\n\nload data \'/user/datawork/users/qianxiao/demo.csv\' table tdl_spark_test options( delimiter=\',\', header=\'true\');\nselect * from tdl_spark_test;\n\n\nexport table bigdata.test_demo_dt PARTITION (ds=20210822) TO \'test_demo_dt_1.csv\' options(delimiter=\'#\', overwrite=false);\n\n\nselect * from test_demo_dt where ds like \'202108%\'\n\nwith\ntdl_test_demo_dt as (select * from bigdata.test_demo_dt where ds like \'202108%\')\nexport table tdl_test_demo_dt TO \'test_demo_dt_2.csv.zip\' options(password=\'123456\');\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-16 11:03:51', '2021-12-04 22:41:34', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (65, 'bigdata', 1, 14, 'dzlog', 'job-2577599e-0061-4542-95cd-f5be56432107', 'hangzhou-spark-3.2', 'dzlog', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-07-17 14:51:34\n--********************************************************************--\n\ndrop table if exists dzlog_test_dt;\ncreate table dzlog_test_dt (\n    message string,\n    collect_time timestamp,\n    ds string\n) \nusing parquet\npartitioned by (ds) \nlifeCycle 14;\n\nshow create table dzlog_test_dt\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-17 14:51:34', '2021-12-09 15:03:57', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (66, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")\n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-08-18 18:04:44', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-07-19 14:14:52', '2021-08-18 18:05:05', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (98, 'bigdata', 1, 10, 'puython_demo', 'job-cdb2a5d4-341a-4e67-b11b-07b2acbe14e9', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-07-28 19:29:08\n#********************************************************************\n\n# addPkg git://qianxiao/python-demo/master\n\n#unset spark.driver.memory=3g\n\nimport helloworld\n\ndef main(sparkSession):\n	helloworld.show()\n	', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-28 19:29:09', '2021-09-16 09:53:11', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (99, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-09-16 11:10:56', 0, NULL, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-28 19:45:21', '2021-09-16 11:11:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (102, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-09-16 11:11:09', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao,zhaixing', 'period', 6, NULL, NULL, NULL, '2021-07-28 20:21:30', '2021-12-05 13:50:53', '怀信#huaixin', '方悟#fangwu');
INSERT INTO `meta_job` VALUES (103, 'bigdata', 1, 2, 'demo_proxy_dj', 'job-c21d48f2-8cf9-430f-a89c-835e9ea30770', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")\n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', NULL, 1, 0, '2021-07-29 19:10:21', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-07-29 19:09:17', '2021-07-30 10:41:47', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (104, 'bigdata', 1, 2, 'demo_proxy_dj', 'job-c21d48f2-8cf9-430f-a89c-835e9ea30770', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")\n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', NULL, 1, 0, '2021-07-30 10:41:47', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-07-30 10:41:37', '2021-07-30 10:42:13', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (105, 'bigdata', 1, 2, 'demo_proxy_dj', 'job-c21d48f2-8cf9-430f-a89c-835e9ea30770', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")\n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', NULL, 1, 0, '2021-07-30 10:42:13', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-07-30 10:41:59', '2021-07-30 11:01:47', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (108, 'bigdata', 1, 2, 'demo_proxy_dj', 'job-c21d48f2-8cf9-430f-a89c-835e9ea30770', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")\n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '摘星#zhaixing', 1, 0, '2021-11-09 10:59:13', 0, 0, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-07-30 11:27:05', '2021-12-05 13:50:49', '怀信#huaixin', '方悟#fangwu');
INSERT INTO `meta_job` VALUES (109, 'bigdata', 1, 2, 'month_last_day_mj', 'job-9b58e158-2445-436e-a5a0-4136565fa2b3', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-07-30 22:38:25\n#********************************************************************\n\ndef main(sparkSession):\n	print(\"last day\")', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 0, 0, '2021-07-30 22:40:05', 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-07-30 22:38:25', '2021-07-30 22:40:05', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (113, 'bigdata', 1, 15, 'hdfs-sftp', 'job-c144b16b-64eb-4635-bd1b-602c75ac2b34', 'hangzhou-spark-3.2', 'sd', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-08-17 17:58:29\n--********************************************************************--\n\nset spark.driver.memory = 3g;\n\ndatax reader(\"hdfs\") options(path=\"/user/datawork/users/qianxiao/export\", fileNameSuffix=\".csv\")\n    writer(\"sftp\") options(host=\"10.10.9.11\", port=22, username=\"sftpuser\", password=\'dz@2021\',\n              path=\"/upload/20210821\", overwrite=true);\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-08-17 17:58:30', '2021-11-15 13:39:45', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (114, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")  \n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-08-18 18:05:05', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-08-18 18:00:23', '2021-08-18 18:09:51', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (115, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\") \n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-08-18 18:09:51', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-08-18 18:06:08', '2021-08-18 18:13:35', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (116, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\") \n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-08-18 18:13:35', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-08-18 18:07:19', '2021-09-16 11:11:05', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (117, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")  \n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 0, '2021-09-16 11:11:05', 0, NULL, 'normal', 1, '0', 'p2', 'qianxiao', 'period', 6, NULL, NULL, NULL, '2021-08-18 18:13:57', '2021-12-05 13:50:51', '怀信#huaixin', '方悟#fangwu');
INSERT INTO `meta_job` VALUES (118, 'bigdata', 1, 10, 'graphframes_demo', 'job-3a767cbc-d10d-4bc9-8c97-e5f4250e6956', 'hangzhou-spark-3.2', 'graphframes', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-08-19 13:57:25\n#********************************************************************\n\nfrom graphframes import GraphFrame\n\ndef main(sparkSession):\n	v = sparkSession.createDataFrame([\n      (\"a\", \"Alice\", 34),\n      (\"b\", \"Bob\", 36),\n      (\"c\", \"Charlie\", 30),\n    ], [\"id\", \"name\", \"age\"])\n    \n    # Create an Edge DataFrame with \"src\" and \"dst\" columns\n    e = sparkSession.createDataFrame([\n      (\"a\", \"b\", \"friend\"),\n      (\"b\", \"c\", \"follow\"),\n      (\"c\", \"b\", \"follow\"),\n    ], [\"src\", \"dst\", \"relationship\"])\n\n    \n    #Create a GraphFrame\n    g = GraphFrame(v, e)\n\n    # Query: Get in-degree of each vertex.\n    g.inDegrees.show()\n\n    # Query: Count the number of \"follow\" connections in the graph.\n    g.edges.filter(\"relationship = \'follow\'\").count()\n\n    # Run PageRank algorithm, and show results.\n    results = g.pageRank(resetProbability=0.01, maxIter=20)\n    results.vertices.select(\"id\", \"pagerank\").show()\n    \n    \n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-08-19 13:57:25', '2021-12-07 16:47:13', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (124, 'bigdata', 1, 17, 'demo', 'job-172158b5-3386-4293-855a-46e2dea3345d', 'hangzhou-spark-3.2', 'demo ', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-08-24 10:39:57\n--********************************************************************--\n\nshow create table test_user11_dt;\n\ndrop table if exists test_user11_dt;\n\nCREATE TABLE test_demo_dt (name STRING, num int, ds string)\nusing parquet\nPARTITIONED BY (ds)\nLIFECYCLE 100;\n\nINSERT INTO TABLE test_user11_dt VALUES (\'zhangsan\', 23, \'20211203\'), (\'lisi\', 24, \'20211204\');\n\nselect current_timestamp\n\nselect to_timestamp(\'2022-04-20 16:10:21.000000\', \'yyyy-MM-dd HH:MM:ss\')\n\nselect * from superior.superior_test.meta_cluster_compute\n\nselect * from aotele.pevc_reviw.tmp_3\n\nselect name, _metadata.* from spark_catalog.bigdata.test_user11_dt where ds = \'20211203\'\n\nCREATE TABLE test_user1_dt (name STRING, num int)\nPARTITIONED BY (ds STRING)\nLIFECYCLE 2;\n\ninsert overwrite table test_user1_dt select * from test_user_dt where ds like \'202112%\'\n\nselect * from bigdata.dzlog_airenginequery_dt where ds like \'202112241%\'\n\nselect \'\\\\xa0\\\\xa1\' as dd\n\ninsert overwrite table test_demo_dt partition(ds=\'20211227\') values(\'zhangsan\', 23);\n\nSELECT ROUND(-24.35, -1)\n\nselect 1 as col1 where true and false\n\nselect round(1.5, -1)\n\nselect array_min(array(2,3,7,4,5,6))\n\nselect array_max(array(2,3,7,4,5,6))\n\n\nselect array_max(array(\'one\', \'two\', \'thress\'))\n\n\ndrop table if exists tdl_demo_decimal;\ncreate table tdl_demo_decimal as \n\nselect  floor(CAST(5.345 AS DECIMAL(3, 1)), -1) as num\n\nselect  floor(5.1, -1) \n\nSELECT floor(25.35, -1) as dd\nunion\nSELECT ROUND(25.35, -1) as dd\nunion\nSELECT round(-25.35, 1) as dd\nunion\nSELECT round(-25.35, -1) as dd\n\n\nselect * from tdl_demo_decimal\n\nexplain extended select sum(2.12) as num\n\nCREATE TABLE test_decimal_num (num decimal(10, 3))\nusing parquet\nLIFECYCLE 2;\n\n\ninsert overwrite table test_decimal_num values(23.3), (23.233), (1231.12351234)\n\nselect * from test_decimal_num\n\n\n\n\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', NULL, NULL, NULL, NULL, '2021-08-24 10:39:58', '2022-10-05 22:41:00', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (127, 'bigdata', 1, 17, 'CLUSTER_BY_SQL', 'job-301d3a33-9d09-4fc8-a7b2-4a84fd897d71', 'hangzhou-spark-3.2', 'CLUSTER_BY_SQL', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-01 09:38:34\n--********************************************************************--\n\nCREATE TABLE test_person_dt (name STRING, age INT) lifecycle 1;\nINSERT INTO test_person_dt VALUES\n    (\'Zen Hui\', 25),\n    (\'Anil B\', 18),\n    (\'Shone S\', 16),\n    (\'Mike A\', 25),\n    (\'John A\', 18),\n    (\'Jack N\', 16);\n    \n    \nSET spark.sql.shuffle.partitions = 2;\n\nSELECT age, name FROM person;\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-01 09:38:34', '2021-09-01 09:59:27', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (128, 'bigdata', 1, 15, 'datax-hive', 'job-8f0162b4-99f3-4a77-b487-14c91b8fe0cd', 'hangzhou-spark-3.2', 'datax-hive', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-01 16:05:44\n--********************************************************************--\n\ndatatunnel source(\"hive\") options(databaseName=\'bigdata\', tableName=\'test_demo_test\', columns=\'[\"*\"]\')\n    sink(\"log\") options(numRows=20)', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-01 16:05:45', '2022-07-03 17:25:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (131, 'bigdata', 1, 18, 'hudi_partition_sql', 'job-ec737d15-ec4d-42a4-8bb4-5af1d8071e9c', 'hangzhou-spark-3.2', 'dd', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-03 10:47:43\n--********************************************************************--\n\ndrop table if exists test_hudi_dt; \n\ncreate table test_hudi_dt ( \n    id int, \n    name string, \n    price double,\n    ds string)\nusing hudi    \nprimary key (id)\npartitioned by (ds)\nlifeCycle 300\n\n\ncreate table test_hudi_dt ( \n    id int, \n    name string, \n    price double,\n    ds string)\nusing hudi \npartitioned by (ds)\ntblproperties (\n  type = \'cow\',\n  primaryKey = \'id\'\n);\n\nselect hex(binary(\"hello\"))\n\nSELECT \'%SystemDrive%/Users/John\' ilike \'/%SYSTEMDrive/%//Users%\' ESCAPE \'/\';\n\n\nshow create table test_hudi_dt\n\nSELECT shiftleft(1, 120)\n\nSELECT ShiftRight(4, 1);\n\nSELECT date_format(\'2016-04-08\', \'yyyy.ttt.dd\');\n\nSELECT from_utc_timestamp(CURRENT_TIMESTAMP(), \'GMT+1\');\n\nSELECT regexp_extract(\'dremio user 123\', \'[0-9]+\', 0)\n\nmsck repair table test_hudi_dt\n\nshow partitions test_hudi_dt PARTITION(ds=\'2021-05-05\');\n\ninsert into table test_hudi_dt values(1, \'zhangsan\', 20, \'2021-05-05\');\ninsert into table test_hudi_dt values(2, \'wangwu\', 18, \'2021-05-05\');\ninsert into table test_hudi_dt values(1, \'zhangsan\', 22, \'2021-05-06\');\ninsert into table test_hudi_dt values(3, \'zhangsan\', 30, \'2021-05-05\');\n\n\ninsert into table test_hudi_dt values(3, \'xxx\', 22, \'2021-05-06\');\n\n\nupdate test_hudi_dt set price=30 where id=1 and ds=\'2021-05-05\'\n\nselect * from test_hudi_dt where ds like \'2021-05-%\'\n\ndelete from test_hudi_dt where id=3  and ds=\'2021-05-06\'\n\n\n\nALTER TABLE test_hudi_dt DROP PARTITION (ds=\'2021-05-05\');\n\nshow create table test_hudi_dt\n\nshow partitions bigdata.test_hudi_dt PARTITION(ds=\'2021-05-05\')\n\nCALL system.show_commits(table=>\'test_hudi_dt\')\n\nCALL system.show_commits_metadata(table=>\'test_hudi_dt\')\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-03 10:47:44', '2022-06-22 16:01:54', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (133, 'bigdata', 1, 18, 'hudi_demo', 'job-56751358-4d81-4d24-862e-638a288313a5', 'hangzhou-spark-3.2', 'hudi_demo', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-07 13:28:30\n--********************************************************************--\n\n\ndrop table if exists bigdata.test_hudi_demo;\n\ncreate table bigdata.test_hudi_demo ( \n    id int, \n    name string, \n    price double,\n    ds string)\nusing hudi    \nprimary key (id)\npartitioned by (ds)\nlifeCycle 300;\n\nshow create table test_hudi_demo;\n\n\ninsert into table bigdata.test_hudi_demo select 1, \'zhangsan\', 20, \'20210810\';\ninsert into table test_hudi_demo select 1, \'zhangsan\', 30, \'20210810\';\ninsert into table bigdata.test_hudi_demo select 3, \'wangwu\', 20, \'20210810\';\ninsert into table test_hudi_demo select 1, \'zhangsan\', 40, \'20210811\';\n\nselect * from bigdata.test_hudi_demo where ds = \'20210811\'\n\ncall system.show_metadata_table_files(table => \'test_hudi_demo\');\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-07 13:28:31', '2022-09-09 14:26:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (135, 'bigdata', 1, 18, 'hudi_mor', 'job-4ffd8a6b-7d62-4e33-b450-78ef222c0ed9', 'hangzhou-spark-3.2', 'hudi_mor', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-13 11:13:46\n--********************************************************************--\n\nDROP TABLE if exists test_huid_stream_json_dt;\n\ncreate table test_huid_stream_json_dt ( \n    id string, \n    userid string,\n    city string,\n    kafka_topic string,\n    kafka_timestamp timestamp,\n    ds string)\nusing hudi    \nprimary key (id) with MOR \npartitioned by (ds)\nlifeCycle 300\n\nSELECT INITCAP(\'a guide to data lakehouses\')\n\nselect timestamp(date \'2022-01-01\' + INTERVAL 2 day),\ntimestamp(date \'2022-01-01\' + INTERVAL 2 month),\ntimestamp(date \'2022-01-01\' + INTERVAL 2 year)\n\n\nselect current_timestamp, current_timestamp()\n\nselect a, b, typeof(nums) from (\nSELECT a, b, row_number() OVER (PARTITION BY a ORDER BY b) as nums FROM VALUES (\'A1\', 2), (\'A1\', 1), (\'A2\', 3), (\'A1\', 1) tab(a, b) \n) c where a = \'ds\'\n\n\n\n\nshow create table test_huid_stream_json_dt\n\nselect  date_format(current_timestamp, \"yyyyMMddHH\")\n\nselect * from test_huid_stream_json_dt\n\n\nDROP TABLE if exists test_huid_stream_csv_dt;\n\ncreate table test_huid_stream_csv_dt ( \n    id string, \n    userid string,\n    city string,\n    kafka_topic string,\n    kafka_timestamp timestamp,\n    ds string)\nusing hudi    \nprimary key (id) with MOR \npartitioned by (ds)\nlifeCycle 300\n\nselect * from test_huid_stream_csv_dt where ds like \'202109%\'\n\n\nalter table bigdata.test_demo1_test touch\n\nalter table bigdata.test_child_dt touch partition (ds=20210913)\n\n\nshow create table kafka_log_dt\n\ndrop table kafka_log_dt\ncreate table drop kafka_log_dt ( \n    id string, \n    message string,\n    ds string)\nusing hudi  \nprimary key (id) with MOR \nPARTITIONED BY (ds)\nlifeCycle 100\ncomment \'hudi demo\'\n\nselect * from kafka_log_dt where ds like \'20211229%\'\n\n', 'spark_sql', 'bizdate=$[yyyyMMddHH-1h]\nbizdate12=$[yyyyMMddHH-1h]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-13 11:13:47', '2022-07-14 19:06:54', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (136, 'stream_bigdata', 1, 19, 'kafka_stream_json', 'job-36e6c257-4445-4203-9011-e300d61b9592', 'hangzhou-spark-3.2', 'kafak stream', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-14 14:05:59\n--********************************************************************--\n\nCREATE Stream TABLE tdl_kafka_message (\n    id string,\n    userid string,\n    city \'/ext/city\' string,\n    kafka_topic string,\n    kafka_timestamp timestamp\n)\nWITH (\n    type = \'kafka\',\n    subscribe = \'hudi_topic\',\n    startingOffsets = \'latest\',\n    format = \'json\',\n    includeHeaders = \'true\',\n    maxOffsetsPerTrigger = 1000,\n    kafka.bootstrap.servers = \'10.10.9.14:9092\'\n);\n\ninsert into bigdata.test_huid_stream_json_dt \nSELECT id, userid, city, kafka_topic, kafka_timestamp, date_format(current_timestamp, \"yyyyMMddHH\") ds \nFROM tdl_kafka_message;\n\n--{id:\'16\', userid:\'qianxia\', ext:{city:\'hangzhou\'}}\n\n\n', 'spark_stream_sql', NULL, NULL, '怀信#huaixin', '怀信#huaixin', NULL, 1, 0, '2021-09-16 11:24:08', NULL, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-14 14:06:00', '2021-09-16 11:24:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (137, 'bigdata', 1, 10, 'python_demo', 'job-ed7fcda4-9b26-40f1-87c5-58a74dd33ac1', 'hangzhou-spark-3.2', 'python_demo', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-09-14 16:53:20\n#********************************************************************\n\ndef main(sparkSession):\n    print(\"hello world\")\n    sparkSession.sql(\"select name, _metadata.* from test_user11_dt where ds = \'20211203\'\").show()\n\n	\n\n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-14 16:53:21', '2022-07-27 16:26:45', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (139, 'stream_bigdata', 1, 19, 'kafka_stream_text', 'job-c7837bb3-3f7c-44b4-813b-41e130f32b06', 'hangzhou-spark-3.2', 'kafka_stream_text', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-15 12:20:31\n--********************************************************************--\n\n-- https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html\n\nCREATE Stream TABLE tdl_kafka_message (\n    message string,\n    kafka_topic string,\n    kafka_timestamp timestamp\n)\nWITH (\n    type = \'kafka\',\n    subscribe = \'hudi_topic_text\',\n    startingOffsets = \'latest\',\n    format = \'text\',\n    includeHeaders = \'true\',\n    maxOffsetsPerTrigger = 1000,\n    kafka.bootstrap.servers = \'10.10.9.14:9092\'\n);\n\ninsert into bigdata.test_huid_stream_csv_dt \nselect items[0] as id, items[1] as userid, items[2] as city, kafka_topic, kafka_timestamp, ds from (\n    SELECT split(message, \',\') as items, kafka_topic, kafka_timestamp, date_format(current_timestamp, \"yyyyMMddHH\") ds \n    FROM tdl_kafka_message\n)\n\n--15,qianxiao,hangzhou\n\n', 'spark_stream_sql', NULL, NULL, NULL, '怀信#huaixin', NULL, 0, 0, NULL, NULL, NULL, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-09-15 12:20:32', '2021-09-15 18:56:07', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (141, 'stream_bigdata', 1, 19, 'kafka_stream_json', 'job-36e6c257-4445-4203-9011-e300d61b9592', 'spark3.2-stream-cluster', 'kafak stream', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-09-14 14:05:59\n--********************************************************************--\n\nCREATE Stream TABLE tdl_kafka_message (\n    id string,\n    userid string,\n    city \'/ext/city\' string, \n    kafka_topic string,\n    kafka_timestamp timestamp\n)\nWITH (\n    type = \'kafka\',\n    subscribe = \'hudi_topic\', \n    format = \'json\',\n    includeHeaders = \'true\',\n    maxOffsetsPerTrigger = 1000,\n    failOnDataLoss = \'false\',\n    kafka.bootstrap.servers = \'10.5.20.12:9092\'\n);\n\n\ninsert into bigdata.test_huid_stream_json_dt\nSELECT id, userid, city, kafka_topic, kafka_timestamp, date_format(current_timestamp, \"yyyyMMddHH\") ds \nFROM tdl_kafka_message;\n\n-- {id:\'19\', userid:\'qianxia\', ext:{city:\'hangzhou\'}}\n\n-- bin/kafka-topics.sh --create --partitions 2 --replication-factor 1 --topic hudi_topic --bootstrap-server 10.5.20.12:9092\n\n-- bin/kafka-topics.sh --delete --topic hudi_topic --bootstrap-server 10.5.20.12:9092\n\n\n-- 生产消息\n-- bin/kafka-console-producer.sh --topic hudi_topic --bootstrap-server 10.5.20.12:9092 --property \"parse.key=true\" --property \"key.separator=:\"\n\n\n\n', 'spark_stream_sql', NULL, NULL, NULL, '怀信#huaixin', NULL, 0, 0, NULL, NULL, NULL, 'normal', 0, '0', 'p2', '', 'period', 0, 'sms,dingding', 2, 10, '2021-09-16 10:44:47', '2022-10-05 16:39:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (155, 'first', 1, 24, 'demo', 'job-337fe9b0-0fab-42fd-9228-7a5036e907cd', 'hangzhou-spark-3.2', 'demo', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-10-28 13:24:47\n--********************************************************************--\n\nselect * from bigdata.test_demo_test\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-10-28 13:24:47', '2021-10-28 13:28:02', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (162, 'bigdata', 1, 15, 'datax-jdbc', 'job-842ba0f8-8c2d-459c-9794-3bb617d356db', 'hangzhou-spark-3.2', 'datax-jdbc', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-11-08 14:31:00\n--********************************************************************--\n\ndrop table hive_dtunnel_datasource;\nCREATE TABLE hive_dtunnel_datasource (\n    id bigint, \n    code string,\n    name string,\n    `type` string,\n    description string,\n    config string,\n    creater string,\n    modifier string,\n    gmt_created timestamp,\n    gmt_modified timestamp,\n    tenant_id string\n)\nCOMMENT \'数据源管理\'\nLIFECYCLE 10;\n\ndrop table hive_datasource4;\n\ndatatunnel source(\"mysql\") options(\n    username=\"superior\",\n    password=\"superior2022\",\n    host=\'139.217.237.72\',\n    port=3306,\n    databaseName=\'superior_test\', tableName=\'meta_datasource\', columns=[\"*\"])\n    sink(\"hive\") options(databaseName=\"bigdata\", tableName=\'hive_datasource4\', writeMode=\'overwrite\', columns=[\"*\"]);\n\nexplain extended select * from hive_dtunnel_datasource limit 10\n\ndatatunnel \nsource(\'mysql\') options(\n    username=\'dataworks\',\n    password=\'dataworks2021\',\n    host=\'10.5.20.20\',\n    port=3306,\n    resultTableName=\'tdl_dc_job\',\n    databaseName=\'dataworks\', tableName=\'dc_job\', columns=[\'*\'])\ntransform = \'select * from tdl_dc_job where type=\"spark_sql\"\'\nsink(\'log\') options(numRows = 10)\n\n\n\ndatatunnel source(\"hive\") options(\n    databaseName=\'bigdata\',\n    tableName=\'hive_dtunnel_datasource\', \n    columns=[\'id\', \'code\', \'type\', \'description\', \'config\', \'gmt_created\', \'gmt_modified\', \'creater\', \'modifier\'])\nsink(\"mysql\") options(\n    username=\"dataworks\",\n    password=\"dataworks2021\",\n    host=\'10.5.20.20\',\n    port=3306,\n    databaseName=\'dataworks\', \n    tableName=\'dc_datax_datasource_copy1\', \n    writeMode=\'overwrite\',\n    truncate=true,\n    columns=[\'id\', \'code\', \'dstype\', \'description\', \'config\', \'gmt_created\', \'gmt_modified\', \'creater\', \'modifier\'])\n        \n        \nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=1,\n  upperBound=12,\n  numPartitions=12\n)\nSINK(\"hive\") OPTIONS (\n  databaseName = \"aoteledemo\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210816\"\n)\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-11-08 14:31:00', '2022-09-24 13:36:05', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (170, 'bigdata', 1, 10, 'koalas_demo_dt', 'job-7082765d-6d49-4301-a472-df2a0f25b4b3', 'hangzhou-spark-3.2', 'koalas_demo', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-11-15 18:11:33\n#********************************************************************\n\nimport pandas as pd\nimport databricks.koalas as ks\n\ndef main(sparkSession):\n    print(pd.__version__)\n    demo = ks.read_csv(\'/user/datawork/users/${userId}/demo.csv\');\n    print(demo)\n	', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 1, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'trigger', 6, NULL, NULL, NULL, '2021-11-15 18:11:34', '2021-12-05 22:13:54', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (180, 'bigdata', 1, 17, 'spark_create_table', 'job-723e610f-d258-4d4a-9024-54b8c192ba3e', 'hangzhou-spark-3.2', 'spark_create_table', '--********************************************************************--\n-- author:      千潇#qianxiao\n-- create time: 2021-11-23 15:12:43\n--********************************************************************--\n\ndrop table if exists spark_demo_dt;\n\nCREATE TABLE spark_demo_dt (\n    name STRING, \n    num int,\n    ds String\n) \nusing orc\nPARTITIONED BY (ds)\nLIFECYCLE 2; \n\nINSERT INTO\n    TABLE spark_demo_dt partition(ds = \'20211123\')\nVALUES (\'zhangsan\', 23);\n\nselect * from spark_demo_dt where ds=\'20211123\'\n\nshow create table spark_demo_dt\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-11-23 15:12:43', '2021-12-04 22:34:20', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (184, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '方悟#fangwu', '怀信#huaixin', '', 1, 0, '2021-12-05 13:50:53', 0, 0, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-12-05 13:49:28', '2021-12-28 13:02:56', '方悟#fangwu', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (185, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")  \n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '方悟#fangwu', '怀信#huaixin', '', 1, 0, '2021-12-05 13:50:51', 0, 0, 'normal', 1, '0', 'p2', 'huaixin', 'period', 6, NULL, NULL, NULL, '2021-12-05 13:50:05', '2022-10-15 17:15:01', '方悟#fangwu', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (186, 'bigdata', 1, 2, 'demo_proxy_dj', 'job-c21d48f2-8cf9-430f-a89c-835e9ea30770', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n \ndef main(sparkSession):\n    print(\"hello spark\")\n    sql = \"insert overwrite table test_child_dt partition(ds) select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    sparkSession.sql(sql)\n\n    sparkSession.sql(\"select * from test_child_dt where ds=\'${bizdate}\'\").show()\n    \n    \n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '方悟#fangwu', '怀信#huaixin', '', 0, 0, '2021-12-05 13:50:49', 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-12-05 13:50:43', '2021-12-05 13:50:49', '方悟#fangwu', '方悟#fangwu');
INSERT INTO `meta_job` VALUES (187, 'bigdata', 1, 10, 'koalas_demo_dt', 'job-7082765d-6d49-4301-a472-df2a0f25b4b3', 'hangzhou-spark-3.2', 'koalas_demo', '#********************************************************************\n# author:      千潇#qianxiao\n# create time: 2021-11-15 18:11:33\n#********************************************************************\n\nimport pyspark.pandas as pd\n\ndef main(sparkSession):\n    demo = pd.read_csv(\'/user/dataworks/users/${userId}/files/demo.csv\');\n    print(demo)\n	', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'trigger', 6, NULL, NULL, NULL, '2021-12-05 22:13:54', '2021-12-06 19:15:46', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (200, 'bigdata', 1, 15, 'datax-kafka', 'job-f29bbf6a-4760-4853-9c60-9fc7862dce1f', 'hangzhou-spark-3.2', 'kafka', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2021-12-10 17:37:19\n--********************************************************************--\n\ndatax reader(\"hive\") options(\n    databaseName=\'bigdata\',\n    tableName=\'wangying_test1210_dt\', \n    condition=\"ds=\'${bizdate}\'\",\n    column=[\"name\",\"num\",\"city\",\"street\"]\n )\nwriter(\"kafka\") options(\n    topic=\'dzlog-test\',\n    bootstrap.servers=\'10.5.20.16:9092,10.5.20.17:9092,10.5.20.18:9092\');\n\ndrop table kafka_log1_dt\n\ndatax reader(\"kafka\") options(\n    subscribe=\'test2,test_other\',\n    kafka.bootstrap.servers=\'10.5.20.16:9092,10.5.20.17:9092,10.5.20.18:9092\'\n )\n\nwriter(\"hive\") options(\n    databaseName=\'bigdata\',\n    tableName=\'kafka_log1_dt\');\n    \n\ndrop table bigdata.kafka_log1_dt_ro;\ndrop table bigdata.kafka_log1_dt_rt;\ndrop table bigdata.kafka_log1_dt;\ncreate table bigdata.kafka_log1_dt (\n    id string comment \"默认为kafka key，如果key为空，值为timestamp\",\n    message string comment \"采集消息\",\n    kafka_timestamp bigint,\n    ds string comment \"小时分区：yyyyMMddHH\",\n    kafka_topic string comment \"subscribe可以配置多个topic，通过kafka_topic分区消息\")\nusing hudi    \nOPTIONS (\n   primaryKey=\'id\',\n   type=\'mor\',\n   hoodie.parquet.compression.codec=\'snappy\',\n   hoodie.payload.event.time.field=\'kafka_timestamp\',\n   hoodie.payload.ordering.field=\'kafka_timestamp\',\n   hoodie.datasource.write.precombine.field=\'id\',\n   hoodie.cleaner.commits.retained=24\n)\nPARTITIONED BY (ds,kafka_topic)\ncomment \'hudi demo\';\n    \n    ', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-12-10 17:37:20', '2022-02-25 15:32:29', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (203, 'bigdata', 1, 2, 'dsd_dd_hj', 'Job-bCOzLTzLeCFZsjZInNxDMeSkO5ieCAYM', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      怀信#huaixin\n# create time: 2021-12-11 00:15:22\n#********************************************************************\n\ndef main(sparkSession):\n    print(\"dd\")\n	', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 0, 0, '2021-12-11 00:17:21', 1, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-12-11 00:15:23', '2022-09-10 00:44:07', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (229, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 3, '2022-04-17 13:54:52', 0, 0, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-12-28 13:02:17', '2022-10-15 17:14:52', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (230, 'bigdata', 1, 10, 'python-lineage', 'Job-szfUJQietKs2zeEyrgmmyzyGl4XL9pzx', 'hangzhou-spark-3.2', 'lineage', '#********************************************************************\n# author:      怀信#huaixin\n# create time: 2021-12-28 13:54:55\n#********************************************************************\n\nad\n\ndef main(sparkSession):\n    sql = \"select name, num * 10 as num, ds from test_demo_dt where ds=\'${bizdate}\'\"\n    df = sparkSession.sql(sql)\n\n    df = df.withColumn(\'num\', df[\"num\"] + 123)\n    \n    df.createOrReplaceTempView(\"tdl_result_test\")\n    \n    sparkSession.sql(\"insert overwrite table test_child_dt partition(ds) select * from tdl_result_test\")', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2021-12-28 13:54:56', '2022-09-06 16:55:43', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (232, 'bigdata', 1, 2, 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'hangzhou-spark-3.2', 'dd', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n\ndef main(sparkSession):\n    print(\"hello spark\")\n\n', 'spark_python', 'bizdate=$[yyyyMMdd-1d]', '2022-10-17', '怀信#huaixin', '怀信#huaixin', '', 0, 3, '2022-10-15 17:15:01', 1, 0, 'normal', 0, '0', 'p2', 'huaixin', 'period', 2, 'sms,dingding', 2, 2, '2021-12-29 10:16:18', '2022-10-15 17:15:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (254, 'bigdata', 1, 17, 'analyze', 'Job-Gvwi9cE74Z72d1FsSjGX5vU7qGKTPkhS', 'hangzhou-spark-3.2', 'analyze', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-01-04 16:10:46\n--********************************************************************--\n\ndrop table test_demo_test;\nCREATE TABLE test_demo_test (name string, age int)\nusing orc\nLIFECYCLE 10;\n\nINSERT INTO table test_demo_test VALUES ( null, 23);\nINSERT INTO table test_demo_test VALUES ( \'\', 25);\nINSERT INTO table test_demo_test VALUES ( \'zhangsan\', 23);\n\nANALYZE TABLE bigdata.test_demo_test COMPUTE STATISTICS FOR COLUMNS name, age;\n\nDESC EXTENDED test_demo_test name;\n\nselect * from test_demo_test\n\ndrop table analyze_demo_dt;\nCREATE TABLE analyze_demo_dt \n(name STRING, num int, ds STRING)\nusing parquet\nPARTITIONED BY (ds)\nLIFECYCLE 2;\n\nINSERT INTO TABLE analyze_demo_dt partition(ds = \'20210622\') VALUES (\'zhangsan\', 23);\n\nANALYZE TABLE analyze_demo_dt PARTITION (ds = \'20210622\') COMPUTE STATISTICS FOR COLUMNS name, num;\n\nDESC EXTENDED analyze_demo_dt PARTITION (ds = \'20210622\');\n\n\nselect *\nfrom\n	superior.superior_test.meta_job\n\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-01-04 16:10:47', '2022-09-10 00:52:18', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (258, 'bigdata', 1, 83, 'iceberg-demo', 'Job-fFi3vgoIKa5QBUmngCu4C3UKdUpO1eCG', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-03-11 22:51:20\n--********************************************************************--\n\nCREATE TABLE if not exists iceberg.bigdata.ice_arctic_demo (id bigint, data string) \nUSING iceberg\nlifecycle 10 \n\ninsert into iceberg.bigdata.ice_arctic_demo values(12, \'20120315\')\n\nSELECT * FROM iceberg.bigdata.ice_arctic_demo.snapshots;\nSELECT * FROM iceberg.bigdata.ice_arctic_demo.history;\nSELECT * FROM iceberg.bigdata.ice_arctic_demo.files;\nSELECT * FROM iceberg.bigdata.ice_arctic_demo.manifests;\n\nSELECT * FROM iceberg.bigdata.ice_arctic_demo\n\nhttps://iceberg.apache.org/docs/latest/spark-procedures/\n\n\nCALL spark_catalog.system.ancestors_of(\'iceberg.bigdata.ice_arctic_demo\')\n\nCALL spark_catalog.system.rewrite_manifests(\'iceberg.bigdata.ice_arctic_demo\')\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '怀信#huaixin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-03-11 22:51:21', '2022-06-09 11:48:16', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (259, 'bigdata', 1, 86, 'ODS_T01', 'Job-iWJdBPS6bmwHfWA9wZ3W0fFmcdZIn0lY', 'hangzhou-spark-3.2', 'TEST ODS', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-07-27 09:57:46\n--********************************************************************--\nselect name, num, ds from bigdata.test_user12_dt where ds=\'20211203\'\n\nINSERT INTO TABLE bigdata.test_user12_dt VALUES (\'wangwu\', 25, \'20211203\');\n\nselect * from aoteledemo.dim_store_ware_os limit 10\n\nSELECT current_timestamp\n\n\n\n\ndatatunnel source(\"mysql\") options(\n    username=\"root\",\n    password=\"Password@12345\",\n    host=\'139.217.237.72\',\n    port=3306,\n    databaseName=\'hive\', tableName=\'meta_catalog\', columns=[\"*\"])\n    sink(\"hive\") options(databaseName=\"bigdata\", tableName=\'ods_meta_catalog_1\', writeMode=\'overwrite\', columns=[\"*\"]);\n    \n    \ninsert OVERWRITE bigdata.csv_test_mt values(2,\'李四\',\'202209\')\n\nselect  * from bigdata.csv_test_mt limit 10\n\n\nload data \'/user/superior/users/buxuan/EXCEL文/ table tdl_spark_test options(header=\'true\');\nselect * from tdl_spark_test ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'trigger', 6, NULL, NULL, NULL, '2022-07-27 09:57:47', '2022-09-22 22:56:19', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (260, 'bigdata', 1, 85, 'dtunnel-jdbc', 'Job-d0AGtggSXUo6TejKCS9tXHPOQcgUdNKK', 'hangzhou-spark-3.2', 'jdbc', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-07-28 23:46:02\n--********************************************************************--\n\nDROP TABLE IF EXISTS ods_meta_catalog;\nCREATE TABLE ods_meta_catalog  (\n  ctlg_id bigint,\n  name varchar(256) ,\n  tenant_id varchar(32),\n  ds_type varchar(32),\n  description varchar(4000),\n  location_uri varchar(4000),\n  create_time int,\n  update_time int,\n  meta_md5 varchar(64),\n  origin_name varchar(256)\n)\nCOMMENT \'目录表\'\nLIFECYCLE 10;\n\ndatatunnel source(\"mysql\") options(\n    username=\"arctic\",\n    password=\"arctic2022\",\n    host=\'10.5.20.21\',\n    port=3306,\n    databaseName=\'arctic\', tableName=\'meta_catalog\', columns=[\"*\"])\n    sink(\"hive\") options(databaseName=\"bigdata\", tableName=\'ods_meta_catalog_1\', writeMode=\'overwrite\', columns=[\"*\"]);\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-07-28 23:46:03', '2022-09-06 16:51:56', '不玄#buxuan', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (263, 'bigdata', 1, 87, 'mysql2hive', 'Job-PAETda5TURZc0jcSffHyKyFCwO0Jkd9a', 'hangzhou-spark-3.2', '创建hive表，并同步数据库', '--********************************************************************--\n-- author:      林庆贤#zerolin\n-- create time: 2022-08-01 07:57:57\n--********************************************************************--\n\ndrop table if exists dwd_scm_purchase_order_ware_d;\ncreate table dwd_scm_purchase_order_ware_d(\n        po_no	string,\n        po_item_no	string,\n        group_id	string,\n        group_name	string,\n        vender_id	string,\n        vender_name	string,\n        store_code	string,\n        store_name	string,\n        matnr	string,\n        item_num	string,\n        ware_name	string,\n        purchase_tax_code	string,\n        purchase_tax_rate	string,\n        promotion_title	string,\n        promotion_schedule_no	string,\n        promotion_level	string,\n        promotion_type	string,\n        first_flag	string,\n        inner_supplier_code	string,\n        inner_supplier_name	string,\n        inner_supplier_type	string,\n        delivery_type	string,\n        supplier_code	string,\n        supplier_name	string,\n        po_biz_type	string,\n        po_type	string,\n        po_source	string,\n        po_item_status	string,\n        close_flag	string,\n        reverse_flag	string,\n        purchase_time	string,\n        expect_dc_delivery_date	string,\n        expect_store_delivery_date	string,\n        receive_complete_flag	string,\n        receive_time	string,\n        original_book_num	string,\n        book_num	string,\n        book_unit	string,\n        book_cf	string,\n        supplier_confirm_purchase_num	string,\n        purchase_unit	string,\n        purchase_cf	string,\n        purchase_taxed_price	string,\n        gift_num	string,\n        base_unit	string,\n        store_type	string,\n        sell_type	string,\n        erp_no	string,\n        dt	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nLIFECYCLE 30;\n\ndatatunnel source(\"mysql\") options(\n    username=\"itdd\",\n    password=\"itdd2022\",\n    host=\'47.109.18.82\',\n    port=3306,\n    databaseName=\'bi\', tableName=\'dwd_scm_purchase_order_ware_d\', columns=[\"*\"])\n    sink(\"hive\") options(databaseName=\"bigdata\", tableName=\'dwd_scm_purchase_order_ware_d\', writeMode=\'overwrite\', columns=[\"*\"]);\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '林庆贤#zerolin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-01 15:57:57', '2022-08-02 18:46:14', '林庆贤#zerolin', '林庆贤#zerolin');
INSERT INTO `meta_job` VALUES (265, 'bigdata', 1, 87, 'co', 'Job-a39gg33SKhlX0i2GKLEhrravGI9zkmeq', 'hangzhou-spark-3.2', '11', '--********************************************************************--\n-- author:      林庆贤#zerolin\n-- create time: 2022-08-05 02:19:25\n--********************************************************************--\n\nselect * from dim_ware_purchase_category limit 2 ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '林庆贤#zerolin', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-05 10:19:25', '2022-08-06 13:33:47', '林庆贤#zerolin', '林庆贤#zerolin');
INSERT INTO `meta_job` VALUES (268, 'aoteledemo', 1, 88, 'test', 'Job-obbWRuaXaS6r3OHbhx6cre9Jmdh7yptL', 'hangzhou-spark-3.2', '测试函数', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-09 06:19:14\n--********************************************************************--\n\nselect * from bigdata.csv_test_mt;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, 'demo#demo', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-09 14:19:14', '2022-09-28 23:06:18', 'demo#demo', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (270, 'aoteledemo', 1, 88, 'fang_test', 'Job-CONtizkfbok9gBs49doG17wpe3D12OaO', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 03:15:25\n--********************************************************************--\nselect * from ads_pay_ord_df limit 10;\n\n\n\ncreate table tdl_ads_order_pay as\nselect t1.dt as time,\nyear(t1.dt) as year,\nmonth(t1.dt) as month,\nday(t1.dt) as day,\n       (decode t1.store_code,\'80\',\'折扣仓\',\n		   \'81\',\'门店\',\n		   \'10\',\'大仓\',\n		   \'00\' ,\'总部\') as store_type,\n        t1.store_code as store_code,\n        t2.purchase_category1_name as purchase_category1,\n       t1.matnr,\n       t1.ware_name ware_name,\n       (if(locate(\'自有品牌\', t3.supplier_name) > 0, \'自有品牌\', \'外购品牌\')) as brand_type,\n        province_name as province_name,\n        city_area_name as cityArea_name,\n        district_name as district_name,\n      sum(case when refund_flag = 0 then actual_sale_taxed_amt when refund_flag = 1 then -actual_sale_taxed_amt end)    as sale_have,\n       sum(case when refund_flag = 0 then actual_sale_untaxed_amt when refund_flag = 1 then -actual_sale_untaxed_amt end)  as sale_no,\n       sum(case when refund_flag = 0 then cost_taxed_amt when refund_flag = 1 then -cost_taxed_amt end)    as cost_have,\n       sum(case when refund_flag = 0 then cost_untaxed_amt when refund_flag = 1 then -cost_untaxed_amt end)  as cost_no,\n       sum(case when refund_flag = 0 then sale_num when refund_flag = 1 then -sale_num end)    as sale_num\n       from dwd_sale_posting_order_ware_post_d_view as t1\nleft join dim_ware_purchase_category t2\non t1.matnr = t2.matnr\nleft join dim_store_ware_os t3 on t2.matnr = t3.matnr\nleft join dim_store_new t4 on  t1.store_code = t4.store_code\ngroup by dt,store_type,t1.store_code,purchase_category1,t1.matnr,t1.ware_name,brand_type,province_name,cityArea_name,district_name', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, 'demo#demo', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-10 11:15:26', '2022-08-11 15:35:16', 'demo#demo', 'demo#demo');
INSERT INTO `meta_job` VALUES (290, 'aoteledemo', 1, 116, 'DDL_DIM_STORE_NEW', 'job-b3e48734-c8a8-41ba-b634-1157964d68a8', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:08:53\n--********************************************************************--\n\n\n--门店维度表\ncreate table dim_store_new(\n        store_code	string,\n        store_id	string,\n        store_name	string,\n        company_id	string,\n        company_name	string,\n        group_id	string,\n        group_name	string,\n        vender_id	string,\n        vender_name	string,\n        group_tree_code1	string,\n        group_tree_name1	string,\n        group_tree_code2	string,\n        group_tree_name2	string,\n        group_tree_code3	string,\n        group_tree_name3	string,\n        group_tree_code4	string,\n        group_tree_name4	string,\n        large_area_code	string,\n        large_area_name	string,\n        management_area_code	string,\n        management_area_name	string,\n        province_code	string,\n        province_name	string,\n        city_area_code	string,\n        city_area_name	string,\n        district_name	string,\n        district_code	string,\n        store_address	string,\n        address_longitude	string,\n        address_latitude	string,\n        store_manager_emp_id	string,\n        store_type	string,\n        biz_type	string,\n        store_status	string,\n        manage_type	string,\n        front_avaliable_flag	string,\n        back_avaliable_flag	string,\n        fwh_flag	string,\n        test_flag	string,\n        dfc_flag	string,\n        dfc_date	string,\n        os_flag	string,\n        os_open_date	string,\n        offline_store_open_date	string,\n        store_close_flag	string,\n        offline_store_close_date	string,\n        yn	string,\n        create_time	string,\n        update_time	string,\n        md_flag	string,\n        post_code	string,\n        store_tel	string,\n        fax_number	string,\n        store_open_flag	string,\n        store_business_district	string,\n        offline_store_name	string,\n        category_flag	string,\n        group_tree_code5	string,\n        group_tree_name5	string,\n        group_tree_code6	string,\n        group_tree_name6	string,\n        vender_group_id	string,\n        store_area	string,\n        comparable_flag	string,\n        comparison_flag	string,\n        examine_flag	string,\n        franchisee_type	string,\n        store_life_status	string,\n        group_tree_layers	string,\n        store_business_district_name	string,\n        group_tree_empid1	string,\n        group_tree_empname1	string,\n        group_tree_empid2	string,\n        group_tree_empname2	string,\n        group_tree_empid3	string,\n        group_tree_empname3	string,\n        group_tree_empid4	string,\n        group_tree_empname4	string,\n        group_tree_empid5	string,\n        group_tree_empname5	string,\n        group_tree_empid6	string,\n        group_tree_empname6	string,\n        store_manager_emp_name	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 10:57:41', '2022-08-11 07:16:41', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (291, 'aoteledemo', 1, 116, 'DDL_DIM_STORE_WARE_OS', 'job-958410c5-0729-42aa-b494-b82ff24166f0', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 08:05:51\n--********************************************************************--\n\n--门店商品维度表\ncreate table dim_store_ware_os(\n    group_id	string,\n    store_code	string,\n    matnr	string,\n    group_name	string,\n    store_name	string,\n    item_num	string,\n    ware_name	string,\n    offline_ware_name	string,\n    offline_original_price	string,\n    offline_current_price	string,\n    status_code	string,\n    status_name	string,\n    sell_type	string,\n    sell_type_name	string,\n    clearing_way	string,\n    manage_way	string,\n    can_order	string,\n    can_return	string,\n    can_sale	string,\n    can_sale_return	string,\n    can_exhibit	string,\n    order_unit	string,\n    purchase_unit	string,\n    purchase_tax_code	string,\n    purchase_tax_rate	string,\n    purchase_tax_price	string,\n    purchase_delivery_type	string,\n    supplier_code	string,\n    supplier_name	string,\n    inner_supplier_code	string,\n    inner_supplier_name	string,\n    create_time	string,\n    update_time	string,\n    spec_type	string,\n    spec_qty	string,\n    spec_unit	string,\n    basic_unit	string,\n    basic_unit_desc	string,\n    package_num	string,\n    brand_id	string,\n    brand_name	string,\n    brand_business_id	string,\n    brand_business_name	string,\n    brand_flag	string,\n    ware_flavor	string,\n    ware_create_time	string,\n    purchase_category_layers	string,\n    purchase_category1_code	string,\n    purchase_category1_name	string,\n    purchase_category2_code	string,\n    purchase_category2_name	string,\n    purchase_category3_code	string,\n    purchase_category3_name	string,\n    purchase_category4_code	string,\n    purchase_category4_name	string,\n    purchase_category5_code	string,\n    purchase_category5_name	string,\n    operation_category_layers	string,\n    operation_category1_code	string,\n    operation_category1_name	string,\n    operation_category2_code	string,\n    operation_category2_name	string,\n    operation_category3_code	string,\n    operation_category3_name	string,\n    operation_category4_code	string,\n    operation_category4_name	string,\n    operation_category5_code	string,\n    operation_category5_name	string,\n    matkl	string,\n    super_flag	string,\n    exclude_flag	string,\n    service_flag	string,\n    shopping_bag_flag	string,\n    ware_life	string,\n    ware_life_unit	string,\n    estimate_type	string,\n    estimate_type_name	string,\n    ware_tax_rate	string,\n    product_place	string,\n    id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifecycle 300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 11:03:53', '2022-08-11 07:16:54', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (294, 'aoteledemo', 1, 116, 'DDL_DIM_WARE_NEW', 'job-32dfd18f-1b94-40d6-96ec-7e42a68eecf8', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:07:21\n--********************************************************************--\n\n-- 商品维度表\ncreate table dim_ware_new(\n        group_id	string,\n        matnr	string,\n        group_name	string,\n        item_num	string,\n        ware_name	string,\n        offline_ware_name	string,\n        ware_en_name	string,\n        spec_type	string,\n        spec_qty	string,\n        spec_unit	string,\n        weight	string,\n        net_weight	string,\n        ware_status	string,\n        basic_unit	string,\n        basic_unit_desc	string,\n        weight_flag	string,\n        ware_type	string,\n        ware_type_code	string,\n        ware_life	string,\n        ware_life_unit	string,\n        ware_tag	string,\n        ware_tag_time	string,\n        ware_tax_rate	string,\n        brand_id	string,\n        brand_name	string,\n        brand_business_id	string,\n        brand_business_name	string,\n        brand_flag	string,\n        seasonal_flag	string,\n        seasonal_start_date	string,\n        seasonal_end_date	string,\n        create_time	string,\n        update_time	string,\n        estimate_type	string,\n        estimate_type_name	string,\n        matkl	string,\n        package_num	string,\n        out_brand_id	string,\n        market_time	string,\n        extend_infos	string,\n        storage_type	string,\n        produce_area	string,\n        img_detail_flag	string,\n        img_uri	string,\n        tax_cat_no	string,\n        parent_matnr	string,\n        remark	string,\n        private_ware_type	string,\n        article_no	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 11:07:19', '2022-08-11 07:17:03', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (295, 'aoteledemo', 1, 116, 'DDL_DIM_WARE_PURCHASE_CATEGORY', 'job-a86ce0ff-9894-492e-ac1f-587dcdb9379d', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:11:04\n--********************************************************************--\n\n\n--商品采购类目维度表\ncreate table dim_ware_purchase_category(\n        group_id	string,\n        matnr	string,\n        category_flag	string,\n        group_name	string,\n        matkl	string,\n        purchase_category_layers	string,\n        purchase_category1_code	string,\n        purchase_category1_name	string,\n        purchase_category2_code	string,\n        purchase_category2_name	string,\n        purchase_category3_code	string,\n        purchase_category3_name	string,\n        purchase_category4_code	string,\n        purchase_category4_name	string,\n        purchase_category5_code	string,\n        purchase_category5_name	string,\n        create_time	string,\n        update_time	string,\n        purchase_category1_id	string,\n        purchase_category2_id	string,\n        purchase_category3_id	string,\n        purchase_category4_id	string,\n        purchase_category5_id	string,\n        category_layers	string,\n        matkl_layers	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 11:07:50', '2022-08-11 07:17:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (296, 'aoteledemo', 1, 126, 'DDL_DWD_SALE_POSTING_ORDER_WARE_POST_D_VIEW', 'job-7a5ea926-99e4-442e-97f9-9e375dea2215', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:12:26\n--********************************************************************--\n\n\n--流水表\ncreate table dwd_sale_posting_order_ware_post_d_view(\n        order_id	string,\n        origin_order_id	string,\n        item_id	string,\n        group_name	string,\n        vender_id	string,\n        vender_name	string,\n        store_name	string,\n        store_code	string,\n        user_id	string,\n        member_flag	string,\n        cashier_id	string,\n        pos_device_id	string,\n        order_create_time	string,\n        order_complete_time	string,\n        posting_time	string,\n        ware_db_id	string,\n        matnr	string,\n        item_num	string,\n        ware_name	string,\n        supplier_code	string,\n        ware_unit	string,\n        sale_tax_rate	string,\n        ware_type	string,\n        sku_type	string,\n        parent_order_id	string,\n        refund_flag	string,\n        order_sn	string,\n        trade_type	string,\n        sale_type	string,\n        order_origin	string,\n        source_tag	string,\n        custom_refund_flag	string,\n        ware_amt	string,\n        actual_sale_taxed_amt	string,\n        actual_sale_untaxed_amt	string,\n        cost_taxed_amt	string,\n        cost_untaxed_amt	string,\n        sale_num	string,\n        promotion_amt	string,\n        point_amt	string,\n        clean_sale_infos	string,\n        offline_bar_code	string,\n        retail_price	string,\n        data_source	string,\n        modify_price_flag	string,\n        package_num	string,\n        extend_infos	string,\n        promotion_id_list	string,\n        schedule_no_list	string,\n        vender_promotion_amt	string,\n        sap_promotion_schdule_no	string,\n        user_promotion_identity_code	string,\n        v_actual_sale_untaxed_amt	string,\n        delivery_type	string,\n        trans_type_code1	string,\n        trans_type_name1	string,\n        trans_type_code2	string,\n        trans_type_name2	string,\n        trans_type_code3	string,\n        trans_type_name3	string,\n        trans_type_code4	string,\n        trans_type_name4	string,\n        coupon_amt	string,\n        dt	string,\n        group_id	string,\n        id	string,\n        dt_copy	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 11:27:31', '2022-08-11 09:28:49', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (297, 'aoteledemo', 1, 158, 'DDL_DWS_STOCK_WARE_D', 'job-ca9c09df-8673-4fce-80b2-0a4618848d6d', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:14:20\n--********************************************************************--\n\n--进销存集市汇总表\ncreate table dws_stock_ware_d(\n        group_id	string,\n        store_code	string,\n        matnr	string,\n        supplier_code	string,\n        group_name	string,\n        store_name	string,\n        store_type	string,\n        supplier_name	string,\n        item_num	string,\n        ware_name	string,\n        stock_unit	string,\n        sell_type	string,\n        sell_type_name	string,\n        stock_mode	string,\n        unit_taxed_cost	string,\n        unit_untaxed_cost	string,\n        start_stock_num	string,\n        start_stock_taxed_cost	string,\n        start_stock_untaxed_cost	string,\n        end_stock_num	string,\n        end_stock_taxed_cost	string,\n        end_stock_untaxed_cost	string,\n        init_stock_num	string,\n        init_stock_taxed_cost	string,\n        init_stock_untaxed_cost	string,\n        receive_stock_num	string,\n        receive_stock_taxed_cost	string,\n        receive_stock_untaxed_cost	string,\n        return_stock_num	string,\n        return_stock_taxed_cost	string,\n        return_stock_untaxed_cost	string,\n        distribute_in_stock_num	string,\n        distribute_in_stock_taxed_cost	string,\n        distribute_in_stock_untaxed_cost	string,\n        distribute_out_stock_num	string,\n        distribute_out_stock_taxed_cost	string,\n        distribute_out_stock_untaxed_cost	string,\n        sale_stock_num	string,\n        sale_stock_taxed_cost	string,\n        sale_stock_untaxed_cost	string,\n        sale_return_stock_num	string,\n        sale_return_stock_taxed_cost	string,\n        sale_return_stock_untaxed_cost	string,\n        bom_sale_stock_num	string,\n        bom_sale_stock_taxed_cost	string,\n        bom_sale_stock_untaxed_cost	string,\n        bom_sale_return_stock_num	string,\n        bom_sale_return_stock_taxed_cost	string,\n        bom_sale_return_stock_untaxed_cost	string,\n        get_stock_num	string,\n        get_stock_taxed_cost	string,\n        get_stock_untaxed_cost	string,\n        product_stock_num	string,\n        product_stock_taxed_cost	string,\n        product_stock_untaxed_cost	string,\n        material_stock_num	string,\n        material_stock_taxed_cost	string,\n        material_stock_untaxed_cost	string,\n        allot_in_stock_num	string,\n        allot_in_stock_taxed_cost	string,\n        allot_in_stock_untaxed_cost	string,\n        allot_out_stock_num	string,\n        allot_out_stock_taxed_cost	string,\n        allot_out_stock_untaxed_cost	string,\n        check_stock_num	string,\n        check_stock_taxed_cost	string,\n        check_stock_untaxed_cost	string,\n        adjust_stock_num	string,\n        adjust_stock_taxed_cost	string,\n        adjust_stock_untaxed_cost	string,\n        discard_stock_num	string,\n        discard_stock_taxed_cost	string,\n        discard_stock_untaxed_cost	string,\n        compensate_stock_taxed_cost	string,\n        compensate_stock_untaxed_cost	string,\n        batch_share_stock_taxed_cost	string,\n        batch_share_stock_untaxed_cost	string,\n        cost_diff_stock_taxed_cost	string,\n        cost_diff_stock_untaxed_cost	string,\n        dt	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 11:46:09', '2022-08-11 09:28:00', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (299, 'aoteledemo', 1, 147, 'DDL_DWD_SCM_PURCHASE_ORDER_WARE', 'job-9746f9e8-c9b3-4a8c-aea4-e66bdb158418', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 08:00:34\n--********************************************************************--\n\n--采购订单表\ncreate table dwd_scm_purchase_order_ware_d(\n        po_no	string,\n        po_item_no	string,\n        group_id	string,\n        group_name	string,\n        vender_id	string,\n        vender_name	string,\n        store_code	string,\n        store_name	string,\n        matnr	string,\n        item_num	string,\n        ware_name	string,\n        purchase_tax_code	string,\n        purchase_tax_rate	string,\n        promotion_title	string,\n        promotion_schedule_no	string,\n        promotion_level	string,\n        promotion_type	string,\n        first_flag	string,\n        inner_supplier_code	string,\n        inner_supplier_name	string,\n        inner_supplier_type	string,\n        delivery_type	string,\n        supplier_code	string,\n        supplier_name	string,\n        po_biz_type	string,\n        po_type	string,\n        po_source	string,\n        po_item_status	string,\n        close_flag	string,\n        reverse_flag	string,\n        purchase_time	string,\n        expect_dc_delivery_date	string,\n        expect_store_delivery_date	string,\n        receive_complete_flag	string,\n        receive_time	string,\n        original_book_num	string,\n        book_num	string,\n        book_unit	string,\n        book_cf	string,\n        supplier_confirm_purchase_num	string,\n        purchase_unit	string,\n        purchase_cf	string,\n        purchase_taxed_price	string,\n        gift_num	string,\n        base_unit	string,\n        store_type	string,\n        sell_type	string,\n        erp_no	string,\n        dt	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300\n;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 11:52:26', '2022-08-11 09:25:50', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (300, 'aoteledemo', 1, 149, 'DDL_DWT_STORE_WARE_D', 'job-ea490940-e12c-46e4-8b9f-e99cb25caa5a', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:20:38\n--********************************************************************--\n\n\n--门店商品宽表\ncreate table dwt_store_ware_d(\n        store_code	string,\n        manage_type	string,\n        store_type	string,\n        matnr	string,\n        sell_type	string,\n        sell_type_name	string,\n        status_code	string,\n        status_name	string,\n        item_num	string,\n        ware_name	string,\n        offline_ware_name	string,\n        purchase_taxed_price	string,\n        offline_current_price	string,\n        spec_type	string,\n        spec_type_name	string,\n        spec_qty	string,\n        spec_unit	string,\n        ware_create_time	string,\n        package_unit	string,\n        package_num	string,\n        ware_taste	string,\n        supplier_code	string,\n        supplier_name	string,\n        purchase_category1_code	string,\n        purchase_category1_name	string,\n        purchase_category2_code	string,\n        purchase_category2_name	string,\n        purchase_category3_code	string,\n        purchase_category3_name	string,\n        purchase_category4_code	string,\n        purchase_category4_name	string,\n        purchase_category5_code	string,\n        purchase_category5_name	string,\n        operation_category1_code	string,\n        operation_category1_name	string,\n        operation_category2_code	string,\n        operation_category2_name	string,\n        operation_category3_code	string,\n        operation_category3_name	string,\n        operation_category4_code	string,\n        operation_category4_name	string,\n        operation_category5_code	string,\n        operation_category5_name	string,\n        brand_id	string,\n        brand_name	string,\n        brand_business_id	string,\n        brand_business_name	string,\n        brand_flag	string,\n        super_flag	string,\n        exclude_flag	string,\n        service_flag	string,\n        shopping_bag_flag	string,\n        sale_data_flag	string,\n        purchase_data_flag	string,\n        stock_data_flag	string,\n        sale_ware_unit	string,\n        ware_amt	string,\n        sale_num	string,\n        actual_sale_taxed_amt	string,\n        actual_sale_untaxed_amt	string,\n        tg_sale_num	string,\n        tg_actual_sale_taxed_amt	string,\n        tg_actual_sale_untaxed_amt	string,\n        cost_taxed_amt	string,\n        cost_untaxed_amt	string,\n        refund_sale_num	string,\n        refund_ware_amt	string,\n        refund_actual_sale_taxed_amt	string,\n        refund_actual_sale_untaxed_amt	string,\n        bgp_taxed_amt	string,\n        bgp_untaxed_amt	string,\n        gp_taxed_amt	string,\n        gp_untaxed_amt	string,\n        ngp_taxed_amt	string,\n        ngp_untaxed_amt	string,\n        gpc_taxed_amt	string,\n        gpc_untaxed_amt	string,\n        pcd_taxed_amt	string,\n        pcd_untaxed_amt	string,\n        ccd_taxed_amt	string,\n        ccd_untaxed_amt	string,\n        cgp_taxed_amt	string,\n        cgp_untaxed_amt	string,\n        skb_taxed_amt	string,\n        skb_untaxed_amt	string,\n        wl_num	string,\n        wl_taxed_amt	string,\n        wl_untaxed_amt	string,\n        discard_num	string,\n        discard_taxed_amt	string,\n        discard_untaxed_amt	string,\n        adjust_loss_num	string,\n        adjust_loss_taxed_amt	string,\n        adjust_loss_untaxed_amt	string,\n        adjust_profit_num	string,\n        adjust_profit_taxed_amt	string,\n        adjust_profit_untaxed_amt	string,\n        check_loss_num	string,\n        check_loss_taxed_amt	string,\n        check_loss_untaxed_amt	string,\n        check_profit_num	string,\n        check_profit_taxed_amt	string,\n        check_profit_untaxed_amt	string,\n        scm_book_unit	string,\n        scm_book_num	string,\n        stock_ware_unit	string,\n        end_stock_num	string,\n        end_stock_taxed_cost	string,\n        end_stock_untaxed_cost	string,\n        map_stock_taxed_cost	string,\n        map_stock_untaxed_cost	string,\n        return_stock_num	string,\n        return_stock_taxed_amt	string,\n        return_stock_untaxed_amt	string,\n        receive_stock_num	string,\n        receive_stock_taxed_amt	string,\n        receive_stock_untaxed_amt	string,\n        extend_json	string,\n        u_id	string,\n        modified	string,\n        week_id	string,\n        month_id	string,\n        quarter_id	string,\n        year_id	string,\n        ware_life	string,\n        ware_life_unit	string,\n        estimate_type	string,\n        estimate_type_name	string,\n        scm_book_taxed_amt	string,\n        scm_book_untaxed_amt	string,\n        distribute_in_stock_num	string,\n        distribute_in_stock_taxed_amt	string,\n        distribute_in_stock_untaxed_amt	string,\n        distribute_out_stock_num	string,\n        distribute_out_stock_taxed_amt	string,\n        distribute_out_stock_untaxed_amt	string,\n        get_stock_num	string,\n        get_stock_taxed_amt	string,\n        get_stock_untaxed_amt	string,\n        basic_unit	string,\n        basic_unit_desc	string,\n        price_group_code	string,\n        price_group_name	string,\n        v_actual_sale_untaxed_amt	string,\n        data_source	string,\n        sale_stock_num	string,\n        sale_stock_taxed_cost	string,\n        sale_stock_untaxed_cost	string,\n        bom_sale_stock_num	string,\n        bom_sale_stock_taxed_cost	string,\n        bom_sale_stock_untaxed_cost	string,\n        offline_original_price	string,\n        dt	string,\n        group_id	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:40:47', '2022-08-11 09:26:54', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (301, 'aoteledemo', 1, 147, 'DDL_DWD_SCM_DC_RECEIVE_ORDER_WARE_D', 'job-6b1d30a5-b5b8-46c7-b619-1f2f12c80ab6', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 08:02:07\n--********************************************************************--\n\n--DC入库作业明细表\ncreate table dwd_scm_dc_receive_order_ware_d(\n        receive_no	string,\n        receive_item_no	string,\n        receive_origin	string,\n        receive_origin_no	string,\n        order_type	string,\n        bussiness_type	string,\n        delivery_type	string,\n        expect_dc_delivery_date	string,\n        receive_complete_time	string,\n        posting_time	string,\n        po_no	string,\n        po_item_no	string,\n        purchase_time	string,\n        purchase_num	string,\n        supplier_confirm_purchase_num	string,\n        supplier_code	string,\n        supplier_name	string,\n        group_id	string,\n        group_name	string,\n        vender_id	string,\n        vender_name	string,\n        warehouse_code	string,\n        warehouse_name	string,\n        matnr	string,\n        item_num	string,\n        ware_name	string,\n        purchase_tax_rate	string,\n        purchase_tax_code	string,\n        purchase_tax_amt	string,\n        base_unit	string,\n        spec_qty	string,\n        spec_unit	string,\n        sell_type	string,\n        stock_position_code	string,\n        reversal_flag	string,\n        reverse_receive_no	string,\n        reversal_reason_id	string,\n        reversal_reason	string,\n        reverse_ware_num	string,\n        reverse_time	string,\n        return_reason	string,\n        receive_ware_num	string,\n        unit_cost_untaxed_amt	string,\n        unit_cost_taxed_amt	string,\n        total_cost_taxed_amt	string,\n        total_cost_untaxed_amt	string,\n        cx_unit_cost_untaxed_amt	string,\n        cx_unit_cost_taxed_amt	string,\n        po_type	string,\n        po_biz_type	string,\n        reverse_result_ware_num	string,\n        dt	string,\n        id	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifecycle 300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:42:14', '2022-08-11 09:25:36', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (302, 'aoteledemo', 1, 147, 'DDL_DWD_SCM_RECEIVE_ORDER_WARE_D', 'job-dc6d3d6b-94eb-4f06-85b4-a65c63a13ede', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:57:39\n--********************************************************************--\n\n--门店收货商品明细信息\ncreate table dwd_scm_receive_order_ware_d(\n        receive_no	string,\n        receive_item_no	string,\n        matnr	string,\n        item_num	string,\n        ware_name	string,\n        ware_type	string,\n        gift_flag	string,\n        promotion_flag	string,\n        po_no	string,\n        po_item_no	string,\n        po_type	string,\n        po_biz_type	string,\n        purchase_time	string,\n        expect_store_delivery_date	string,\n        send_no	string,\n        send_time	string,\n        send_locale_code	string,\n        send_locale_name	string,\n        send_locale_type	string,\n        supplier_code	string,\n        supplier_name	string,\n        receive_cost_type	string,\n        item_receive_status	string,\n        receive_origin	string,\n        receive_order_type	string,\n        receive_business_type	string,\n        group_id	string,\n        group_name	string,\n        vender_id	string,\n        vender_name	string,\n        store_code	string,\n        store_name	string,\n        store_address	string,\n        item_receive_time	string,\n        reverse_no	string,\n        reversal_voucher_no	string,\n        reversal_flag	string,\n        reversal_reason_id	string,\n        reversal_reason	string,\n        reverse_time	string,\n        reverse_ware_num	string,\n        batch_id	string,\n        batch_sn	string,\n        batch_production_time	string,\n        batch_expiry_time	string,\n        batch_status	string,\n        compensation_no	string,\n        compensate_status	string,\n        compensate_ware_num	string,\n        compensate_reason_id	string,\n        compensate_remark	string,\n        purchase_ware_num	string,\n        delivery_ware_num	string,\n        receive_ware_num	string,\n        ware_unit	string,\n        purchase_tax_rate	string,\n        purchase_tax_code	string,\n        purchase_tax_amt	string,\n        item_taxed_amt	string,\n        item_untaxed_amt	string,\n        receive_untaxed_price	string,\n        receive_taxed_price	string,\n        purchase_untaxed_price	string,\n        purchase_taxed_price	string,\n        ware_spec_unit_value	string,\n        ware_spec_unit	string,\n        package_name	string,\n        production_time	string,\n        production_address	string,\n        item_receive_diff_ware_num	string,\n        stock_position_code	string,\n        erp_no	string,\n        reverse_result_ware_num	string,\n        dt	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:42:37', '2022-08-11 09:26:31', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (303, 'aoteledemo', 1, 130, 'DDL_ADS_PAY_ORD_DF', 'job-63dfc3b2-9092-46fb-88a0-35f1f7bf2e9d', 'hangzhou-spark-3.2', '创建表', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 05:24:49\n--********************************************************************--\n\n--支付汇总表\ncreate table ads_pay_ord_df(\n        date_col	string,\n        year_col	string,\n        month_col	string,\n        day_col	string,\n        store_type string,\n        store_id string,\n        goods_id string,\n        goods_num string,\n        goods_first_type string,\n        brand_type string,\n        area_type string,\n        gmv_tax string,\n        gmv_untax string,\n        cost_tax string,\n        cost_untax string,\n        order_num string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:47:33', '2022-08-11 09:29:07', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (304, 'aoteledemo', 1, 130, 'DDL_ADS_RE_PUR_DF', 'job-6628a3ca-e1d0-49e3-9ee1-c5e54af9b440', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 06:48:31\n--********************************************************************--\n\n--复购表\ncreate table ads_re_pub_df(\n        user_id string,\n        new_old_type string,\n        gmv_tax string,\n        gmv_untax string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:48:12', '2022-08-11 09:29:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (305, 'aoteledemo', 1, 160, 'DDL_ADS_REPERTORY_DF', 'job-a15ccc4e-0efe-458b-af51-dd15c069d8da', 'hangzhou-spark-3.2', 'table', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 06:56:32\n--********************************************************************--\n\n--库存表\ncreate table ads_repertory_df(\n        date_col string,\n        month_col string,\n        store_type string,\n        goods_id string,\n        money_col string,\n        Library_age string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:48:35', '2022-08-11 09:28:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (306, 'aoteledemo', 1, 130, 'DDL_ADS_STORE_COST_DF', 'job-2662369c-472a-4b5e-9a31-c9207801424e', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 06:06:19\n--********************************************************************--\n\n-- 其他成本表\ncreate table ads_store_cost_df(\n            date_col	string,\n            year_col	string,\n            month_col	string,    \n            other_cost string,\n            rent_cost string,\n            property_cost string,\n            employe_cost string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:48:51', '2022-08-11 09:29:23', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (307, 'aoteledemo', 1, 151, 'DDL_ADS_SUPPLIER_DF', 'job-743b7941-2e88-40fd-8b4c-b42fd578b397', 'hangzhou-spark-3.2', 'TABLE', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 06:52:52\n--********************************************************************--\n\n--供应商表\ncreate table ads_supplier_df(\n        user_id string,\n        year_col string,\n        month_col string,\n        day_col string,\n        supplier_id string,\n        supplier_type string,\n        Purchase_amount string,\n        goods_frist_type string\n) \nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 12:49:19', '2022-08-11 09:27:01', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (310, 'aoteledemo', 1, 116, 'DDL_DIM_PAWWAY_NEW', 'Job-TgVonHKwbIaVUpnCOxl7JfTfrKCeekDY', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-11 07:14:45\n--********************************************************************--\n\n--********************************************************************--\n-- author:      demo#demo\n-- create time: 2022-08-10 07:08:53\n--********************************************************************--\n\n\n--支付方式维度表\ncreate table dim_payway_new(\n        vender_id	string   comment \'商家id\',\n        group_id	string   comment \'集团id\',\n       pay_channel	string   comment \'小类别支付方式\',\n        group_name	string   comment \'集团名称\',\n        pay_channel_desc	string   comment \'小类别支付方式说明\',\n        pay_way	string   comment \'大类别支付方式\',\n        pay_way_desc	string   comment \'大类别支付方式说明\',\n        pay_flag	string   comment \'支付方式正逆向标识\',\n        vender_name	string   comment \'商家名称\'\n)  comment \'支付方式维度表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, 'demo#demo', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-11 15:14:45', '2022-08-11 07:47:49', 'demo#demo', 'demo#demo');
INSERT INTO `meta_job` VALUES (311, '7or9', 1, 170, 'ADS_inventory_df', 'Job-pubWiwpzQfkhCMJLJ4adwMriZMI9TFZj', 'hangzhou-spark-3.2', '库存现有数量表', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-12 11:31:12\n--********************************************************************--\n---库存表\n\ncreate table ads_inventory_df(\n    Shoe_type	string	comment	\'鞋子类型\',\n	Shoe_Name	string	comment	\'鞋子名称\',\n	year_last_one_month	string	comment	\'时间_每年最近的第一个月\',\n	year_last_two_month string	comment	\'时间_每年最近的第二个月\',\n	year_last_three_month string	comment	\'时间_每年最近的第三个月\',\n	Delivery_quantity string	comment	\'本期发出数量\',\n	year_last_month	string	comment	\'时间_每年的最后一个月份\',\n	Inventory_quantity	string	comment	\'期末结存的数量\',\n	amount_of_money string	comment	\'期末结存的金额\'\n	\n)  comment	\'库存表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\nselect sum(amount_of_money)\nfrom ads_inventory_df;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-12 19:31:12', '2022-08-17 09:21:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (314, '7or9', 1, 169, 'ds2ods_inventory_receipt', 'Job-FT11BYQNG3nZyZ0K2Hmvpf9XPr5tIm4b', 'hangzhou-spark-3.2', '将进销存数据从excel导入ods表', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-08-13 12:38:03\n--********************************************************************--\n\nload data \'/user/superior/users/buxuan/inventory2.csv\' table tdl_spark_test options( delimiter=\',\',charset=\'UTF-8\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ncreate table ods_inventory_receipt_delivery2 as select * from tdl_spark_test ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-13 20:38:03', '2022-08-14 23:42:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (315, '7or9', 1, 168, 'ods_Inventory_receipt_delivery', 'job-9f043952-4d7b-4693-ae28-30faff0f5e89', 'hangzhou-spark-3.2', '库存收发汇总表', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-12 12:05:40\n--********************************************************************--\n\n\n---存货收发汇总表\ncreate table ods_Inventory_receipt_delivery (\n    Material_code	string	comment	\'物料编码\',\n	Material_name	string	comment	\'物料名称\',\n	Material_properties	string	comment	\'物料属性\',\n	Inventory_category string	comment	\'存货类别\',\n	Material_Grouping string	comment	\'物料分组\',\n	Specification_model string	comment	\'规格型号\',\n	Inventory_status string	comment	\'库存状态\',\n	Warehouse string	comment	\'仓库\',\n	Accounting_range_code string	comment	\'核算范围编码\',\n	Accounting_range_name string	comment	\'核算范围名称\',\n	Opening_balance_quantity string	comment	\'期初结存数量\',\n	Opening_balance_unit_price string	comment	\'期初结存单价\',\n	Opening_balance_amount string	comment	\'期初结存金额\',\n	Revenue_quantity string	comment	\'本期收入数量\',\n	Revenue_unit_price string 	comment	\'本期收入单价\',\n	Revenue_amount string	comment	\'本期收入金额\',\n	Issued_quantity string	comment	\'本期发出数量\',\n	Issued_unit_price string	comment	\'本期发出单价 \',\n	Issued_amount string	comment	\'本期发出金额\',\n	Balance_quantity string	comment	\'期末结存数量\',\n	Balance_unit_price string	comment	\'期末结存单价\',\n	Balance_amount string	comment	\'期末结存金额\'\n)  comment	\'存货收发汇总表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\nselect sum(Balance_amount)\nfrom  ods_Inventory_receipt_delivery\nwhere Material_Grouping =\'辅料\';\n\n\n\n\n\n\n\n\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-14 18:06:15', '2022-08-16 23:19:04', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (316, '7or9', 1, 169, 'ds2ods_Inventory_receipt_delivery', 'Job-QQ1RRe25OQ9u29r4FirnvyVemyan3xta', 'hangzhou-spark-3.2', 'q', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-14 13:07:16\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/inventory.csv\' table spark_test options( delimiter=\',\',charset=\'UTF-8\',header=\'true\') ;\nselect * from tdl_spark_test limit 10;\n--create table ods_inventory_receipt_delivery2 as select * from tdl_spark_test ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-14 21:07:16', '2022-08-15 01:48:56', '方楚生#fangchusheng', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (317, '7or9', 1, 169, 'ds1ods_Inventory_receipt_delivery', 'Job-iKRl4f1QJ45okdWOACquvDhnNyEWpWy5', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-15 01:11:29\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/cun.csv\' table tdl_spark_tex options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ods_Inventory_receipt_delivery select * from tdl_spark_tex ;\n---create table tdl_data_table lifecycle 7 select * from tdl_spark_tex;\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-15 09:11:29', '2022-08-17 11:46:44', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (318, '7or9', 1, 172, 'dwd_inventory_recepit_202112', 'Job-LJWJ6Rg9BF0NfnDgEoEe6vAdJb3BJkff', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-15 02:24:28\n--********************************************************************--\n\n---库存明细表\ncreate table dwd_Inventory_details (\n    Shoe_type	string	comment	\'鞋子类型\',\n	Shoe_Name	string	comment	\'鞋子名称\',\n	year	string	comment	\'年\',\n	month string	comment	\'月\',\n	Inventory_quantity string	comment	\'期末结存的数量\',\n	amount_of_money string	comment	\'期末结存的金额\',\n	Delivery_quantity string	comment	\'本期发出的数量\'\n	)  comment	\'库存明细表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\n\nselect sum(amount_of_money) from   dwd_Inventory_details\nwhere Shoe_type=\'凉鞋系列高跟鞋\';\n\n\n\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-15 10:24:29', '2022-08-16 21:59:36', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (319, '7or9', 1, 173, 'ds1dwd_inventory_recepit_202112', 'Job-heD1ZUb90q4OgrrnnVXgxyEOddUyVq6c', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-15 03:11:42\n--********************************************************************--\n\ninsert overwrite table dwd_Inventory_details select  \nt1.material_grouping,\nt1.material_name,\n\'2021\',\n\'12\',\nt1.balance_quantity,\nt1.balance_amount,\nt1.issued_quantity\nfrom ods_Inventory_receipt_delivery t1\nwhere t1.material_grouping= \'凉鞋系列高跟鞋\' or t1.material_grouping=\'7系列高跟鞋\' or  t1.material_grouping =\'9系列高跟鞋\';\n\n----select count(*) from dwd_Inventory_details  ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-15 11:11:42', '2022-08-16 16:15:50', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (321, '7or9', 1, 174, 'ds2ADS_inventory_df', 'Job-SabgMxtVtfyD02VFDNm2kOBURa0pBgvZ', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-15 06:48:16\n--********************************************************************--\n\ninsert overwrite table  ads_inventory_df\nselect  \ndecode(q1.Shoe_type,\'凉鞋系列高跟鞋\',\'凉鞋\',\'7系列高跟鞋\',\'单鞋\',\'9系列高跟鞋\',\'单鞋\'),\ndecode(q1.Shoe_Name,\'杜乐丽花园-黑糖布丁\',\'杜乐丽花园-黑糖布丁\',\'罗丹花园-棉花糖\',\'罗丹花园-棉花糖\',\n\'罗丹花园-杏仁露\',\'罗丹花园-杏仁露\',\'卢森堡花园-甜甜圈\',\'卢森堡花园-甜甜圈\',\'莫奈花园-白巧\',\'其他单鞋\',\n\'凡尔赛花园-水晶糖\',\'其他单鞋\',\'其他凉鞋\'),\nconcat(q1.year,\'-\',q1.month),\nnull,\nnull,\ndelivery_quantity,\nconcat(q1.year,\'-\',q1.month),\nInventory_quantity,\namount_of_money\nfrom dwd_Inventory_details q1;\n\n----select * from  ads_inventory_df limit 10;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-15 14:48:17', '2022-08-16 13:45:48', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (322, '7or9', 1, 182, 'ODS_LRB_Commodity_sales', 'Job-siQwmBFhUB2ktHXPHffnoiuGWNTmqEt0', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-16 03:38:43\n--********************************************************************--\n\n---小红书商品销售表\ncreate table ODS_LRB_Commodity_sales (\n    Order_completion_time	string	comment	\'订单完成时间\',\n	User_order_time 	string	comment	\'用户下单时间\',\n	order_number	string	comment	\'订单号\',\n	Package_number string	comment	\'包裹号\',\n	Order_type string	comment	\'订单类型\',\n	Item_Name string	comment	\'商品名称\',\n	Item_ID string	comment	\'商品id\',\n	Lrb_code string	comment	\'小红书编码\',\n	Commodity_type string	comment	\'商品类型\',\n	Member_product_name string	comment	\'成员商品名称\',\n	Member_commodity_lrb_code string	comment	\'成员商品小红书编码\',\n	Total_revenue string	comment	\'收入总额\',\n	Settlement_account string	comment	\'结算账户\',\n	Commodity_quantity string	comment	\'商品数量\',\n	Total_settlement string	comment	\'结算总额\',\n	Total_paid  string	comment	\'实付总额\',\n	Payment_channel_fee_commodity string	comment	\'支付渠道费(商品)\',\n	Total_deposit string	comment	\'定金总额 \',\n	Total_discount_merchants string	comment	\'商家优惠总额\',\n	lrb_discount_total string	comment	\'小红书优惠总额\',\n	Commission_rate string	comment	\'佣金率\',\n	Total_Commission string	comment	\'佣金总额\',\n	Taxable_price_including_tax string	comment	\'计税价格(含税)\',\n	Taxable_price_before_tax string	comment	\'计税价格(未税)\',\n	tax_category string	comment	\'税种\',\n	tax_rate string	comment	\'税率\',\n	Tax_rate_cross_border_tax_payment  string	comment	\'跨境税代缴\',\n	Total_tax_commodity string	comment	\'税金总额(商品)\'\n	\n)  comment	\'小红书商品销售表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n---drop table  ODS_LRB_Commodity_sales ;\n\n\n----select * from  ODS_LRB_Commodity_sales limit 10;\n\n\n\n\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-16 11:38:44', '2022-08-17 13:57:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (323, '7or9', 1, 175, 'ds3ADS_inventory_df', 'Job-5fb1l25uDMjSzXFLSPhT9yMsBODsGYmu', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-16 06:03:09\n--********************************************************************--\n/*\ndatatunnel source(\"mysql\") options(\n    username=\"dataworks\",\n    password=\"dataworks2021\",\n    host=\'10.5.20.20\',\n    port=3306,\n    databaseName=\'dataworks\', tableName=\'dc_dtunnel_datasource\', columns=[\"*\"])\n    sink(\"hive\") options(databaseName=\"bigdata\", tableName=\'hive_dtunnel_datasource\', writeMode=\'overwrite\', columns=[\"*\"]);\n\nexplain extended select * from hive_dtunnel_datasource limit 10\n\ndatatunnel \nsource(\'mysql\') options(\n    username=\'dataworks\',\n    password=\'dataworks2021\',\n    host=\'10.5.20.20\',\n    port=3306,\n    resultTableName=\'tdl_dc_job\',\n    databaseName=\'dataworks\', tableName=\'dc_job\', columns=[\'*\'])\ntransform = \'select * from tdl_dc_job where type=\"spark_sql\"\'\nsink(\'log\') options(numRows = 10)\n*/\n\n\ndatatunnel source(\"hive\") options(\n    databaseName=\'7or9\',   ---数据库名\n    tableName=\'ads_inventory_df\',   ----表名\n    columns= [\'*\'])              ------字段\nsink(\"mysql\") options(\n    username=\"optimus_dev\",          ------用户名\n    password=\"optimus_dev\",   ---------用户密码\n    host=\'8.136.133.76\',        ------服务器地址\n    port=23306,                 --------端口号\n    databaseName=\'pevc_reviw\',    ------数据库名\n    tableName=\'dc_inventory_copy\',  -----新的表名\n    writeMode=\'overwrite\',\n    truncate=true,\n    columns=[\'*\'])\n        \n        \n\n\n----139.217.237.72  root Password@12345\n\n\n\n        \n        ', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-16 14:03:09', '2022-08-17 09:14:41', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (324, '7or9', 1, 182, 'ODS_LRB_freight', 'Job-lapAPlvk37ogrwSIU9eQ2qDqfpIdWNXn', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 02:11:19\n--********************************************************************--\n\n\n---小红书运费表\ncreate table ODS_LRB_freight (\n    entry_force_time	string	comment	\'生效时间\',\n	User_order_time 	string	comment	\'用户下单时间\',\n	Delivery_time	string	comment	\'发货时间\',\n	order_number string	comment	\'订单号\',\n	Package_number string	comment	\'包裹号\',\n	Freight_Po string	comment	\'运费宝单号\',\n	Policy_amount string	comment	\'保单金额\',\n	Settlement_account string	comment	\'结算账户\'\n	\n	\n)  comment	\'小红书运费表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\n\n----select sum(Policy_amount) from  ODS_LRB_freight ---limit 10;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 10:11:20', '2022-08-17 14:13:39', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (325, '7or9', 1, 182, 'ODS_LRB_return_goods', 'Job-ru4jW2uDslgubuBlWnARleP9Frvpjwr9', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 02:30:54\n--********************************************************************--\n\n---小红书退货表\ncreate table ODS_LRB_return_goods (\n    Refund_time	string	comment	\'退款时间\',\n	Product_Name 	string	comment	\'商品名称\',\n	Commodity_type	string	comment	\'商品类型\',\n	Total_expenditure string	comment	\'支出总额\',\n	Settlement_account string	comment	\'结算账户\',\n	Quantity_returned_goods string	comment	\'退货商品数量\',\n	Total_paid_sales  string	comment	\'销售实付总额\',\n	Total_sales_settlement  string	comment	\'销售结算总额\',\n	Total_sales_commission  string	comment	\'销售佣金总额\',\n	Total_amount_actually_returned  string	comment	\'实退总额\',\n	Total_return_commission  string	comment	\'退货佣金总额\',\n	Payment_channel_fee_return string	comment	\'支付渠道费退货\',\n	Item_ID string	comment	\'商品id\',\n	lrb_code string	comment	\'小红书编码\',\n	Package_number string	comment	\'包裹号\',\n	Return_No string	comment	\'退货单号\'\n	\n	\n	\n)  comment	\'小红书退货表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\nSELECT SUM(Total_expenditure) FROM  ODS_LRB_return_goods-- LIMIT 10;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 10:30:54', '2022-08-17 14:35:03', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (326, '7or9', 1, 182, 'ODS_LRB_Manual_refund', 'Job-sFVvDbwaFZTErxhOo69yYQbrEf2eAcpm', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 02:53:14\n--********************************************************************--\n\n\n---小红书人工退款表\ncreate table ODS_LRB_Manual_refund (\n    Refund_time	string	comment	\'退款时间\',\n	Expenditure_amount 	string	comment	\'支出金额\',\n	Settlement_account	string	comment	\'结算账户\',\n	Refund_settlement_amount string	comment	\'退款结算金额\',\n	Commission_amount string	comment	\'佣金金额\',\n	Actual_refund_amount string	comment	\'实退金额\',\n	Paid_amount string	comment	\'实付金额\',\n	Settlement_amount string	comment	\'结算金额\',\n	Package_number string	comment	\'包裹号\',\n	Refund_reason string	comment	\'退款原因\'\n\n	\n)  comment	\'小红书人工退款表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\nselect sum(Expenditure_amount) from ODS_LRB_Manual_refund;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 10:53:14', '2022-08-17 14:46:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (327, '7or9', 1, 182, 'ODS_LRB_CPS_distribution', 'Job-EiqMp3vjoApH2qE5lCLoUsrIwHtMDgDm', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 03:12:07\n--********************************************************************--\n\n---小红书CPS分销表\ncreate table ODS_LRB_GPS_distribution (\n    Settlement_time	string	comment	\'结算时间\',\n	Business_type 	string	comment	\'业务类型\',\n	Order_completion_refund_time	string	comment	\'订单完成时间/退款时间\',\n	User_order_time string	comment	\'用户下单时间\',\n	order_number string	comment	\'订单号\',\n	Package_number string	comment	\'包裹号\',\n	Item_Name  string	comment	\'商品名称\',\n	Item_ID string	comment	\'商品id\',\n	Commodity_quantity string	comment	\'商品数量\',\n	Total_paid_refunded string	comment	\'实付总额/退款总额\',\n	taxation string	comment	\'税费\',\n	Carrying_amount string	comment	\'带货金额\',\n	Commodity_CPS_commission_rate string	comment	\'商品CPS佣金率\',\n	Platform_subsidy_commission_rate string	comment	\'平台补贴佣金率\',\n	CPS_commission_rate_seller string	comment	\'卖家CPS佣金率\',\n	Distribution_commission_expense string	comment	\'分销佣金支出\',\n	Settlement_account string	comment	\'结算账户\',\n	Talent_ID string	comment	\'达人id\'\n	\n\n	\n)  comment	\'小红书CPS分销表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\n---DROP TABLE ODS_LRB_GPS_distribution\n\n\n\n----select SUM(Distribution_commission_expense) from  ODS_LRB_GPS_distribution \n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 11:12:07', '2022-08-17 15:08:06', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (328, '7or9', 1, 185, 'ds1_ODS_LRB_Commodity_sales', 'Job-blyyjrwzZcVsgO5DJGMyRUmrVS5ltwIm', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 03:45:18\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/Commodity.xlsx\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_LRB_Commodity_sales select * from tdl_spark_tes ;\n\n\n\n/*\nload data \'/user/superior/users/fangchusheng/ODS_Gross_profit\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_Gross_profit  select * from tdl_spark_tes ;\n*/', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 11:45:18', '2022-08-17 17:21:50', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (329, '7or9', 1, 185, 'ds1_ODS_LRB_freight', 'Job-y5xfBVp7YnUunXcHeOxRy3SkRaW6J0o2', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 05:57:42\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/lrb_yunfeibao.xlsx\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_LRB_freight select * from tdl_spark_tes ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 13:57:43', '2022-08-17 14:09:47', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (330, '7or9', 1, 185, 'ds1_ODS_LRB_return_goods', 'Job-gDjNL0xdqGM7KxwBlH3MgCQ9reUtIVLA', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 06:20:24\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/lrb_tuihuo.xlsx\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_LRB_return_goods select * from tdl_spark_tes ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 14:20:24', '2022-08-17 14:23:35', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (331, '7or9', 1, 185, 'ds1_ODS_LRB_Manual_refund', 'Job-6eb77adGCzak610hEPC9DRRaLHvKcArm', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 06:39:05\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/lrb_rengongtuikuan.xlsx\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_LRB_Manual_refund select * from tdl_spark_tes ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 14:39:06', '2022-08-17 14:42:00', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (332, '7or9', 1, 185, 'ds1_ODS_LRB_CPS_distribution', 'Job-ycdiAqpqNUXiuxIt9dGk0YqX5l7lucbf', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 06:49:51\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/lrb_CPS.xlsx\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_LRB_GPS_distribution  select * from tdl_spark_tes ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 14:49:52', '2022-08-17 14:59:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (333, '7or9', 1, 192, 'ODS_ODS_Gross_profit', 'Job-HGPidwHqWBB4HWXszPlAvzUvv7w3aJLe', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 08:32:36\n--********************************************************************--\n\n--毛利表\ncreate table ODS_Gross_profit (\n    Business_date	string	comment	\'业务日期\',\n	Document_No 	string	comment	\'单据编号\',\n	Document_Status	string	comment	\'单据状态\',\n	Sales_Order_No string	comment	\'销售订单号\',\n	customer string	comment	\'客户\',\n	currency string	comment	\'币别\',\n	due_date string	comment	\'到期日\',\n	Material_code string	comment	\'物料编码\',\n	Material_name string	comment	\'物料名称\',\n	Specification_model string	comment	\'规格型号\',\n	Pricing_unit string	comment	\'计价单位\',\n	Pricing_quantity string	comment	\'计价数量\',\n	Unit_price_including_tax string	comment	\'含税单价\',  \n	tax_rate string	comment	\'税率\',\n	Amount_excluding_tax string	comment	\'不含税金额\',\n	Tax_amount string	comment	\'税额\',\n	gift string	comment	\'赠品\',\n	Cost_amount string	comment	\'成本金额\',\n	Gross_profit string	comment	\'毛利\',\n	Gross_profit_margin string	comment	\'毛利率\',\n	category string	comment	\'类别\'\n	\n\n	\n)  comment	\'毛利表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\n---DROP TABLE ODS_Gross_profit\n\n\n\n----select * from ODS_Gross_profit where Sales_Order_No=\'1585752733628980677\' ;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 16:32:36', '2022-08-17 17:30:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (334, '7or9', 1, 193, 'ds1ODS_ODS_Gross_profit', 'Job-dFhN92E2JuDmrctpDfDe00TH7dJcEoJl', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-17 09:20:50\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/maoli.xlsx\' table tdl_spark_tes options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\ninsert overwrite table ODS_Gross_profit  select * from tdl_spark_tes ;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-17 17:20:51', '2022-08-17 17:22:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (335, '7or9', 1, 194, 'dim_Platform_gross_profit', 'Job-foKHyCVGdqd47dap3ShQ6GSmrUBb3L1U', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-18 02:01:15\n--********************************************************************--\n\n--平台毛利维度表\ncreate table dim_Platform_gross_profit (\n    year	string	comment	\'年\',\n	month 	string	comment	\'月\',\n	customer string	comment	\'平台\',\n	Amount_excluding_tax string	comment	\'不含税金额\',\n	Cost_amount string	comment	\'成本金额\',\n	Gross_profit  string	comment	\'毛利\',\n    category string	comment	\'类别\'\n	\n\n	\n)  comment	\'平台毛利维度表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n/*\nselect a.category,sum(Amount_excluding_tax) from  dim_Platform_gross_profit a \nwhere a.customer=\'7or9小红书\'\ngroup by a.category;\n \nselect count(*) from  dim_Platform_gross_profit;\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-18 10:01:16', '2022-08-18 13:36:54', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (336, '7or9', 1, 195, 'ds1dim_Platform_gross_profit', 'Job-qGiVogGoGpbGqe23IyGYi44YKdWCAmqz', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-18 02:42:10\n--********************************************************************--\n\ninsert overwrite table  dim_Platform_gross_profit\nselect  \n\'2021\',\n\'11\',\ncustomer,\nAmount_excluding_tax,\nCost_amount,\nGross_profit,\ndecode(category,\'辅料\',\'饰品及其他\',\'高跟鞋配饰\',\'饰品及其他\',\'周边产品\',\'饰品及其他\',\'鞋子\')\nfrom ODS_Gross_profit q; \n\n--select count(*) from  ads_inventory_df a limit 10\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-18 10:42:10', '2022-08-18 11:43:13', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (337, '7or9', 1, 183, 'dwd_LRB_Commodity_sales', 'Job-V3n5BVZ5OzIjh2r449XN05UT2hbsvUcK', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-18 03:55:17\n--********************************************************************--\n\n---小红书商品销售事实表\ncreate table dwd_LRB_Commodity_sales (\n    platform	string	comment	\'平台\',\n	year 	string	comment	\'年\',\n	month 	string	comment	\'月\',\n	order_number	string	comment	\'订单号\',\n	Package_number string	comment	\'商品销售包裹号\',\n	Item_ID string	comment	\'商品id\',\n	Total_revenue string	comment	\'收入总额\',\n	Total_paid  string	comment	\'实付总额\',\n	Payment_channel_fee_commodity string	comment	\'支付渠道费(商品)\',\n	Total_Commission string	comment	\'佣金总额\',\n	Package_freight_number string	comment	\'运费宝包裹号\',\n	Policy_amount string	comment	\'保单金额\',\n	Package_CPS_number string	comment	\'CPS包裹号\',\n	Distribution_commission_expense string	comment	\'分销佣金支出\'\n	\n)  comment	\'小红书商品销售事实表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n---drop table  ODS_LRB_Commodity_sales ;\n\n\n----select * from  ODS_LRB_Commodity_sales limit 10;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-18 11:55:17', '2022-08-18 14:50:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (338, '7or9', 1, 183, 'dwd_LRB_refund', 'Job-2qbQNzF6Os3S2fLipkWe9sNvA5Z7w2Wx', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-18 05:46:27\n--********************************************************************--\n\n\n\n---小红书商品退款事实表\ncreate table dwd_LRB_refund (\n    platform	string	comment	\'平台\',\n	year 	string	comment	\'年\',\n	month 	string	comment	\'月\',\n	Total_expenditure string	comment	\'支出总额\',\n    Total_return_commission  string	comment	\'退货佣金总额\',\n    Package_return_number string	comment	\'退货包裹号\'\n	\n)  comment	\'小红书商品销售事实表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n---drop table  ODS_LRB_Commodity_sales ;\n\n\n----select * from  ODS_LRB_Commodity_sales limit 10;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-18 13:46:27', '2022-08-18 15:27:52', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (339, '7or9', 1, 186, 'ds2dwd_LRB_Commodity_sales', 'Job-w5BcpIjqmDCJfz9pX3ddgWHYTGSUiwtK', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-18 06:52:45\n--********************************************************************--\n\ninsert OVERWRITE table dwd_LRB_Commodity_sales  \nselect \n\'小红书\',\n\'2021\',\n\'11\',\n\'t1.order_number\',\n\'t1.Package_number\',\n\'t1.Item_ID\',\n\'t1.Total_revenue\',\n\'t1.Total_paid\',\n\'t1.Payment_channel_fee_commodity\',\n\'t1.Total_Commission\',\n\'t2.Package_number\',\n\'t2.Policy_amount\',\n\'t3.Package_number\',\n\'t3.Distribution_commission_expense\'\nfrom ODS_LRB_Commodity_sales  as t1\nleft join ODS_LRB_freight as t2\non  t1.Package_number= t2.Package_number\nleft join ODS_LRB_GPS_distribution as t3\non t1.Package_number =t3.Package_number;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-18 14:52:45', '2022-08-18 15:07:50', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (340, '7or9', 1, 186, 'ds2_dwd_LRB_refund', 'Job-WaimK4NKZ2wQFMl0Fhtdt3WmfsUUgseh', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-18 07:23:02\n--********************************************************************--\n\ninsert OVERWRITE table dwd_LRB_refund select\n\'小红书\',\n\'2021\',\n\'11\',\n\'Total_expenditure\',\n\'Total_return_commission\',\n\'Package_number\' \nfrom ODS_LRB_return_goods as t1\nunion all \nselect \n\'小红书\',\n\'2021\',\n\'11\',\n\'Expenditure_amount\',\n\'Commission_amount\',\n\'Package_number\' \nfrom ODS_LRB_Manual_refund as t2\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-18 15:23:02', '2022-08-18 15:39:05', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (344, 'bigdata', 1, 199, 'qingdao_jianpao_1', 'Job-s1psdyYRRpSfVqOrjLwP20KuVBTnvbpI', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-24 02:13:05\n--********************************************************************--\n\nload data \'/user/superior/users/fangchusheng/qingdao.csv\' table tdl_spark_tex options( delimiter=\',\',charset=\'gbk\',header=\'true\') ;\n--select * from tdl_spark_test limit 10;\n---insert overwrite table ods_Inventory_receipt_delivery select * from tdl_spark_tex ;\ncreate table ods_qingdao_check lifecycle 300 select * from tdl_spark_tex;\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-24 10:13:06', '2022-08-24 10:22:37', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (345, 'bigdata', 1, 199, 'ddl_qingdao_qqq', 'Job-RWgyWfbX23QGLz6pqeaevFBMkdOLL6tf', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      方楚生#fangchusheng\n-- create time: 2022-08-24 02:24:03\n--********************************************************************--\n\n---青岛表\ncreate table ods_qingdao_check (\n    type	string	comment	\'用户类型\',\n	number	string	comment	\'卡面人数\'\n\n)  comment	\'青岛表\'\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;\n\n\nselect * from  ods_qingdao_check', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '方楚生#fangchusheng', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-08-24 10:24:04', '2022-08-24 10:27:52', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_job` VALUES (346, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '怀信#huaixin', '怀信#huaixin', '', 1, 3, '2022-10-15 17:14:52', 1, 0, 'normal', 1, '0', 'p2', '', 'period', 3, 'sms,dingding', 2, 10, '2022-09-06 16:58:02', '2022-10-16 09:48:27', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job` VALUES (347, 'bigdata', 1, 200, 'test', 'Job-gNs675hDKxKZgvFnaIfIN44cD6hPp5mn', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      阿平#xuanwu\n-- create time: 2022-09-12 08:18:12\n--********************************************************************--\n\nselect count(1) from new_server.ydec.test_table;\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '阿平#xuanwu', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-12 16:18:13', '2022-09-28 23:31:54', '阿平#xuanwu', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (348, 'offline_sec', 1, 201, 'user_a_a', 'Job-H1tPqrkJeUfQZAtdcrCEbicaqipSF7nk', 'hangzhou-spark-3.2', '1', '--********************************************************************--\n-- author:      阿平#xuanwu\n-- create time: 2022-09-13 08:56:49\n--********************************************************************--\n\nselect * from ', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '阿平#xuanwu', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-13 16:56:49', '2022-09-13 16:57:16', '阿平#xuanwu', '阿平#xuanwu');
INSERT INTO `meta_job` VALUES (349, 'aoteledemo', 1, 88, 'test_t001', 'Job-4a956pJSeEpQGlPejqKJtrbXHercrF6f', 'hangzhou-spark-3.2', '800万数据', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-21 06:54:21\n--********************************************************************--\n	\nCREATE TABLE `test_table_dt` (\n  `time_col` varchar(255) ,\n  `year_col` varchar(255),\n  `month_col` varchar(255) ,\n  `day_col` varchar(255) ,\n  `store_type` varchar(255),\n  `store_code` varchar(255),\n  `matnr` varchar(255) ,\n  `ware_name` varchar(255) ,\n  `supplier_code` varchar(255),\n  `province_name` varchar(255) ,\n  `city_area_name` varchar(255),\n  `district_name` varchar(255) ,\n  `sale_have` float ,\n  `sale_no` float ,\n  `cost_have` float ,\n  `cost_no` float ,\n  `sale_num` float ,\n  `purchase_category1` varchar(255),\n  `supplier_name` varchar(255),\n  `brand_class` varchar(255) \n) \npartitioned by(ds string) \nlifecycle 20\n\n\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n)\nSINK(\"hive\") OPTIONS (\n  databaseName = \"aoteledemo\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210816\"\n);\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-21 14:54:21', '2022-09-24 09:28:12', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (350, 'aoteledemo', 1, 88, 'test001', 'Job-V5hHbalooET0kTTNmce7N1hjwecVZwCs', NULL, 'test', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-21 14:29:29\n--********************************************************************--\n\n', 'spark_sql', NULL, NULL, NULL, '不玄#buxuan', NULL, 0, 0, NULL, NULL, 0, 'normal', 0, '0', NULL, NULL, 'period', 6, NULL, NULL, NULL, '2022-09-21 22:29:30', '2022-09-21 22:29:30', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (351, 'bigdata', 1, 199, 'test_task', 'Job-edvSQAF3wYupONOMHSjRfwXw7EKCCbFE', 'hangzhou-spark-3.2', '测试任务', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 03:30:11\n--********************************************************************--\n\ndrop table if exists test_table_1;\ncreate table test_table_1(\n        date_col	string,\n        year_col	string,\n        month_col	string,\n        day_col	string,\n        store_type	string,\n        store_code	string,\n        matnr	string,\n        ware_name	string,\n        supplier_code	string,\n        province_name	string,\n        city_area_name	string,\n        district_name	string,\n        sale_tax	string,\n        sale_no	string,\n        cost_tax	string,\n        cost_no	string,\n        sale_num	string,\n        purchase_category1	string,\n        supplier_name	string,\n        brand_class	string,\n        region_class	string\n)\nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nLIFECYCLE 30;\n\n\ndatatunnel source(\"mysql\") options(\n    username=\"optimus_dev\",\n    password=\"optimus_dev\",\n    host=\'8.136.133.76\',\n    port=23306,\n    databaseName=\'pevc_reviw\', tableName=\'test_table_1\', columns=[\"*\"])\n    sink(\"hive\") options(databaseName=\"bigdata\", tableName=\'test_table_1\', writeMode=\'overwrite\', columns=[\"*\"]);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 11:30:12', '2022-09-23 18:30:08', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (353, 'aoteledemo', 1, 206, 'ods_create_table', 'Job-pYGhEItXj0Usp6WFI3E0B0aUdWNLl3bZ', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:06:47\n--********************************************************************--\ncreate table ods_basedata_di(\n        st_date  string,\n        material_code  string,\n        pp  string,\n        yjlm  string,\n        ejlm  string,\n        sjlm  string,\n        yjlyqd  string,\n        ejlyqd  string,\n        sjlyqd  string,\n        fks  string,\n        lll  string,\n        rjlll  string,\n        pjtlsc  string,\n        jgrs  string,\n        gzrs  string,\n        xdrs  string,\n        xdje  string,\n        cjrs  string,\n        cjje  string,\n        cjzhl  string,\n        kdj  string,\n        uvjz  string,\n        create_time  string,\n        update_time  string\n) \nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:06:47', '2022-09-26 09:44:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (354, 'aoteledemo', 1, 208, 'cdm_add_goods_di', 'Job-SbLEoGSMiDA3bZR4jktVpiepaIGgecYZ', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:19:04\n--********************************************************************--\n\ncreate table ods_basedata_add_goods_di(\n        st_date  string,\n        material_code  string,\n        pp  string,\n        yjlm  string,\n        ejlm  string,\n        sjlm  string,\n        yjlyqd  string,\n        ejlyqd  string,\n        sjlyqd  string,\n        fks  string,\n        lll  string,\n        rjlll  string,\n        pjtlsc  string,\n        jgrs  string,\n        gzrs  string,\n        xdrs  string,\n        xdje  string,\n        cjrs  string,\n        cjje  string,\n        cjzhl  string,\n        kdj  string,\n        uvjz  string,\n        create_time  string,\n        update_time  string,\n        spbh  string,\n        CAI  string,\n        pfmc  string,\n        cpmc  string,\n        zt  string,\n        ljsx string,\n        hw string,\n        dmk string,\n        bpb string,\n        lg string,\n        czzb string,\n        sdjb string,\n        DIM string,\n        xhlc string,\n        OE_Marking string,\n        tsbs string,\n        cpzl string,\n        gao string\n) \nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:19:04', '2022-09-23 17:30:41', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (355, 'aoteledemo', 1, 209, 'cdm_insert_di', 'Job-h43xmRbYHDoOIXlyDHGhrmFbb9VnB0RO', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:20:07\n--********************************************************************--\n\nINSERT INTO ods_basedata_add_goods_di\nSELECT t1.*,t2.* FROM ods_basedata_di t1\nleft join\nods_goods_di t2 \non t1.material_code = t2.spbh\n;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:20:08', '2022-09-23 17:36:15', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (356, 'aoteledemo', 1, 206, 'ods_create_goods_table', 'Job-C5RBBIcwF0i4S2560xa7K7JSRSq1ivrx', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:26:14\n--********************************************************************--\n\n\n\n\ninsert into ADS_Tyre_store_di\nselect \nst_date,\nsum(uv),\nsum(deal_num),\nsum(deal_gmv),\navg(Tu_rate),\navg(arpa),\nsum(sales),\navg(per_sales)\nfrom \nDWS_Tyre_sku_qd_add_goods_di\ngroup by st_date', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:26:14', '2022-09-26 13:51:42', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (357, 'aoteledemo', 1, 207, 'ods_input_data_goods', 'Job-peBMdjVEZKbyCitdb6mELV27fZROSdMd', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:27:53\n--********************************************************************--\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"root\",\n  password = \"hello1234\",\n  host = \'40.72.114.55\',\n  port = 3306,\n  databaseName = \'ydec\',\n  tableName = \'good_detail\',\n  columns = [\"*\"]\n)\nSINK(\"hive\") OPTIONS (\n  databaseName = \"aoteledemo\",\n  tableName = \'ods_goods_di\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"]\n);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:27:54', '2022-09-23 17:54:26', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (358, 'aoteledemo', 1, 210, 'ads_qd_di', 'Job-GeBjxLcvKtK7jUDZUuV277SM6vEPMMSt', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:37:59\n--********************************************************************--\n\ncreate table ads_qd_di(\n            hw string,\n            qd string,\n            uv\n) \nstored as ORC tblproperties (\'orc.compress\'=\'SNAPPY\')\nlifeCycle  300;', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:37:59', '2022-09-23 17:39:06', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (359, 'aoteledemo', 1, 211, 'ads_exp_pd_di', 'Job-ZGZDkCFGa5JjHeN4ZWo4zB9cP3Jxe6Hk', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-23 09:38:21\n--********************************************************************--\n\ninsert into ads_qd_di\nselect hw,yjlyqd,sum(fks) as uv from ods_basedata_add_goods_di group by hw,yjlyqd', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-23 17:38:21', '2022-09-23 17:51:04', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (361, 'bigdata', 1, 212, 'aaa', 'Job-gd2cM4jZbzJmrUCfWNAbJwPQAlJoTLhe', 'hangzhou-spark-3.2', 'as', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-29 09:04:01\n--********************************************************************--\n\nCREATE TABLE `test_table_dt` (\n  `time_col` varchar(255) ,\n  `year_col` varchar(255),\n  `month_col` varchar(255) ,\n  `day_col` varchar(255) ,\n  `store_type` varchar(255),\n  `store_code` varchar(255),\n  `matnr` varchar(255) ,\n  `ware_name` varchar(255) ,\n  `supplier_code` varchar(255),\n  `province_name` varchar(255) ,\n  `city_area_name` varchar(255),\n  `district_name` varchar(255) ,\n  `sale_have` float ,\n  `sale_no` float ,\n  `cost_have` float ,\n  `cost_no` float ,\n  `sale_num` float ,\n  `purchase_category1` varchar(255),\n  `supplier_name` varchar(255),\n  `brand_class` varchar(255) \n) \npartitioned by(ds string) \nlifecycle 20\n\n\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n)\nSINK(\"hive\") OPTIONS (\n  databaseName = \"aoteledemo\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210816\"\n);\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-29 17:04:01', '2022-09-29 17:04:24', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (362, 'test001', 1, 213, 'data_tunnel', 'Job-rxqDGXxPfVd6GotOTRfwcHlY2wI4gYSZ', 'hangzhou-spark-3.2', '数据同步', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-29 09:09:46\n--********************************************************************--\n\n--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-29 09:04:01\n--********************************************************************--\n\nCREATE TABLE `test_table_dt` (\n  `time_col` varchar(255) ,\n  `year_col` varchar(255),\n  `month_col` varchar(255) ,\n  `day_col` varchar(255) ,\n  `store_type` varchar(255),\n  `store_code` varchar(255),\n  `matnr` varchar(255) ,\n  `ware_name` varchar(255) ,\n  `supplier_code` varchar(255),\n  `province_name` varchar(255) ,\n  `city_area_name` varchar(255),\n  `district_name` varchar(255) ,\n  `sale_have` float ,\n  `sale_no` float ,\n  `cost_have` float ,\n  `cost_no` float ,\n  `sale_num` float ,\n  `purchase_category1` varchar(255),\n  `supplier_name` varchar(255),\n  `brand_class` varchar(255) \n) \npartitioned by(ds string) \nlifecycle 20\n\n\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  resultTableName = \'tdl_test_table\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n) TRANSFORM = \'select * from tdl_test_table where time_col=\"20210825\"\'\nSINK(\"hive\") OPTIONS (\n  databaseName = \"test001\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210816\"\n);\n\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  condition = \"time_col = \'20210826\'\"\n) \nSINK(\"hive\") OPTIONS (\n  databaseName = \"test001\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210817\"\n);\n\n\n\n\nselect count(1) from test_table_dt;\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-29 17:09:47', '2022-09-30 17:03:33', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (363, 'test001', 1, 213, 'dws_purchase_category1_di', 'Job-1z9RM2wYk6YpaM2MoPJ4iSWedvbIBwby', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 07:45:58\n--********************************************************************--\n\nCREATE TABLE `dws_purchase_category1_di` (\n    purchase_category1 varchar(10),\n    GMV float\n) \nlifecycle 20', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-30 15:45:58', '2022-09-30 07:47:49', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (364, 'test001', 1, 213, 'dws_purchase_category1_dj', 'Job-DmMsMFLfn1zcNM2VY3RwOvs6Zk0bzN7x', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 07:48:23\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 1, 1, NULL, 1, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-30 15:48:24', '2022-09-30 15:55:53', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (365, 'test001', 1, 213, 'dws_purchase_category1_dj', 'Job-DmMsMFLfn1zcNM2VY3RwOvs6Zk0bzN7x', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 07:48:23\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, NULL, '不玄#buxuan', '', 0, 0, NULL, 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-30 15:55:53', '2022-09-30 16:18:40', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (366, 'test001', 1, 213, 'dws_purchase_category2_dj', 'Job-UKTPorf7gNdD3NMDCKFPbOnYQ3gIK1Dn', 'hangzhou-spark-3.2', 'test', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:22:05\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', NULL, '不玄#buxuan', '不玄#buxuan', '', 1, 3, '2022-09-30 16:23:26', 0, 0, 'normal', 1, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-30 16:22:05', '2022-09-30 16:33:37', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (367, 'test001', 1, 213, 'ods_pevc_review_test_table_dj', 'Job-nKpLXu6EwzMA4WpfLVZnjvUhhhvLHMa7', 'hangzhou-spark-3.2', 'ss', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:26:59\n--********************************************************************--\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  resultTableName = \'tdl_test_table\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n) TRANSFORM = \'select * from tdl_test_table where time_col=\"20210826\"\'\nSINK(\"hive\") OPTIONS (\n  databaseName = \"test001\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210817\"\n);', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', '2022-10-17', '不玄#buxuan', '不玄#buxuan', '', 0, 3, '2022-09-30 16:30:06', 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-30 16:26:59', '2022-09-30 16:30:06', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (368, 'test001', 1, 213, 'dws_purchase_category2_dj', 'Job-UKTPorf7gNdD3NMDCKFPbOnYQ3gIK1Dn', 'hangzhou-spark-3.2', 'test', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:22:05\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', '2022-10-17', '不玄#buxuan', '不玄#buxuan', '', 0, 3, '2022-09-30 16:33:37', 0, 0, 'normal', 0, '0', 'p2', '', 'period', 6, NULL, NULL, NULL, '2022-09-30 16:33:23', '2022-09-30 16:33:37', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job` VALUES (379, 'bigdata', 1, 2, 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'hangzhou-spark-3.2', 'd', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n\n', 'spark_sql', 'bizdate=$[yyyyMMdd-1d]', '2022-10-17', '怀信#huaixin', '怀信#huaixin', '', 0, 3, '2022-10-16 09:48:27', 1, 0, 'normal', 0, '0', 'p2', '', 'period', 3, 'sms,dingding', 2, 10, '2022-10-16 09:47:57', '2022-10-16 09:48:27', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_alarm
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_alarm`;
CREATE TABLE `meta_job_alarm` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `job_code` varchar(45) COLLATE utf8_bin DEFAULT NULL COMMENT '作业类型',
  `workspace_code` varchar(45) COLLATE utf8_bin DEFAULT NULL COMMENT '项目code',
  `job_name` varchar(128) COLLATE utf8_bin NOT NULL COMMENT 'job名称',
  `type` varchar(20) COLLATE utf8_bin DEFAULT NULL COMMENT '作业类型',
  `wait_overtime` tinyint(4) DEFAULT '0' COMMENT '触发条件',
  `max_alarm_count` int(11) DEFAULT NULL COMMENT '最大告警次数',
  `alarm_interval` int(11) DEFAULT '60' COMMENT '告警间隔（分钟）',
  `receivers` varchar(500) COLLATE utf8_bin DEFAULT NULL COMMENT '接收人',
  `alarm_type` varchar(50) COLLATE utf8_bin DEFAULT NULL COMMENT '报警方式',
  `no_disturb_start` varchar(20) COLLATE utf8_bin DEFAULT NULL COMMENT '免打扰开始时间',
  `no_disturb_end` varchar(20) COLLATE utf8_bin DEFAULT NULL COMMENT '免打扰结束时间',
  `alarm_time` int(11) DEFAULT '0' COMMENT '运行超过多长时间告警，默认值：分钟任务，周期一半时间，小时任务：30分钟，其他任务：3小时',
  `wr_alarm_time` int(11) DEFAULT '0' COMMENT '等待运行超时告警间隔时间',
  `creater` varchar(45) COLLATE utf8_bin NOT NULL,
  `modifier` varchar(45) COLLATE utf8_bin DEFAULT NULL,
  `gmt_created` datetime NOT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `uk_job_code` (`job_code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=258 DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='告警表';

-- ----------------------------
-- Records of meta_job_alarm
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_alarm` VALUES (17, 'job-2ae9694f-ff71-481f-b5e2-592f31e5f6a4', 'bigdata', 'spark_jar_task', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '王凯#wangkai', '2021-07-09 22:52:01', '2022-09-23 18:11:42', 1);
INSERT INTO `meta_job_alarm` VALUES (20, 'job-c0596ed2-bdb2-4e0d-a08d-178ab5eb3ea3', 'bigdata', 'udf-demo', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-12 14:30:12', '2021-08-04 13:43:27', 1);
INSERT INTO `meta_job_alarm` VALUES (24, 'job-d1c70d20-217f-4a0f-abca-483f7ce41ea8', 'bigdata', 'read_write_file', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-13 10:56:18', '2021-08-30 16:05:36', 1);
INSERT INTO `meta_job_alarm` VALUES (27, 'job-a539cfb7-dceb-4766-9dfc-663ed135bf1f', 'bigdata', 'python_3th_pkg', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-13 16:21:10', '2021-08-30 11:47:36', 1);
INSERT INTO `meta_job_alarm` VALUES (33, 'job-012e4cd5-b758-4237-86c4-f05bae6fa7b4', 'bigdata', 'export_load_test', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-16 13:19:31', '2021-08-24 20:18:26', 1);
INSERT INTO `meta_job_alarm` VALUES (34, 'job-2577599e-0061-4542-95cd-f5be56432107', 'bigdata', 'dzlog', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-17 14:54:30', '2021-12-09 15:03:57', 1);
INSERT INTO `meta_job_alarm` VALUES (40, 'job-cdb2a5d4-341a-4e67-b11b-07b2acbe14e9', 'bigdata', 'puython_demo', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-28 19:29:30', '2021-09-16 09:53:11', 1);
INSERT INTO `meta_job_alarm` VALUES (42, 'job-c21d48f2-8cf9-430f-a89c-835e9ea30770', 'bigdata', 'demo_proxy_dj', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '方悟#fangwu', '2021-07-29 19:09:30', '2021-12-05 13:50:43', 1);
INSERT INTO `meta_job_alarm` VALUES (44, 'job-9b58e158-2445-436e-a5a0-4136565fa2b3', 'bigdata', 'month_last_day_mj', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-07-30 22:38:37', '2021-07-30 22:40:00', 1);
INSERT INTO `meta_job_alarm` VALUES (45, 'job-77ee55ec-d37c-4dd6-9073-e6bfab5dad67', 'bigdata', 'presto', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-08-02 23:06:47', '2021-12-11 18:25:21', 1);
INSERT INTO `meta_job_alarm` VALUES (48, 'job-c144b16b-64eb-4635-bd1b-602c75ac2b34', 'bigdata', 'hdfs-sftp', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-08-17 17:59:38', '2021-11-15 13:39:45', 1);
INSERT INTO `meta_job_alarm` VALUES (49, 'job-3a767cbc-d10d-4bc9-8c97-e5f4250e6956', 'bigdata', 'graphframes_demo', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-08-19 13:57:38', '2021-12-07 16:47:13', 1);
INSERT INTO `meta_job_alarm` VALUES (52, 'job-301d3a33-9d09-4fc8-a7b2-4a84fd897d71', 'bigdata', 'CLUSTER_BY_SQL', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-01 09:39:04', '2021-09-01 09:59:27', 1);
INSERT INTO `meta_job_alarm` VALUES (53, 'job-8f0162b4-99f3-4a77-b487-14c91b8fe0cd', 'bigdata', 'datax-hive', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-01 16:19:07', '2022-07-03 17:25:09', 1);
INSERT INTO `meta_job_alarm` VALUES (55, 'job-ec737d15-ec4d-42a4-8bb4-5af1d8071e9c', 'bigdata', 'hudi_partition_sql', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-03 10:47:50', '2022-06-22 16:01:54', 1);
INSERT INTO `meta_job_alarm` VALUES (57, 'job-56751358-4d81-4d24-862e-638a288313a5', 'bigdata', 'hudi_demo', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-07 13:28:57', '2022-09-09 14:26:25', 1);
INSERT INTO `meta_job_alarm` VALUES (59, 'job-4ffd8a6b-7d62-4e33-b450-78ef222c0ed9', 'bigdata', 'hudi_mor', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-13 11:14:17', '2022-07-14 19:06:54', 1);
INSERT INTO `meta_job_alarm` VALUES (60, 'job-36e6c257-4445-4203-9011-e300d61b9592', 'stream_bigdata', 'kafka_stream_json', 'job_stream', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-14 14:06:07', '2022-07-11 12:50:48', 1);
INSERT INTO `meta_job_alarm` VALUES (61, 'job-ed7fcda4-9b26-40f1-87c5-58a74dd33ac1', 'bigdata', 'python_demo', 'job', NULL, NULL, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-14 16:53:52', '2022-07-27 16:26:45', 1);
INSERT INTO `meta_job_alarm` VALUES (62, 'job-c7837bb3-3f7c-44b4-813b-41e130f32b06', 'stream_bigdata', 'kafka_stream_text', NULL, NULL, NULL, NULL, 'huaixin', NULL, NULL, NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '2021-09-15 12:20:50', '2021-09-15 18:56:07', 1);
INSERT INTO `meta_job_alarm` VALUES (72, 'job-337fe9b0-0fab-42fd-9228-7a5036e907cd', 'first', 'demo', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-10-28 13:24:53', '2021-10-28 13:28:02', 1);
INSERT INTO `meta_job_alarm` VALUES (77, 'job-172158b5-3386-4293-855a-46e2dea3345d', 'bigdata', 'demo', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-11-03 18:09:24', '2022-10-03 23:31:24', 1);
INSERT INTO `meta_job_alarm` VALUES (80, 'job-842ba0f8-8c2d-459c-9794-3bb617d356db', 'bigdata', 'datax-jdbc', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-11-08 14:31:33', '2022-09-24 13:36:05', 1);
INSERT INTO `meta_job_alarm` VALUES (84, 'job-7082765d-6d49-4301-a472-df2a0f25b4b3', 'bigdata', 'koalas_demo_dt', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-11-15 18:13:12', '2021-12-06 19:15:46', 1);
INSERT INTO `meta_job_alarm` VALUES (87, 'job-723e610f-d258-4d4a-9024-54b8c192ba3e', 'bigdata', 'spark_create_table', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-11-23 15:13:25', '2021-12-04 22:34:20', 1);
INSERT INTO `meta_job_alarm` VALUES (89, 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 'bigdata', 'demo_parent_dj', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '方悟#fangwu', '怀信#huaixin', '2021-12-05 13:49:28', '2022-10-04 18:17:25', 1);
INSERT INTO `meta_job_alarm` VALUES (90, 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 'bigdata', 'demo_child_dj', 'job', NULL, 10, 60, 'fangwu', 'sms,dingding', '', '', 360, NULL, '方悟#fangwu', '怀信#huaixin', '2021-12-05 13:50:05', '2021-12-29 10:16:18', 1);
INSERT INTO `meta_job_alarm` VALUES (91, 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 'bigdata', 'sql-test', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-12-05 13:57:55', '2022-09-05 23:16:49', 1);
INSERT INTO `meta_job_alarm` VALUES (101, 'job-f29bbf6a-4760-4853-9c60-9fc7862dce1f', 'bigdata', 'datax-kafka', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-12-10 17:37:56', '2022-02-25 15:32:29', 1);
INSERT INTO `meta_job_alarm` VALUES (103, 'Job-bCOzLTzLeCFZsjZInNxDMeSkO5ieCAYM', 'bigdata', 'dsd_dd_hj', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-12-11 00:16:45', '2022-09-10 00:44:07', 1);
INSERT INTO `meta_job_alarm` VALUES (127, 'Job-szfUJQietKs2zeEyrgmmyzyGl4XL9pzx', 'bigdata', 'python-lineage', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2021-12-28 13:55:00', '2022-09-06 16:55:43', 1);
INSERT INTO `meta_job_alarm` VALUES (148, 'Job-Gvwi9cE74Z72d1FsSjGX5vU7qGKTPkhS', 'bigdata', 'analyze', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2022-01-04 16:11:16', '2022-09-10 00:52:18', 1);
INSERT INTO `meta_job_alarm` VALUES (152, 'Job-fFi3vgoIKa5QBUmngCu4C3UKdUpO1eCG', 'bigdata', 'iceberg-demo', 'job', NULL, 10, 60, 'huaixin', 'sms,dingding', '', '', 360, NULL, '怀信#huaixin', '怀信#huaixin', '2022-03-11 22:51:56', '2022-06-09 11:48:16', 1);
INSERT INTO `meta_job_alarm` VALUES (153, 'Job-iWJdBPS6bmwHfWA9wZ3W0fFmcdZIn0lY', 'bigdata', 'ODS_T01', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-07-27 09:58:19', '2022-09-22 22:56:19', 1);
INSERT INTO `meta_job_alarm` VALUES (154, 'Job-d0AGtggSXUo6TejKCS9tXHPOQcgUdNKK', 'bigdata', 'dtunnel-jdbc', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '怀信#huaixin', '2022-07-28 23:48:56', '2022-09-06 16:51:57', 1);
INSERT INTO `meta_job_alarm` VALUES (157, 'Job-PAETda5TURZc0jcSffHyKyFCwO0Jkd9a', 'bigdata', 'mysql2hive', 'job', NULL, 10, 60, 'zerolin', 'sms,dingding', '', '', 360, NULL, '林庆贤#zerolin', '林庆贤#zerolin', '2022-08-01 17:30:28', '2022-08-02 18:46:14', 1);
INSERT INTO `meta_job_alarm` VALUES (159, 'Job-a39gg33SKhlX0i2GKLEhrravGI9zkmeq', 'bigdata', 'co', 'job', NULL, 10, 60, 'zerolin', 'sms,dingding', '', '', 360, NULL, '林庆贤#zerolin', '林庆贤#zerolin', '2022-08-06 13:29:33', '2022-08-06 13:33:47', 1);
INSERT INTO `meta_job_alarm` VALUES (162, 'Job-obbWRuaXaS6r3OHbhx6cre9Jmdh7yptL', 'aoteledemo', 'test', 'job', NULL, 10, 60, 'demo', 'sms,dingding', '', '', 360, NULL, 'demo#demo', '不玄#buxuan', '2022-08-09 14:19:41', '2022-09-28 23:06:18', 1);
INSERT INTO `meta_job_alarm` VALUES (164, 'Job-CONtizkfbok9gBs49doG17wpe3D12OaO', 'aoteledemo', 'fang_test', 'job', NULL, 10, 60, 'demo', 'sms,dingding', '', '', 360, NULL, 'demo#demo', 'demo#demo', '2022-08-10 11:20:46', '2022-08-11 15:35:16', 1);
INSERT INTO `meta_job_alarm` VALUES (184, 'job-ea490940-e12c-46e4-8b9f-e99cb25caa5a', 'aoteledemo', 'DDL_DWT_STORE_WARE_D', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-11 14:43:08', '2022-08-11 15:09:33', 1);
INSERT INTO `meta_job_alarm` VALUES (186, 'Job-TgVonHKwbIaVUpnCOxl7JfTfrKCeekDY', 'aoteledemo', 'DDL_DIM_PAWWAY_NEW', 'job', NULL, 10, 60, 'demo', 'sms,dingding', '', '', 360, NULL, 'demo#demo', 'demo#demo', '2022-08-11 15:20:15', '2022-08-11 15:39:37', 1);
INSERT INTO `meta_job_alarm` VALUES (187, 'Job-pubWiwpzQfkhCMJLJ4adwMriZMI9TFZj', '7or9', 'ADS_inventory_df', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-12 19:32:09', '2022-08-17 09:21:22', 1);
INSERT INTO `meta_job_alarm` VALUES (190, 'Job-FT11BYQNG3nZyZ0K2Hmvpf9XPr5tIm4b', '7or9', 'ds2ods_inventory_receipt', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-08-13 20:38:32', '2022-08-14 23:43:00', 1);
INSERT INTO `meta_job_alarm` VALUES (191, 'Job-QQ1RRe25OQ9u29r4FirnvyVemyan3xta', '7or9', 'ds2ods_Inventory_receipt_delivery', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-14 21:16:23', '2022-08-14 23:17:36', 1);
INSERT INTO `meta_job_alarm` VALUES (192, 'Job-iKRl4f1QJ45okdWOACquvDhnNyEWpWy5', '7or9', 'ds1ods_Inventory_receipt_delivery', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-15 09:12:03', '2022-08-17 11:46:44', 1);
INSERT INTO `meta_job_alarm` VALUES (193, 'Job-LJWJ6Rg9BF0NfnDgEoEe6vAdJb3BJkff', '7or9', 'dwd_inventory_recepit_202112', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-15 10:25:40', '2022-08-16 21:59:36', 1);
INSERT INTO `meta_job_alarm` VALUES (194, 'Job-heD1ZUb90q4OgrrnnVXgxyEOddUyVq6c', '7or9', 'ds1dwd_inventory_recepit_202112', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-15 11:12:46', '2022-08-16 16:15:50', 1);
INSERT INTO `meta_job_alarm` VALUES (196, 'Job-SabgMxtVtfyD02VFDNm2kOBURa0pBgvZ', '7or9', 'ds2ADS_inventory_df', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-15 14:49:08', '2022-08-16 13:45:48', 1);
INSERT INTO `meta_job_alarm` VALUES (197, 'Job-siQwmBFhUB2ktHXPHffnoiuGWNTmqEt0', '7or9', 'ODS_LRB_Commodity_sales', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-16 11:41:47', '2022-08-17 13:57:09', 1);
INSERT INTO `meta_job_alarm` VALUES (198, 'Job-5fb1l25uDMjSzXFLSPhT9yMsBODsGYmu', '7or9', 'ds3ADS_inventory_df', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-16 14:14:27', '2022-08-17 09:14:41', 1);
INSERT INTO `meta_job_alarm` VALUES (199, 'job-9f043952-4d7b-4693-ae28-30faff0f5e89', '7or9', 'ods_Inventory_receipt_delivery', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-16 16:40:56', '2022-08-16 23:19:04', 1);
INSERT INTO `meta_job_alarm` VALUES (200, 'Job-lapAPlvk37ogrwSIU9eQ2qDqfpIdWNXn', '7or9', 'ODS_LRB_freight', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 10:11:59', '2022-08-17 14:13:39', 1);
INSERT INTO `meta_job_alarm` VALUES (201, 'Job-ru4jW2uDslgubuBlWnARleP9Frvpjwr9', '7or9', 'ODS_LRB_return_goods', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 10:31:42', '2022-08-17 14:35:03', 1);
INSERT INTO `meta_job_alarm` VALUES (202, 'Job-sFVvDbwaFZTErxhOo69yYQbrEf2eAcpm', '7or9', 'ODS_LRB_Manual_refund', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 10:56:30', '2022-08-17 14:46:11', 1);
INSERT INTO `meta_job_alarm` VALUES (203, 'Job-EiqMp3vjoApH2qE5lCLoUsrIwHtMDgDm', '7or9', 'ODS_LRB_CPS_distribution', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 11:13:56', '2022-08-17 15:08:06', 1);
INSERT INTO `meta_job_alarm` VALUES (204, 'Job-blyyjrwzZcVsgO5DJGMyRUmrVS5ltwIm', '7or9', 'ds1_ODS_LRB_Commodity_sales', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 11:52:43', '2022-08-17 17:21:50', 1);
INSERT INTO `meta_job_alarm` VALUES (205, 'Job-y5xfBVp7YnUunXcHeOxRy3SkRaW6J0o2', '7or9', 'ds1_ODS_LRB_freight', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 14:06:13', '2022-08-17 14:09:47', 1);
INSERT INTO `meta_job_alarm` VALUES (206, 'Job-gDjNL0xdqGM7KxwBlH3MgCQ9reUtIVLA', '7or9', 'ds1_ODS_LRB_return_goods', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 14:23:36', '2022-08-17 14:23:36', 1);
INSERT INTO `meta_job_alarm` VALUES (207, 'Job-6eb77adGCzak610hEPC9DRRaLHvKcArm', '7or9', 'ds1_ODS_LRB_Manual_refund', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 14:42:00', '2022-08-17 14:42:00', 1);
INSERT INTO `meta_job_alarm` VALUES (208, 'Job-ycdiAqpqNUXiuxIt9dGk0YqX5l7lucbf', '7or9', 'ds1_ODS_LRB_CPS_distribution', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 14:52:05', '2022-08-17 14:59:22', 1);
INSERT INTO `meta_job_alarm` VALUES (209, 'Job-HGPidwHqWBB4HWXszPlAvzUvv7w3aJLe', '7or9', 'ODS_ODS_Gross_profit', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 16:33:21', '2022-08-17 17:30:29', 1);
INSERT INTO `meta_job_alarm` VALUES (210, 'Job-dFhN92E2JuDmrctpDfDe00TH7dJcEoJl', '7or9', 'ds1ODS_ODS_Gross_profit', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-17 17:22:29', '2022-08-17 17:22:29', 1);
INSERT INTO `meta_job_alarm` VALUES (211, 'Job-foKHyCVGdqd47dap3ShQ6GSmrUBb3L1U', '7or9', 'dim_Platform_gross_profit', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-18 10:02:44', '2022-08-18 13:36:54', 1);
INSERT INTO `meta_job_alarm` VALUES (212, 'Job-qGiVogGoGpbGqe23IyGYi44YKdWCAmqz', '7or9', 'ds1dim_Platform_gross_profit', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-18 10:43:15', '2022-08-18 11:43:13', 1);
INSERT INTO `meta_job_alarm` VALUES (213, 'Job-V3n5BVZ5OzIjh2r449XN05UT2hbsvUcK', '7or9', 'dwd_LRB_Commodity_sales', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-18 11:56:09', '2022-08-18 14:50:30', 1);
INSERT INTO `meta_job_alarm` VALUES (214, 'Job-2qbQNzF6Os3S2fLipkWe9sNvA5Z7w2Wx', '7or9', 'dwd_LRB_refund', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-18 13:47:10', '2022-08-18 15:27:52', 1);
INSERT INTO `meta_job_alarm` VALUES (215, 'Job-w5BcpIjqmDCJfz9pX3ddgWHYTGSUiwtK', '7or9', 'ds2dwd_LRB_Commodity_sales', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-18 14:53:37', '2022-08-18 15:07:50', 1);
INSERT INTO `meta_job_alarm` VALUES (216, 'Job-WaimK4NKZ2wQFMl0Fhtdt3WmfsUUgseh', '7or9', 'ds2_dwd_LRB_refund', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-18 15:25:06', '2022-08-18 15:39:05', 1);
INSERT INTO `meta_job_alarm` VALUES (220, 'Job-s1psdyYRRpSfVqOrjLwP20KuVBTnvbpI', 'bigdata', 'qingdao_jianpao_1', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-24 10:15:23', '2022-08-24 10:22:37', 1);
INSERT INTO `meta_job_alarm` VALUES (221, 'Job-RWgyWfbX23QGLz6pqeaevFBMkdOLL6tf', 'bigdata', 'ddl_qingdao_qqq', 'job', NULL, 10, 60, 'fangchusheng', 'sms,dingding', '', '', 360, NULL, '方楚生#fangchusheng', '方楚生#fangchusheng', '2022-08-24 10:25:04', '2022-08-24 10:27:52', 1);
INSERT INTO `meta_job_alarm` VALUES (222, 'Job-gNs675hDKxKZgvFnaIfIN44cD6hPp5mn', 'bigdata', 'test', 'job', NULL, 10, 60, 'xuanwu', 'sms,dingding', '', '', 360, NULL, '阿平#xuanwu', '不玄#buxuan', '2022-09-12 16:18:36', '2022-10-12 11:35:16', 1);
INSERT INTO `meta_job_alarm` VALUES (223, 'Job-H1tPqrkJeUfQZAtdcrCEbicaqipSF7nk', 'offline_sec', 'user_a_a', 'job', NULL, 10, 60, 'xuanwu', 'sms,dingding', '', '', 360, NULL, '阿平#xuanwu', '阿平#xuanwu', '2022-09-13 16:57:16', '2022-09-13 16:57:16', 1);
INSERT INTO `meta_job_alarm` VALUES (224, 'Job-4a956pJSeEpQGlPejqKJtrbXHercrF6f', 'aoteledemo', 'test_t001', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-21 14:54:44', '2022-09-24 09:28:12', 1);
INSERT INTO `meta_job_alarm` VALUES (225, 'Job-edvSQAF3wYupONOMHSjRfwXw7EKCCbFE', 'bigdata', 'test_task', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 11:30:42', '2022-09-23 18:30:08', 1);
INSERT INTO `meta_job_alarm` VALUES (226, 'Job-pYGhEItXj0Usp6WFI3E0B0aUdWNLl3bZ', 'aoteledemo', 'ods_create_table', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:08:52', '2022-09-26 09:44:36', 1);
INSERT INTO `meta_job_alarm` VALUES (228, 'Job-SbLEoGSMiDA3bZR4jktVpiepaIGgecYZ', 'aoteledemo', 'cdm_add_goods_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:19:24', '2022-09-23 17:30:41', 1);
INSERT INTO `meta_job_alarm` VALUES (229, 'Job-C5RBBIcwF0i4S2560xa7K7JSRSq1ivrx', 'aoteledemo', 'ods_create_goods_table', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:26:43', '2022-09-26 13:51:42', 1);
INSERT INTO `meta_job_alarm` VALUES (230, 'Job-peBMdjVEZKbyCitdb6mELV27fZROSdMd', 'aoteledemo', 'ods_input_data_goods', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:28:21', '2022-09-23 17:54:26', 1);
INSERT INTO `meta_job_alarm` VALUES (231, 'Job-h43xmRbYHDoOIXlyDHGhrmFbb9VnB0RO', 'aoteledemo', 'cdm_insert_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:31:18', '2022-09-23 17:36:15', 1);
INSERT INTO `meta_job_alarm` VALUES (232, 'Job-GeBjxLcvKtK7jUDZUuV277SM6vEPMMSt', 'aoteledemo', 'ads_qd_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:38:45', '2022-09-23 17:39:06', 1);
INSERT INTO `meta_job_alarm` VALUES (233, 'Job-ZGZDkCFGa5JjHeN4ZWo4zB9cP3Jxe6Hk', 'aoteledemo', 'ads_exp_pd_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-23 17:39:42', '2022-09-23 17:51:04', 1);
INSERT INTO `meta_job_alarm` VALUES (234, 'Job-gd2cM4jZbzJmrUCfWNAbJwPQAlJoTLhe', 'bigdata', 'aaa', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-29 17:04:24', '2022-09-29 17:04:24', 1);
INSERT INTO `meta_job_alarm` VALUES (235, 'Job-rxqDGXxPfVd6GotOTRfwcHlY2wI4gYSZ', 'test001', 'data_tunnel', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-29 17:10:10', '2022-09-30 17:03:33', 1);
INSERT INTO `meta_job_alarm` VALUES (236, 'Job-1z9RM2wYk6YpaM2MoPJ4iSWedvbIBwby', 'test001', 'dws_purchase_category1_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-30 15:46:22', '2022-09-30 15:47:30', 1);
INSERT INTO `meta_job_alarm` VALUES (237, 'Job-DmMsMFLfn1zcNM2VY3RwOvs6Zk0bzN7x', 'test001', 'dws_purchase_category1_dj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-30 15:48:47', '2022-09-30 16:18:40', 1);
INSERT INTO `meta_job_alarm` VALUES (238, 'Job-UKTPorf7gNdD3NMDCKFPbOnYQ3gIK1Dn', 'test001', 'dws_purchase_category2_dj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-30 16:22:24', '2022-09-30 16:33:24', 1);
INSERT INTO `meta_job_alarm` VALUES (239, 'Job-nKpLXu6EwzMA4WpfLVZnjvUhhhvLHMa7', 'test001', 'ods_pevc_review_test_table_dj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-09-30 16:29:30', '2022-09-30 16:29:55', 1);
INSERT INTO `meta_job_alarm` VALUES (240, 'Job-0fSKamjXUSVeU0JWDOw10QuTMWg1vpES', 'bigdata', 'ods_sap_skb1_dt', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-09 10:04:44', '2022-10-09 14:17:46', 1);
INSERT INTO `meta_job_alarm` VALUES (241, 'Job-En9adlnURrRVy2oWcvUoBG7DxjtfYORm', 'bigdata', 'dwd_skb1_trsf_bj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-09 14:10:58', '2022-10-09 14:17:41', 1);
INSERT INTO `meta_job_alarm` VALUES (242, 'Job-TGTZFcDG9USctwrJv6N5ThGFch0gDkoo', 'bigdata', 'ods_sap_skb1_input_dj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-09 14:27:28', '2022-10-09 14:27:28', 1);
INSERT INTO `meta_job_alarm` VALUES (243, 'Job-cBp6bEgNfkpSmvzTaDVBEpuDCcNbSfEZ', 'zhongtaiceshi2', 'create_table_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 10:37:53', '2022-10-13 10:47:18', 1);
INSERT INTO `meta_job_alarm` VALUES (244, 'Job-r5D7PiwZBBRey7fArhkBfkDCm7pMG00J', 'zhongtaiceshi2', 'input_table_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 10:50:05', '2022-10-13 10:52:39', 1);
INSERT INTO `meta_job_alarm` VALUES (245, 'Job-Ba4xLqmWVl7pnX43ZRIRQ2tlrEJCHsiu', 'zhongtaiceshi2', 'table_sum_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 10:54:38', '2022-10-13 10:56:43', 1);
INSERT INTO `meta_job_alarm` VALUES (246, 'Job-YkcasaNfwsqYdrf2r1MTS56dkfLCgW04', 'zhongtaiceshi2', 'output_table_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 10:58:25', '2022-10-13 11:02:30', 1);
INSERT INTO `meta_job_alarm` VALUES (247, 'Job-OE2pIO7BbjDHk1YArxqRFurd0jhhschh', 'zhongtaiceshi2', 'create_table_js_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:18:09', '2022-10-13 11:18:50', 1);
INSERT INTO `meta_job_alarm` VALUES (248, 'Job-EaFb2KYg4zxbnWKBHb3v41M7NyklwLQ1', 'zhongtaiceshi2', 'table_insert_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:19:50', '2022-10-13 11:20:25', 1);
INSERT INTO `meta_job_alarm` VALUES (249, 'Job-EDgQcN5V0WRDXLWXdkloPefEdpECO4RH', 'zhongtaiceshi2', 'table_print_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:21:15', '2022-10-13 11:21:15', 1);
INSERT INTO `meta_job_alarm` VALUES (250, 'Job-V9YlW9VdlnIKwPhShD9bgplTYFj1CEZr', 'zhongtaiceshi2', 'create_table_dd_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:33:50', '2022-10-13 11:33:50', 1);
INSERT INTO `meta_job_alarm` VALUES (251, 'Job-Z6NeAQ0RJc4C4OpwqFPnt7iq0H4idGU3', 'zhongtaiceshi2', 'table_dd_hour_hj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:34:32', '2022-10-13 11:37:58', 1);
INSERT INTO `meta_job_alarm` VALUES (252, 'Job-TgjbOKlLnsP0jybbgvrc7CIWW6DvKX9M', 'zhongtaiceshi2', 'create_table_dd_t1_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:41:08', '2022-10-13 11:41:08', 1);
INSERT INTO `meta_job_alarm` VALUES (253, 'Job-oQUZbF5t909Do1AMkP2YGVcgHbsQoiy0', 'zhongtaiceshi2', 'create_dd_t1_dj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:41:42', '2022-10-13 11:42:28', 1);
INSERT INTO `meta_job_alarm` VALUES (254, 'Job-D79xdM10HDaF237qd4hX7P3hT7zGlRqn', 'zhongtaiceshi2', 'create_table_dd_cf_di', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:46:12', '2022-10-13 11:46:12', 1);
INSERT INTO `meta_job_alarm` VALUES (255, 'Job-blMv01VMhachDejEfZFWT1hIxFwQj9wQ', 'zhongtaiceshi2', 'create_dd_cf_dj', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:47:24', '2022-10-13 11:48:02', 1);
INSERT INTO `meta_job_alarm` VALUES (256, 'Job-KAEBI0Inv9Z0kZMRnAWD5k0ZE7Hu9KLc', 'zhongtaiceshi2', 'test', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 11:56:00', '2022-10-13 11:56:23', 1);
INSERT INTO `meta_job_alarm` VALUES (257, 'Job-No4jk17JWFNClN1hs4kceZxUjkaTDOe9', 'test_del', 'create_table_01', 'job', NULL, 10, 60, 'buxuan', 'sms,dingding', '', '', 360, NULL, '不玄#buxuan', '不玄#buxuan', '2022-10-13 14:30:59', '2022-10-13 14:30:59', 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_job_instance
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_instance`;
CREATE TABLE `meta_job_instance` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `workspace_code` varchar(45) DEFAULT NULL COMMENT '项目code',
  `data_center` varchar(64) DEFAULT NULL,
  `code` varchar(45) NOT NULL,
  `name` varchar(512) DEFAULT NULL,
  `cluster_code` varchar(64) DEFAULT NULL,
  `yarn_queue` varchar(128) DEFAULT NULL,
  `dependent_code` varchar(1024) DEFAULT NULL COMMENT '依赖上一个实例code',
  `job_name` varchar(128) DEFAULT NULL COMMENT 'job名称',
  `job_code` varchar(45) DEFAULT NULL,
  `job_id` int(11) DEFAULT NULL,
  `job_type` varchar(45) DEFAULT NULL,
  `type` varchar(45) NOT NULL DEFAULT 'test' COMMENT '开发实例：dev\n调度实例：schedule\n测试实例：test\n补数据实例：supplement',
  `version` int(11) NOT NULL DEFAULT '0',
  `status` varchar(32) NOT NULL DEFAULT '0' COMMENT '1：等待运行，3：等待资源，5：运行中，7：运行失败，9：运行成功， 11：暂停， 13：终止',
  `schedule_start` datetime DEFAULT NULL COMMENT '调度开始时间',
  `run_start` datetime DEFAULT NULL COMMENT '运行开始时间',
  `run_end` datetime DEFAULT NULL COMMENT '运行结束时间',
  `owner` varchar(64) NOT NULL,
  `proxy_user` varchar(64) DEFAULT NULL COMMENT '代理用户',
  `bizdate` varchar(64) DEFAULT NULL COMMENT '业务日期：yyyy-MM-dd\n',
  `rundate` varchar(64) DEFAULT NULL COMMENT '运行日期：yyyy-MM-dd',
  `run_mode` varchar(45) DEFAULT NULL COMMENT '运行模式：jobserver, thriftserver',
  `runtimes` int(11) DEFAULT '0' COMMENT '运行时间，单位秒',
  `last_notify_time` datetime DEFAULT NULL COMMENT '待删除',
  `wait_notify_time` datetime DEFAULT NULL COMMENT '待删除',
  `run_notify_time` datetime DEFAULT NULL COMMENT '待删除',
  `spark_application_id` varchar(128) DEFAULT 'spark app id',
  `empty_schedule` int(11) NOT NULL DEFAULT '0' COMMENT '空跑调度',
  `last_period_code` varchar(128) DEFAULT NULL COMMENT '上一周期实例code',
  `pipeline_data` text COMMENT '数据管道，用于上游作业传递数据给下游作业',
  `run_timeout_hour` int(11) DEFAULT NULL COMMENT '运行超时时间终止任务',
  `wait_timeout_hour` int(11) DEFAULT NULL COMMENT '等待运行超时时间告警',
  `retry_enabled` smallint(6) DEFAULT '1' COMMENT '出错重试：0 暂停，1开启',
  `retry_max_count` int(11) DEFAULT '0' COMMENT '告警最大次数',
  `retry_count` int(11) DEFAULT NULL COMMENT '已经重试次数',
  `retry_interval_minute` int(11) DEFAULT NULL COMMENT '重试间隔',
  `retry_definition` smallint(6) DEFAULT NULL COMMENT '重跑定义',
  `alarm_method` varchar(128) DEFAULT NULL COMMENT '告警方法',
  `alarm_max_count` int(11) DEFAULT '0' COMMENT '告警最大次数',
  `alarm_count` int(11) DEFAULT '0' COMMENT '已经告警次数',
  `alarm_interval_minute` int(11) DEFAULT NULL COMMENT '告警间隔',
  `last_alarm_time` datetime DEFAULT NULL COMMENT '上次告警时间',
  `gmt_created` datetime NOT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) NOT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `code_UNIQUE` (`code`) USING BTREE,
  KEY `project_code_index` (`workspace_code`) USING BTREE,
  KEY `job_code_index` (`job_code`) USING BTREE,
  KEY `type_index` (`type`) USING BTREE,
  KEY `spark_app_id_index` (`spark_application_id`) USING BTREE,
  KEY `idx_name` (`name`(128)) USING BTREE,
  KEY `idx_schedule_start` (`schedule_start`) USING BTREE,
  KEY `idx_gmt_modified` (`gmt_modified`) USING BTREE,
  KEY `idx_gmt_create` (`gmt_created`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=42 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_job_instance
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_instance` VALUES (1, 1, 'test001', NULL, 'uib4wLlCqd3kt41hAlnjARTOp9bVDU4y', 'ods_pevc_review_test_table_dj', 'hangzhou-spark-3.2', NULL, 'start', 'ods_pevc_review_test_table_dj', 'Job-nKpLXu6EwzMA4WpfLVZnjvUhhhvLHMa7', 367, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-12 00:00:00', NULL, '2022-10-14 22:36:12', '不玄#buxuan', '', '2022-10-11', '2022-10-12', 'jobserver', NULL, '2022-10-18 04:31:53', NULL, NULL, NULL, 0, NULL, NULL, NULL, 6, 0, NULL, 1, NULL, NULL, NULL, NULL, 11, NULL, NULL, '2022-10-12 23:26:08', '2022-10-14 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (2, 1, 'test001', NULL, 'epXkn0l9BSJtdxskS5fBYonS2iqOOiVt', 'dws_purchase_category2_dj', 'hangzhou-spark-3.2', NULL, 'uib4wLlCqd3kt41hAlnjARTOp9bVDU4y', 'dws_purchase_category2_dj', 'Job-UKTPorf7gNdD3NMDCKFPbOnYQ3gIK1Dn', 368, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-12 00:00:00', NULL, '2022-10-14 22:36:12', '不玄#buxuan', '', '2022-10-11', '2022-10-12', 'jobserver', NULL, '2022-10-18 04:31:53', NULL, NULL, NULL, 0, NULL, NULL, NULL, 6, 0, NULL, 1, NULL, NULL, NULL, NULL, 11, NULL, NULL, '2022-10-12 23:26:08', '2022-10-14 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (3, 1, 'bigdata', NULL, 'iIwYd26N6LwuKMdOeJHmkYbwjXd0ewg4', 'week_job1', 'hangzhou-spark-3.2', NULL, 'start', 'week_job1', 'Job-Sba6df6EAI0qUfpFDWUDjwoASBOeXwQA', 373, 'spark_sql', 'schedule', 0, 'SUCCESS', '2022-10-12 00:35:00', '2022-10-14 22:36:12', '2022-10-14 22:36:12', '怀信#huaixin', '', '2022-10-11', '2022-10-12', 'jobserver', NULL, NULL, NULL, NULL, NULL, 1, NULL, NULL, NULL, 6, 0, NULL, 1, NULL, NULL, 'sms,dingding', 2, 0, 10, NULL, '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (5, 1, 'bigdata', NULL, 'Gii3sighSZOMUOaqnzPOP6DkBMt9HZDU', 'hour_job', 'hangzhou-spark-3.2', NULL, '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', 'hour_job', '5qEge7uMUSf2XkoLnYCuS1BRtvHwTYfN', 374, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-12 00:00:00', NULL, '2022-10-14 22:36:12', '怀信#huaixin', '', '2022-10-11', '2022-10-12', 'jobserver', NULL, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 0, 2, 1, 10, 2, 'sms,dingding', 2, 0, 10, NULL, '2022-10-12 23:26:08', '2022-10-14 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (6, 1, 'bigdata', NULL, 'CMCYogMY0IIbMUcrr7iuK2wnvtpr7TBD', 'hour_job', 'hangzhou-spark-3.2', NULL, '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', 'hour_job', '5qEge7uMUSf2XkoLnYCuS1BRtvHwTYfN', 374, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-12 07:00:00', NULL, '2022-10-14 22:36:12', '怀信#huaixin', '', '2022-10-11', '2022-10-12', 'jobserver', NULL, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 0, 2, 1, 10, 2, 'sms,dingding', 2, 0, 10, NULL, '2022-10-12 23:26:08', '2022-10-14 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (7, 1, 'bigdata', NULL, 'rIZGQdzeL62aNrGLyEFz1ewsrBpzxlDn', 'hour_job', 'hangzhou-spark-3.2', NULL, '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', 'hour_job', '5qEge7uMUSf2XkoLnYCuS1BRtvHwTYfN', 374, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-12 15:00:00', NULL, '2022-10-14 22:36:12', '怀信#huaixin', '', '2022-10-11', '2022-10-12', 'jobserver', NULL, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 0, 2, 1, 10, 2, 'sms,dingding', 2, 0, 10, NULL, '2022-10-12 23:26:09', '2022-10-14 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (8, 1, 'bigdata', NULL, 'j6Gg3wc70DAfG5Tjey53kD4gXaJ2GF0E', 'day_job', 'hangzhou-spark-3.2', NULL, 'iIwYd26N6LwuKMdOeJHmkYbwjXd0ewg4', 'day_job', 'Job-aHCsQGWeidZvdbNtGGaSefzmvM6l6wLk', 377, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-12 00:00:00', NULL, '2022-10-14 22:36:12', '怀信#huaixin', '', '2022-10-11', NULL, 'jobserver', NULL, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-12 23:56:08', '2022-10-14 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (9, 1, 'bigdata', NULL, 'iiGVMZxzuGPKkl6hUrepQKcAjnqoTlK1', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 16:56:07', '2022-10-15 16:56:07', '2022-10-15 16:56:08', '怀信#huaixin', '', '2022-10-15', NULL, 'jobserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 16:56:07', '2022-10-15 16:56:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (10, 1, 'bigdata', NULL, '9eAhgd0jP3enETlbnQtATaPisghH91K4', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 16:58:14', '2022-10-15 16:58:14', '2022-10-15 16:58:29', '怀信#huaixin', '', '2022-10-15', NULL, 'thriftserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 16:58:14', '2022-10-15 16:58:29', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (11, 1, 'bigdata', NULL, 'XNbiiElVIFTDgPqSceuOoC5oUX2aMhjL', 'demo_parent_dj', 'hangzhou-spark-3.2', NULL, 'NO_BUIIL_INSTANCE_DEPENDENT', 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 346, 'spark_sql', 'schedule', 0, 'SUCCESS', '2022-10-15 00:00:00', '2022-10-15 22:13:57', '2022-10-15 22:14:01', '怀信#huaixin', '', '2022-10-14', NULL, 'jobserver', 3919, NULL, NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, 24, 6, 1, 1, 7, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-15 17:14:52', '2022-10-15 22:14:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (12, 1, 'bigdata', NULL, '6XluzPtU0tPmAqK2FdZwccTZ0EydGqZG', 'demo_child_dj', 'hangzhou-spark-3.2', NULL, 'NO_BUIIL_INSTANCE_DEPENDENT', 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 232, 'spark_python', 'schedule', 0, 'FAILURE', '2022-10-15 00:00:00', '2022-10-15 22:14:02', '2022-10-15 22:14:04', '怀信#huaixin', '', '2022-10-14', NULL, 'jobserver', 2467, '2022-10-18 04:31:53', NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, 24, 6, 1, 1, 3, NULL, NULL, 'SMS', 1, 11, 10, NULL, '2022-10-15 17:15:01', '2022-10-15 22:14:04', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (13, 1, 'bigdata', NULL, 'mPwvhuwDSufr5Gd4J6GxHeOKvwiwMHA5', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 17:33:43', '2022-10-15 17:33:43', '2022-10-15 17:33:50', '怀信#huaixin', '', '2022-10-15', NULL, 'thriftserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 17:33:43', '2022-10-15 17:33:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (14, 1, 'bigdata', NULL, '2GEknMloAv5fkbUdh2prbLOpArAGerPk', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 17:33:54', '2022-10-15 17:33:54', '2022-10-15 17:33:54', '怀信#huaixin', '', '2022-10-15', NULL, 'jobserver', NULL, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 17:33:54', '2022-10-15 17:33:54', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (15, 1, 'bigdata', NULL, 'T4Ccxvu6ukjNeislDg1SSZ9ZVID0erXC', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 18:48:55', '2022-10-15 18:48:55', '2022-10-15 18:48:55', '怀信#huaixin', '', '2022-10-15', NULL, 'jobserver', NULL, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 18:48:55', '2022-10-15 18:48:55', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (16, 1, 'bigdata', NULL, 'JgjF1P5g49QsaSgBKs1omeECHvg9eaEb', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 18:50:32', '2022-10-15 18:50:32', '2022-10-15 18:50:32', '怀信#huaixin', '', '2022-10-15', NULL, 'jobserver', NULL, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 18:50:32', '2022-10-15 18:50:32', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (17, 1, 'bigdata', NULL, 'YObhUBZHcbq4UGuatd0oDQjjCLipqtxk', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 18:50:42', '2022-10-15 18:50:42', '2022-10-15 18:50:53', '怀信#huaixin', '', '2022-10-15', NULL, 'jobserver', NULL, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 18:50:42', '2022-10-15 18:50:53', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (18, 1, 'bigdata', NULL, '0EbxIDxUMbMGzkDiXdLMrQ43Wmjb1U5b', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 19:11:08', '2022-10-15 19:11:10', '2022-10-15 19:11:17', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 6681, NULL, NULL, NULL, 'application_1665585149227_0007', 1, NULL, NULL, 24, 6, 1, 1, 3, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-15 19:11:08', '2022-10-15 19:11:17', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (19, 1, 'bigdata', NULL, 'zvEcf5mBSLGIjiR9CfEl6TRci9lnD7JT', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 19:11:31', '2022-10-15 19:11:31', '2022-10-15 19:11:37', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 19:11:31', '2022-10-15 19:11:37', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (20, 1, 'bigdata', NULL, 'ko5KaJJYsOOemUJcBhRDAbr6r2ECRaqu', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 19:11:59', '2022-10-15 19:11:59', '2022-10-15 19:12:01', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'thriftserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 19:11:59', '2022-10-15 19:12:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (21, 1, 'bigdata', NULL, '3AOXFsseE21PlVPe09YdXQ0zjvqlqI7K', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 19:12:06', '2022-10-15 19:12:06', '2022-10-15 19:12:14', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 8295, NULL, NULL, NULL, 'application_1665585149227_0007', 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-15 19:12:06', '2022-10-15 19:12:14', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (22, 1, 'bigdata', NULL, 'cqAFJfVlMt3qONJETE1Z29zRvkcJMcTb', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 19:12:22', '2022-10-15 19:12:22', '2022-10-15 19:12:33', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 10590, NULL, NULL, NULL, 'application_1665585149227_0007', 1, NULL, NULL, 24, 6, 1, 1, 3, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-15 19:12:22', '2022-10-15 19:12:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (23, 1, 'bigdata', NULL, 'XySnMihcmzaOZ2FnPFgdS9pZQbcZCfho', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 19:12:49', '2022-10-15 19:12:50', '2022-10-15 19:12:52', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 1832, NULL, NULL, NULL, 'application_1665585149227_0007', 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-15 19:12:49', '2022-10-15 19:12:52', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (24, 1, 'bigdata', NULL, 'jEJSbaG3vmLsh6TYVwV7IZYU4K0jW27E', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 20:18:25', '2022-10-15 20:18:32', '2022-10-15 20:18:47', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 15454, NULL, NULL, NULL, 'application_1665585149227_0008', 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-15 20:18:25', '2022-10-15 20:18:47', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (25, 1, 'bigdata', NULL, 'dO31mKPwo0eTrb6ShXqJcibFHa4R6CkA', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 20:23:36', '2022-10-15 20:23:36', '2022-10-15 20:23:36', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 20:23:36', '2022-10-15 20:23:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (26, 1, 'bigdata', NULL, 'cD2cYRlwlgfFIufJoERjBVAVDu1bnQYv', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 20:39:36', '2022-10-15 20:39:36', '2022-10-15 20:39:36', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 1, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 20:39:36', '2022-10-15 20:39:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (27, 1, 'bigdata', NULL, 'pDMde6ycRoLNYWGokLLGDAukbNfQni05', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 20:40:12', '2022-10-15 20:40:12', '2022-10-15 20:40:43', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 20:40:12', '2022-10-15 20:40:43', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (28, 1, 'bigdata', NULL, 'PJxSWZbgTbQCEezPcUEKxcUrdJNrIhS6', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 20:43:46', '2022-10-15 20:43:46', '2022-10-15 20:43:48', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 20:43:46', '2022-10-15 20:43:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (29, 1, 'bigdata', NULL, 'brbmdMVTZuXldIVQJ7BQk44fDtJAN9BH', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 20:45:07', '2022-10-15 20:45:07', '2022-10-15 20:45:08', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 20:45:07', '2022-10-15 20:45:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (30, 1, 'bigdata', NULL, 'QO7NsC9PnoYwK2dAvS94h13dE66Q0yJg', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 22:12:50', '2022-10-15 22:12:50', '2022-10-15 22:12:50', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 22:12:50', '2022-10-15 22:12:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (31, 1, 'bigdata', NULL, '9gIbbeaYbTAwidR4AFo1C7idiPbpWw9y', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 22:13:08', '2022-10-15 22:13:08', '2022-10-15 22:13:09', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 22:13:08', '2022-10-15 22:13:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (32, 1, 'bigdata', NULL, 'Zfc1adMeqaIxFhzWu5uvwLTnPbbCqsrk', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'FAILURE', '2022-10-15 22:13:28', '2022-10-15 22:13:28', '2022-10-15 22:13:28', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'jobserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 22:13:28', '2022-10-15 22:13:28', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (33, 1, 'bigdata', NULL, 'NfIKTOuTOAftNBsWLa6RXCB6o14WXzf2', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 22:13:33', '2022-10-15 22:13:33', '2022-10-15 22:13:34', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'thriftserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 22:13:33', '2022-10-15 22:13:34', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (34, 1, 'bigdata', NULL, 'A4BBXv2J5hhlaSZdvv9ahfpjS7hpGPjm', 'sql-test', 'hangzhou-spark-3.2', NULL, NULL, 'sql-test', 'job-ee4bdf25-566e-474c-b58a-31f3f5e6bdb0', 1, 'spark_sql', 'dev', 0, 'SUCCESS', '2022-10-15 22:13:41', '2022-10-15 22:13:41', '2022-10-15 22:13:42', '怀信#huaixin', '', '2022-10-15', '2022-10-15', 'thriftserver', 0, NULL, NULL, NULL, NULL, 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 1, 10, NULL, '2022-10-15 22:13:41', '2022-10-15 22:13:42', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (35, 1, 'test001', NULL, 'ECGtvwrAfzp4iVbVRU7xYHezdRCfeTD5', 'ods_pevc_review_test_table_dj', 'hangzhou-spark-3.2', NULL, 'start', 'ods_pevc_review_test_table_dj', 'Job-nKpLXu6EwzMA4WpfLVZnjvUhhhvLHMa7', 367, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-16 00:00:00', '2022-10-16 00:05:14', '2022-10-16 00:05:14', '不玄#buxuan', '', '2022-10-15', '2022-10-16', 'jobserver', 43, '2022-10-18 04:31:53', NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, NULL, 6, 0, NULL, 4, NULL, NULL, NULL, NULL, 11, NULL, NULL, '2022-10-15 23:30:00', '2022-10-16 00:05:14', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance` VALUES (36, 1, 'test001', NULL, '4MXPyp4OAyrQ4ZGkXtvrl31wHWd0DfI9', 'dws_purchase_category2_dj', 'hangzhou-spark-3.2', NULL, 'ECGtvwrAfzp4iVbVRU7xYHezdRCfeTD5', 'dws_purchase_category2_dj', 'Job-UKTPorf7gNdD3NMDCKFPbOnYQ3gIK1Dn', 368, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-16 00:00:00', '2022-10-16 00:00:08', '2022-10-16 00:00:09', '不玄#buxuan', '', '2022-10-15', '2022-10-16', 'jobserver', 601, '2022-10-18 04:31:53', NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, NULL, 6, 0, NULL, 3, NULL, NULL, NULL, NULL, 11, NULL, NULL, '2022-10-15 23:30:00', '2022-10-16 00:00:09', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance` VALUES (37, 1, 'bigdata', NULL, 'nl3YBuG3gPtGJcWBI3xUl5nTZk4tbvGM', 'demo_parent_dj', 'hangzhou-spark-3.2', NULL, 'NO_BUIIL_INSTANCE_DEPENDENT', 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 379, 'spark_sql', 'schedule', 0, 'SUCCESS', '2022-10-16 00:00:00', '2022-10-16 09:48:35', '2022-10-16 09:48:36', '怀信#huaixin', '', '2022-10-15', '2022-10-16', 'jobserver', 1011, NULL, NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, 24, 6, 1, 1, 1, NULL, NULL, 'SMS', 1, 0, 10, NULL, '2022-10-16 09:48:27', '2022-10-16 09:48:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (38, 1, 'test001', NULL, 'xWWl6GY4CTIMZyD4JZsUpfQznAOr4Gy1', 'ods_pevc_review_test_table_dj', 'hangzhou-spark-3.2', NULL, 'start', 'ods_pevc_review_test_table_dj', 'Job-nKpLXu6EwzMA4WpfLVZnjvUhhhvLHMa7', 367, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-17 00:00:00', '2022-10-17 00:00:06', '2022-10-17 00:00:06', '不玄#buxuan', '', '2022-10-16', '2022-10-17', 'jobserver', -62, '2022-10-18 04:31:53', NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, NULL, 6, 0, NULL, 3, NULL, NULL, NULL, NULL, 11, NULL, NULL, '2022-10-16 23:30:00', '2022-10-17 00:00:06', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance` VALUES (39, 1, 'test001', NULL, 'xRzC1JC3NtABe5L0seLnbaCZACckW9nE', 'dws_purchase_category2_dj', 'hangzhou-spark-3.2', NULL, 'xWWl6GY4CTIMZyD4JZsUpfQznAOr4Gy1', 'dws_purchase_category2_dj', 'Job-UKTPorf7gNdD3NMDCKFPbOnYQ3gIK1Dn', 368, 'spark_sql', 'schedule', 0, 'FAILURE', '2022-10-17 00:00:00', '2022-10-17 00:05:27', '2022-10-17 00:05:27', '不玄#buxuan', '', '2022-10-16', '2022-10-17', 'jobserver', 457, '2022-10-18 04:31:53', NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, NULL, 6, 0, NULL, 4, NULL, NULL, NULL, NULL, 11, NULL, NULL, '2022-10-16 23:30:00', '2022-10-17 00:05:27', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance` VALUES (40, 1, 'bigdata', NULL, 'wvYMWCqp4JAHrWMxg6zs7TGbNbgHKAK5', 'demo_parent_dj', 'hangzhou-spark-3.2', NULL, 'start', 'demo_parent_dj', 'job-32728cb2-91cf-4ce1-9e49-ad17b569590b', 379, 'spark_sql', 'schedule', 0, 'SUCCESS', '2022-10-17 00:00:00', '2022-10-17 00:05:17', '2022-10-17 00:05:18', '怀信#huaixin', '', '2022-10-16', '2022-10-17', 'jobserver', 1217, '2022-10-17 00:05:07', NULL, NULL, 'application_1665585149227_0008', 0, NULL, NULL, NULL, 6, 1, NULL, 2, NULL, NULL, 'sms,dingding', 2, 0, 10, NULL, '2022-10-16 23:30:00', '2022-10-17 00:05:18', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance` VALUES (41, 1, 'bigdata', NULL, 'AitrNppzS6PzO7MRfGunGUpatOhCtImD', 'demo_child_dj', 'hangzhou-spark-3.2', NULL, 'wvYMWCqp4JAHrWMxg6zs7TGbNbgHKAK5', 'demo_child_dj', 'job-c409c76b-ed86-42e1-aaba-df7763c462b2', 232, 'spark_python', 'schedule', 0, 'FAILURE', '2022-10-17 00:00:00', NULL, NULL, '怀信#huaixin', '', '2022-10-16', '2022-10-17', 'jobserver', NULL, '2022-10-18 03:31:52', NULL, NULL, NULL, 0, NULL, NULL, 25, 6, 1, 2, 3, 10, 2, 'sms,dingding', 2, 11, 2, NULL, '2022-10-16 23:30:00', '2022-10-17 00:10:14', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_instance_content
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_instance_content`;
CREATE TABLE `meta_job_instance_content` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `code` varchar(45) NOT NULL COMMENT '实例code',
  `job_text` longtext COMMENT '作业内容',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '修改人',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `uk_code` (`code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=42 DEFAULT CHARSET=utf8mb4 COMMENT='实例内容表';

-- ----------------------------
-- Records of meta_job_instance_content
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_instance_content` VALUES (1, 'uib4wLlCqd3kt41hAlnjARTOp9bVDU4y', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:26:59\n--********************************************************************--\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  resultTableName = \'tdl_test_table\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n) TRANSFORM = \'select * from tdl_test_table where time_col=\"20210826\"\'\nSINK(\"hive\") OPTIONS (\n  databaseName = \"test001\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210817\"\n);', '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (2, 'epXkn0l9BSJtdxskS5fBYonS2iqOOiVt', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:22:05\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (3, 'iIwYd26N6LwuKMdOeJHmkYbwjXd0ewg4', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-10-09 23:32:33\n--********************************************************************--\n\nselect 1', '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (4, '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-10-09 22:48:10\n--********************************************************************--\n\nselect 1', '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (5, 'Gii3sighSZOMUOaqnzPOP6DkBMt9HZDU', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-10-12 12:45:28\n--********************************************************************--\n\nselect 1', '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (6, 'CMCYogMY0IIbMUcrr7iuK2wnvtpr7TBD', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-10-12 12:45:28\n--********************************************************************--\n\nselect 1', '2022-10-12 23:26:08', '2022-10-12 23:26:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (7, 'rIZGQdzeL62aNrGLyEFz1ewsrBpzxlDn', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-10-12 12:45:28\n--********************************************************************--\n\nselect 1', '2022-10-12 23:26:09', '2022-10-12 23:26:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (8, 'j6Gg3wc70DAfG5Tjey53kD4gXaJ2GF0E', '--********************************************************************--\n-- author:      怀信#huaixin\n-- create time: 2022-10-09 22:48:10\n--********************************************************************--\n\nselect 223', '2022-10-12 23:56:08', '2022-10-12 23:56:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (9, 'iiGVMZxzuGPKkl6hUrepQKcAjnqoTlK1', 'CREATE TABLE test_demo_dt (name string, age int)\nusing parquet\nLIFECYCLE 10;', '2022-10-15 16:56:07', '2022-10-15 16:56:07', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (10, '9eAhgd0jP3enETlbnQtATaPisghH91K4', 'CREATE TABLE test_demo_dt (name string, age int)\nusing parquet\nLIFECYCLE 10;', '2022-10-15 16:58:14', '2022-10-15 16:58:14', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (11, 'XNbiiElVIFTDgPqSceuOoC5oUX2aMhjL', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n\n', '2022-10-15 17:14:52', '2022-10-15 17:14:52', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (12, '6XluzPtU0tPmAqK2FdZwccTZ0EydGqZG', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n\ndef main(sparkSession):\n    print(\"hello spark\")\n\n', '2022-10-15 17:15:01', '2022-10-15 17:15:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (13, 'mPwvhuwDSufr5Gd4J6GxHeOKvwiwMHA5', '\nCREATE TABLE test_demo_dt1 (name string, age int)\nusing parquet\nLIFECYCLE 10;', '2022-10-15 17:33:43', '2022-10-15 17:33:43', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (14, '2GEknMloAv5fkbUdh2prbLOpArAGerPk', 'INSERT INTO table test_demo_test1 VALUES ( null, 23);\n', '2022-10-15 17:33:54', '2022-10-15 17:33:54', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (15, 'T4Ccxvu6ukjNeislDg1SSZ9ZVID0erXC', 'INSERT INTO table test_demo_test1 VALUES ( null, 23);\n', '2022-10-15 18:48:55', '2022-10-15 18:48:55', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (16, 'JgjF1P5g49QsaSgBKs1omeECHvg9eaEb', 'INSERT INTO table test_demo_test1 VALUES ( null, 23);\n', '2022-10-15 18:50:32', '2022-10-15 18:50:32', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (17, 'YObhUBZHcbq4UGuatd0oDQjjCLipqtxk', 'INSERT INTO table test_demo_test1 VALUES ( null, 23);\n', '2022-10-15 18:50:42', '2022-10-15 18:50:42', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (18, '0EbxIDxUMbMGzkDiXdLMrQ43Wmjb1U5b', 'INSERT INTO table test_demo_test1 VALUES ( null, 23);\n', '2022-10-15 19:11:08', '2022-10-15 19:11:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (19, 'zvEcf5mBSLGIjiR9CfEl6TRci9lnD7JT', 'CREATE TABLE test_demo_dt1 (name string, age int)\nusing parquet\nLIFECYCLE 10;', '2022-10-15 19:11:31', '2022-10-15 19:11:31', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (20, 'ko5KaJJYsOOemUJcBhRDAbr6r2ECRaqu', 'CREATE TABLE test_demo_test1 (name string, age int)\nusing parquet\nLIFECYCLE 10;', '2022-10-15 19:11:59', '2022-10-15 19:11:59', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (21, '3AOXFsseE21PlVPe09YdXQ0zjvqlqI7K', 'INSERT INTO table test_demo_test1 VALUES ( \'zhangsan\', 23);\n', '2022-10-15 19:12:06', '2022-10-15 19:12:06', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (22, 'cqAFJfVlMt3qONJETE1Z29zRvkcJMcTb', 'select * from test_demo_test1\n', '2022-10-15 19:12:22', '2022-10-15 19:12:22', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (23, 'XySnMihcmzaOZ2FnPFgdS9pZQbcZCfho', 'select * from test_demo_test1\n', '2022-10-15 19:12:49', '2022-10-15 19:12:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (24, 'jEJSbaG3vmLsh6TYVwV7IZYU4K0jW27E', 'INSERT INTO table test_demo_test1 VALUES ( \'zhangsan\', 23);\n', '2022-10-15 20:18:25', '2022-10-15 20:18:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (25, 'dO31mKPwo0eTrb6ShXqJcibFHa4R6CkA', 'drop table if exists test_demo_dt;\n', '2022-10-15 20:23:36', '2022-10-15 20:23:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (26, 'cD2cYRlwlgfFIufJoERjBVAVDu1bnQYv', 'drop table if exists test_demo_dt;\n', '2022-10-15 20:39:36', '2022-10-15 20:39:36', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (27, 'pDMde6ycRoLNYWGokLLGDAukbNfQni05', 'drop table if exists test_demo_dt;\n', '2022-10-15 20:40:12', '2022-10-15 20:40:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (28, 'PJxSWZbgTbQCEezPcUEKxcUrdJNrIhS6', 'drop table if exists test_demo_dt;\n', '2022-10-15 20:43:46', '2022-10-15 20:43:46', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (29, 'brbmdMVTZuXldIVQJ7BQk44fDtJAN9BH', 'drop table if exists test_demo_dt;\n', '2022-10-15 20:45:07', '2022-10-15 20:45:07', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (30, 'QO7NsC9PnoYwK2dAvS94h13dE66Q0yJg', 'CREATE TABLE test_demo_dt (name string, age int)\npartitioned by (ds) \nusing parquet\nLIFECYCLE 10;', '2022-10-15 22:12:50', '2022-10-15 22:12:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (31, '9gIbbeaYbTAwidR4AFo1C7idiPbpWw9y', 'CREATE TABLE test_demo_dt (name string, age int)\nusing parquet\npartitioned by (ds) \nLIFECYCLE 10;', '2022-10-15 22:13:08', '2022-10-15 22:13:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (32, 'Zfc1adMeqaIxFhzWu5uvwLTnPbbCqsrk', 'CREATE TABLE test_demo_dt (name string, age int, ds String)\nusing parquet\npartitioned by (ds) \nLIFECYCLE 10;', '2022-10-15 22:13:28', '2022-10-15 22:13:28', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (33, 'NfIKTOuTOAftNBsWLa6RXCB6o14WXzf2', 'drop table if exists test_demo_dt;\n', '2022-10-15 22:13:33', '2022-10-15 22:13:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (34, 'A4BBXv2J5hhlaSZdvv9ahfpjS7hpGPjm', 'CREATE TABLE test_demo_dt (name string, age int, ds String)\nusing parquet\npartitioned by (ds) \nLIFECYCLE 10;', '2022-10-15 22:13:41', '2022-10-15 22:13:41', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (35, 'ECGtvwrAfzp4iVbVRU7xYHezdRCfeTD5', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:26:59\n--********************************************************************--\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  resultTableName = \'tdl_test_table\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n) TRANSFORM = \'select * from tdl_test_table where time_col=\"20210826\"\'\nSINK(\"hive\") OPTIONS (\n  databaseName = \"test001\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210817\"\n);', '2022-10-15 23:30:00', '2022-10-15 23:30:00', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance_content` VALUES (36, '4MXPyp4OAyrQ4ZGkXtvrl31wHWd0DfI9', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:22:05\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', '2022-10-15 23:30:00', '2022-10-15 23:30:00', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance_content` VALUES (37, 'nl3YBuG3gPtGJcWBI3xUl5nTZk4tbvGM', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n\n', '2022-10-16 09:48:27', '2022-10-16 09:48:27', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (38, 'xWWl6GY4CTIMZyD4JZsUpfQznAOr4Gy1', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:26:59\n--********************************************************************--\n\nDATATUNNEL SOURCE(\"mysql\") OPTIONS (\n  username = \"optimus_dev\",\n  password = \"optimus_dev\",\n  host = \'8.136.133.76\',\n  port = 23306,\n  databaseName = \'pevc_reviw\',\n  resultTableName = \'tdl_test_table\',\n  tableName = \'test_table\',\n  columns = [\"*\"],\n  partitionColumn=\"month_col\",\n  lowerBound=0,\n  upperBound=12,\n  numPartitions=12\n) TRANSFORM = \'select * from tdl_test_table where time_col=\"20210826\"\'\nSINK(\"hive\") OPTIONS (\n  databaseName = \"test001\",\n  tableName = \'test_table_dt\',\n  writeMode = \'overwrite\',\n  columns = [\"*\"],\n  partition=\"ds=20210817\"\n);', '2022-10-16 23:30:00', '2022-10-16 23:30:00', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance_content` VALUES (39, 'xRzC1JC3NtABe5L0seLnbaCZACckW9nE', '--********************************************************************--\n-- author:      不玄#buxuan\n-- create time: 2022-09-30 08:22:05\n--********************************************************************--\n\ninsert into dws_purchase_category1_di\nselect purchase_category1,sum(sale_have) as gmv from test_table_dt group by purchase_category1', '2022-10-16 23:30:00', '2022-10-16 23:30:00', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_instance_content` VALUES (40, 'wvYMWCqp4JAHrWMxg6zs7TGbNbgHKAK5', '--********************************************************************--\n-- author:      管理员#admin\n-- create time: 2021-06-24 16:44:08\n--********************************************************************--\n\ninsert overwrite table test_demo_dt partition(ds=\'${bizdate}\') values(\'zhangsan\', 23);\n\n', '2022-10-16 23:30:00', '2022-10-16 23:30:00', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_content` VALUES (41, 'AitrNppzS6PzO7MRfGunGUpatOhCtImD', '#********************************************************************\n# author:      管理员#admin\n# create time: 2021-06-24 17:10:59\n#********************************************************************\n\ndef main(sparkSession):\n    print(\"hello spark\")\n\n', '2022-10-16 23:30:00', '2022-10-16 23:30:00', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_instance_dependent
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_instance_dependent`;
CREATE TABLE `meta_job_instance_dependent` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'id',
  `code` varchar(45) NOT NULL COMMENT 'code',
  `dependent_code` varchar(45) NOT NULL COMMENT 'dependent_code',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '修改人',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `uk_code` (`code`,`dependent_code`) USING BTREE,
  KEY `idx_code` (`code`) USING BTREE,
  KEY `idx_dependent_code` (`dependent_code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=10 DEFAULT CHARSET=utf8mb4 COMMENT='实例依赖表';

-- ----------------------------
-- Records of meta_job_instance_dependent
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_instance_dependent` VALUES (1, 'rIZGQdzeL62aNrGLyEFz1ewsrBpzxlDn', '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', '2022-10-12 23:26:09', '2022-10-12 23:26:09', '管理员#admin', '管理员#admin');
INSERT INTO `meta_job_instance_dependent` VALUES (2, 'CMCYogMY0IIbMUcrr7iuK2wnvtpr7TBD', '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', '2022-10-12 23:26:09', '2022-10-12 23:26:09', '管理员#admin', '管理员#admin');
INSERT INTO `meta_job_instance_dependent` VALUES (3, 'epXkn0l9BSJtdxskS5fBYonS2iqOOiVt', 'uib4wLlCqd3kt41hAlnjARTOp9bVDU4y', '2022-10-12 23:26:09', '2022-10-12 23:26:09', '管理员#admin', '管理员#admin');
INSERT INTO `meta_job_instance_dependent` VALUES (4, 'Gii3sighSZOMUOaqnzPOP6DkBMt9HZDU', '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', '2022-10-12 23:26:09', '2022-10-12 23:26:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_dependent` VALUES (5, '5IaVaPg6MfYfFrsM6j56odemjq2neE1s', 'iIwYd26N6LwuKMdOeJHmkYbwjXd0ewg4', '2022-10-12 23:26:09', '2022-10-12 23:26:09', '管理员#admin', '管理员#admin');
INSERT INTO `meta_job_instance_dependent` VALUES (6, 'j6Gg3wc70DAfG5Tjey53kD4gXaJ2GF0E', 'iIwYd26N6LwuKMdOeJHmkYbwjXd0ewg4', '2022-10-12 23:56:08', '2022-10-12 23:56:08', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_instance_dependent` VALUES (7, '4MXPyp4OAyrQ4ZGkXtvrl31wHWd0DfI9', 'ECGtvwrAfzp4iVbVRU7xYHezdRCfeTD5', '2022-10-15 23:30:00', '2022-10-15 23:30:00', '管理员#admin', '管理员#admin');
INSERT INTO `meta_job_instance_dependent` VALUES (8, 'xRzC1JC3NtABe5L0seLnbaCZACckW9nE', 'xWWl6GY4CTIMZyD4JZsUpfQznAOr4Gy1', '2022-10-16 23:30:00', '2022-10-16 23:30:00', '管理员#admin', '管理员#admin');
INSERT INTO `meta_job_instance_dependent` VALUES (9, 'AitrNppzS6PzO7MRfGunGUpatOhCtImD', 'wvYMWCqp4JAHrWMxg6zs7TGbNbgHKAK5', '2022-10-16 23:30:00', '2022-10-16 23:30:00', '管理员#admin', '管理员#admin');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_io_table
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_io_table`;
CREATE TABLE `meta_job_io_table` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `workspace_code` varchar(45) NOT NULL COMMENT '项目code',
  `job_id` int(11) DEFAULT NULL,
  `mode` varchar(45) NOT NULL COMMENT '输入或输出：input、output',
  `io_table` varchar(128) DEFAULT NULL,
  `job_code` varchar(45) DEFAULT NULL COMMENT '输入或者输出表所在任务ID(上一个输出的jobId）',
  `old_io_table` varchar(256) DEFAULT NULL COMMENT '旧to_table',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `fk_sc_job_io_table_dc_job1_idx` (`job_id`) USING BTREE,
  KEY `idx_mode` (`mode`) USING BTREE,
  KEY `idx_io_table` (`io_table`) USING BTREE,
  KEY `idx_mode_io_table` (`io_table`,`mode`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=273 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_job_io_table
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_io_table` VALUES (233, 'aoteledemo', 269, 'input', 'root_node', NULL, NULL, '2022-08-10 10:54:48', '2022-08-10 10:54:48', 'demo#demo', 'demo#demo');
INSERT INTO `meta_job_io_table` VALUES (234, 'aoteledemo', 269, 'output', 'aoteledemo.fcs_test', NULL, NULL, '2022-08-10 10:54:48', '2022-08-10 10:54:48', 'demo#demo', 'demo#demo');
INSERT INTO `meta_job_io_table` VALUES (235, 'aoteledemo', 357, 'input', 'root_node', '', NULL, '2022-09-23 17:54:26', '2022-09-23 17:54:26', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (236, 'aoteledemo', 357, 'output', 'aoteledemo.ods_input_data_goods', '', NULL, '2022-09-23 17:54:26', '2022-09-23 17:54:26', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (237, 'aoteledemo', 352, 'input', 'root_node', '', NULL, '2022-09-23 17:54:35', '2022-09-26 09:57:20', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (238, 'aoteledemo', 352, 'output', 'aoteledemo.ods_input_data_dj', '', NULL, '2022-09-23 17:54:35', '2022-09-26 09:57:20', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (239, 'aoteledemo', 356, 'input', 'root_node', '', NULL, '2022-09-26 09:55:34', '2022-09-26 13:51:42', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (240, 'aoteledemo', 356, 'output', 'aoteledemo.ods_create_goods_table', '', NULL, '2022-09-26 09:55:34', '2022-09-26 13:51:42', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (241, 'test001', 364, 'input', 'root_node', '', NULL, '2022-09-30 15:52:51', '2022-09-30 15:52:51', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (242, 'test001', 364, 'output', 'test001.dws_purchase_category1_dj', '', NULL, '2022-09-30 15:52:51', '2022-09-30 15:52:51', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (243, 'test001', 365, 'input', 'root_node', '', 'root_node', '2022-09-30 15:55:53', '2022-09-30 16:18:40', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (244, 'test001', 365, 'output', 'test001.dws_purchase_category1_di', '', 'test001.dws_purchase_category1_dj', '2022-09-30 15:55:53', '2022-09-30 16:18:40', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (247, 'test001', 367, 'input', 'root_node', '', NULL, '2022-09-30 16:29:50', '2022-09-30 16:29:55', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (248, 'test001', 367, 'output', 'test001.ods_pevc_review_test_table_dj', '', NULL, '2022-09-30 16:29:50', '2022-09-30 16:29:55', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (249, 'test001', 368, 'input', 'test001.ods_pevc_review_test_table_dj', '367', 'root_node', '2022-09-30 16:33:23', '2022-09-30 16:33:25', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (250, 'test001', 368, 'output', 'test001.dws_purchase_category2_dj', '', 'test001.dws_purchase_category1_di', '2022-09-30 16:33:23', '2022-09-30 16:33:25', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_job_io_table` VALUES (253, 'bigdata', 373, 'input', 'root_node', '', 'root_node', '2022-10-09 23:47:05', '2022-10-09 23:47:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (254, 'bigdata', 373, 'output', 'bigdata.week_job1', '', 'bigdata.week_job1', '2022-10-09 23:47:05', '2022-10-09 23:47:09', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (257, 'bigdata', 374, 'input', 'bigdata.day_job', '377', NULL, '2022-10-12 12:46:54', '2022-10-12 12:46:58', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (258, 'bigdata', 374, 'output', 'bigdata.hour_job', '', NULL, '2022-10-12 12:46:54', '2022-10-12 12:46:58', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (263, 'bigdata', 377, 'input', 'bigdata.week_job1', '373', 'bigdata.week_job1', '2022-10-12 23:38:10', '2022-10-12 23:38:14', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (264, 'bigdata', 377, 'output', 'bigdata.day_job', '', 'bigdata.day_job', '2022-10-12 23:38:10', '2022-10-12 23:38:14', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (265, 'bigdata', 378, 'input', 'bigdata.week_job1', '373', 'bigdata.week_job1', '2022-10-12 23:51:23', '2022-10-12 23:51:29', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (266, 'bigdata', 378, 'output', 'bigdata.day_job', '', 'bigdata.day_job', '2022-10-12 23:51:23', '2022-10-12 23:51:29', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (269, 'bigdata', 232, 'input', 'bigdata.test_demo_dt', '379', NULL, '2022-10-15 17:14:56', '2022-10-15 17:14:57', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (270, 'bigdata', 232, 'output', 'bigdata.demo_child_dj', '', NULL, '2022-10-15 17:14:56', '2022-10-15 17:14:57', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (271, 'bigdata', 379, 'input', 'root_node', '', 'root_node', '2022-10-16 09:47:57', '2022-10-16 09:48:03', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_job_io_table` VALUES (272, 'bigdata', 379, 'output', 'bigdata.test_demo_dt', '', 'bigdata.test_demo_dt', '2022-10-16 09:47:57', '2022-10-16 09:48:03', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_scheduler
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_scheduler`;
CREATE TABLE `meta_job_scheduler` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `workspace_code` varchar(45) NOT NULL COMMENT '项目code',
  `job_id` int(11) DEFAULT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `period` varchar(45) DEFAULT NULL COMMENT '调度周期：day、week、month、hour, minute',
  `effect_start_time` varchar(45) DEFAULT NULL COMMENT '调度有效开始时间，格式: yyyy-MM-dd',
  `effect_end_time` varchar(45) DEFAULT NULL COMMENT '调度有效结束时间，格式: yyyy-MM-dd',
  `specific_time` varchar(45) DEFAULT NULL COMMENT '调度周期为day, week, month，具体时间。格式：hh:mm',
  `select_month` varchar(256) DEFAULT NULL COMMENT '年调度周期，选择月份',
  `select_time` varchar(256) DEFAULT NULL COMMENT '调度周期为week, month，选择时间',
  `start_time` varchar(45) DEFAULT NULL COMMENT '调度周期为hour，开始时间。格式：hh:mm',
  `end_time` varchar(45) DEFAULT NULL COMMENT '调度周期为hour，结束时间。格式：hh:mm',
  `interval_time` varchar(45) DEFAULT NULL COMMENT '调度周期为hour，时间间隔',
  `run_timeout_hour` int(11) DEFAULT NULL COMMENT '运行超时时间终止任务',
  `retry_definition` smallint(6) DEFAULT NULL COMMENT '重跑定义',
  `retry_enabled` smallint(6) DEFAULT '0' COMMENT '出错重试：0 暂停，1开启',
  `retry_max_count` int(11) DEFAULT NULL COMMENT '重试最大次数',
  `retry_interval_minute` varchar(255) DEFAULT NULL COMMENT '重试间隔',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `uk_job_id` (`job_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=343 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_job_scheduler
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_scheduler` VALUES (25, 'bigdata', 26, '2021-07-09 22:52:01', '2022-09-23 18:11:42', '怀信#huaixin', '王凯#wangkai', 'day', '1970-01-01', '2031-07-09', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (32, 'bigdata', 33, '2021-07-12 14:30:12', '2021-08-04 13:43:26', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-12', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (38, 'bigdata', 41, '2021-07-13 10:56:18', '2021-08-30 16:05:36', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-13', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (43, 'bigdata', 47, '2021-07-13 16:21:10', '2021-08-30 11:47:36', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-13', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (59, 'bigdata', 64, '2021-07-16 13:19:31', '2021-08-24 20:18:26', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-16', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (60, 'bigdata', 65, '2021-07-17 14:54:30', '2021-12-09 15:03:57', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (61, 'bigdata', 66, '2021-07-19 14:14:53', '2021-08-18 17:38:54', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (91, 'bigdata', 97, '2021-07-28 19:21:23', '2021-08-23 16:08:01', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (92, 'bigdata', 98, '2021-07-28 19:29:30', '2021-09-16 09:53:11', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (93, 'bigdata', 99, '2021-07-28 19:45:21', '2021-07-28 19:45:21', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-06-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (96, 'bigdata', 102, '2021-07-28 20:21:30', '2021-09-16 11:11:01', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-06-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (97, 'bigdata', 103, '2021-07-29 19:09:17', '2021-07-29 19:10:17', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (98, 'bigdata', 104, '2021-07-30 10:41:37', '2021-07-30 10:41:42', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (99, 'bigdata', 105, '2021-07-30 10:41:59', '2021-07-30 10:42:00', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (100, 'bigdata', 106, '2021-07-30 10:42:07', '2021-07-30 11:01:30', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (102, 'bigdata', 108, '2021-07-30 11:27:06', '2021-11-09 10:59:08', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (103, 'bigdata', 109, '2021-07-30 22:38:37', '2021-07-30 22:40:00', '怀信#huaixin', '怀信#huaixin', 'month', '1970-01-01', '2031-07-30', '00:00', NULL, '100,2', '', '', '', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (104, 'bigdata', 111, '2021-08-13 14:36:32', '2021-08-29 15:25:45', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-08-13', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (105, 'bigdata', 112, '2021-08-16 17:14:48', '2021-08-17 17:56:20', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-08-16', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (106, 'bigdata', 113, '2021-08-17 17:59:38', '2021-11-15 13:39:45', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (107, 'bigdata', 114, '2021-08-18 18:00:23', '2021-08-18 18:05:00', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (108, 'bigdata', 115, '2021-08-18 18:06:08', '2021-08-18 18:07:08', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (109, 'bigdata', 116, '2021-08-18 18:07:19', '2021-08-18 18:10:11', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (110, 'bigdata', 117, '2021-08-18 18:13:57', '2021-08-18 18:14:17', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (111, 'bigdata', 118, '2021-08-19 13:57:38', '2021-12-07 16:47:13', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-08-19', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (112, 'bigdata', 119, '2021-08-23 15:14:50', '2021-08-23 15:14:50', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-08-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (114, 'bigdata', 127, '2021-09-01 09:39:04', '2021-09-01 09:59:27', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-09-01', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (115, 'bigdata', 128, '2021-09-01 16:19:07', '2022-07-03 17:25:09', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-09-01', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (117, 'bigdata', 131, '2021-09-03 10:47:50', '2022-06-22 16:01:54', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-09-03', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (119, 'bigdata', 133, '2021-09-07 13:28:57', '2022-09-09 14:26:25', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-09-07', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (120, 'bigdata', 135, '2021-09-13 11:14:17', '2022-07-14 19:06:54', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-09-13', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (121, 'bigdata', 137, '2021-09-14 16:53:52', '2022-07-27 16:26:45', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-09-14', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (134, 'first', 155, '2021-10-28 13:24:53', '2021-10-28 13:28:02', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-10-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (139, 'bigdata', 124, '2021-11-03 18:09:24', '2022-10-05 22:41:00', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-11-03', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (142, 'bigdata', 162, '2021-11-08 14:31:33', '2022-09-24 13:36:05', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-11-08', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (146, 'bigdata', 170, '2021-11-15 18:13:12', '2021-11-18 14:18:54', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-11-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (149, 'bigdata', 180, '2021-11-23 15:13:25', '2021-12-04 22:34:20', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-11-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (151, 'bigdata', 184, '2021-12-05 13:49:28', '2021-12-05 13:49:28', '方悟#fangwu', '方悟#fangwu', 'day', '1970-01-01', '2031-06-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (152, 'bigdata', 185, '2021-12-05 13:50:05', '2021-12-05 13:50:07', '方悟#fangwu', '方悟#fangwu', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (153, 'bigdata', 186, '2021-12-05 13:50:43', '2021-12-05 13:50:43', '方悟#fangwu', '方悟#fangwu', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (154, 'bigdata', 1, '2021-12-05 13:57:55', '2022-10-15 22:13:27', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-12-05', '00:00', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (155, 'bigdata', 187, '2021-12-05 22:13:54', '2021-12-06 19:15:46', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-11-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (156, 'bigdata', 188, '2021-12-06 11:14:26', '2021-12-24 15:40:26', '致意#zhiyi', '怀信#huaixin', 'day', '1970-01-01', '2031-12-06', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (157, 'bigdata', 189, '2021-12-06 16:21:43', '2021-12-29 14:53:54', '齐观#qiguan', '齐观#qiguan', 'day', '1970-01-01', '2031-12-06', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (158, 'bigdata', 190, '2021-12-06 16:35:08', '2022-01-13 09:52:26', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-06', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (159, 'bigdata', 191, '2021-12-07 14:59:36', '2022-01-08 22:12:28', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-07', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (160, 'bigdata', 192, '2021-12-09 15:00:56', '2021-12-09 15:38:38', '王颖#wangying', '王颖#wangying', 'hour', '1970-01-01', '2031-12-09', '', NULL, '', '00:00', '23:59', '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (161, 'bigdata', 193, '2021-12-09 15:42:22', '2021-12-10 15:43:43', '王颖#wangying', '王颖#wangying', 'hour', '1970-01-01', '2031-12-09', '', NULL, '', '00:00', '23:59', '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (162, 'bigdata', 194, '2021-12-10 10:36:23', '2021-12-10 10:36:36', '王颖#wangying', '王颖#wangying', 'hour', '1970-01-01', '2031-12-09', '', NULL, '', '00:00', '23:59', '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (163, 'bigdata', 195, '2021-12-10 10:40:17', '2021-12-10 10:42:59', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-09', '07:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (164, 'bigdata', 196, '2021-12-10 11:45:33', '2021-12-10 16:12:55', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-09', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (165, 'bigdata', 197, '2021-12-10 15:46:12', '2021-12-10 15:46:29', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-09', '07:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (166, 'bigdata', 198, '2021-12-10 16:14:15', '2021-12-10 16:14:16', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-09', '07:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (167, 'bigdata', 199, '2021-12-10 16:17:15', '2021-12-10 17:36:12', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (168, 'bigdata', 200, '2021-12-10 17:37:56', '2022-02-25 15:32:29', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-12-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (169, 'bigdata', 201, '2021-12-10 23:56:11', '2021-12-10 23:56:23', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-12-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (170, 'bigdata', 202, '2021-12-10 23:58:43', '2021-12-10 23:58:55', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-12-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (171, 'bigdata', 203, '2021-12-11 00:16:45', '2022-09-10 00:44:07', '怀信#huaixin', '怀信#huaixin', 'hour', '1970-01-01', '2031-12-11', '', NULL, '', '00:00', '23:59', '4', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (173, 'bigdata', 204, '2021-12-23 15:15:44', '2021-12-30 16:43:00', '葱葱#congcong', '王颖#wangying', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (174, 'bigdata', 205, '2021-12-23 15:16:14', '2021-12-31 11:44:24', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (175, 'bigdata', 209, '2021-12-23 15:52:01', '2021-12-23 15:53:20', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (176, 'bigdata', 206, '2021-12-23 16:54:49', '2021-12-24 15:25:42', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (177, 'bigdata', 207, '2021-12-23 16:54:51', '2021-12-24 16:18:03', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (178, 'bigdata', 208, '2021-12-23 17:06:41', '2021-12-24 16:18:38', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (179, 'bigdata', 210, '2021-12-23 17:30:14', '2022-01-01 17:39:49', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (180, 'bigdata', 211, '2021-12-23 17:48:26', '2022-01-04 10:10:56', '葱葱#congcong', '王颖#wangying', 'hour', '1970-01-01', '2031-12-23', '', NULL, '', '00:00', '23:59', '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (181, 'bigdata', 212, '2021-12-23 17:49:57', '2022-01-04 10:10:29', '葱葱#congcong', '王颖#wangying', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (182, 'bigdata', 213, '2021-12-23 20:34:25', '2021-12-31 21:28:08', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (183, 'bigdata', 214, '2021-12-23 20:34:28', '2022-01-05 15:15:57', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (184, 'bigdata', 216, '2021-12-24 10:18:46', '2022-01-05 14:44:29', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (185, 'bigdata', 217, '2021-12-24 10:23:02', '2022-01-05 14:44:56', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (186, 'bigdata', 218, '2021-12-24 10:27:58', '2021-12-24 16:23:41', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (187, 'bigdata', 219, '2021-12-24 11:41:57', '2021-12-30 18:24:13', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (188, 'bigdata', 220, '2021-12-24 11:48:56', '2021-12-31 21:30:20', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (189, 'bigdata', 221, '2021-12-24 13:46:49', '2022-01-13 10:23:29', '葱葱#congcong', '王颖#wangying', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (190, 'bigdata', 222, '2021-12-24 13:57:06', '2021-12-31 20:40:46', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (191, 'bigdata', 223, '2021-12-24 15:32:10', '2021-12-31 21:03:24', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (192, 'bigdata', 224, '2021-12-27 15:11:26', '2021-12-28 15:59:29', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-09', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (193, 'bigdata', 225, '2021-12-28 10:30:30', '2021-12-28 10:31:04', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (194, 'bigdata', 226, '2021-12-28 10:34:50', '2022-01-12 10:38:30', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (195, 'bigdata', 227, '2021-12-28 10:52:46', '2022-01-13 10:23:55', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (196, 'bigdata', 228, '2021-12-28 10:56:50', '2022-01-12 16:52:44', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (197, 'bigdata', 229, '2021-12-28 13:02:17', '2022-04-17 13:54:44', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-06-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (198, 'bigdata', 230, '2021-12-28 13:55:00', '2022-09-06 16:55:43', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-12-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (199, 'bigdata', 231, '2021-12-28 22:20:58', '2022-01-04 10:50:15', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (200, 'bigdata', 232, '2021-12-29 10:16:18', '2022-10-15 17:14:57', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2031-07-29', '00:00', NULL, '', NULL, NULL, NULL, 25, 2, 1, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (201, 'bigdata', 233, '2021-12-29 14:52:31', '2021-12-29 14:53:23', '齐观#qiguan', '齐观#qiguan', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (202, 'bigdata', 234, '2021-12-29 14:54:35', '2022-02-28 13:03:56', '齐观#qiguan', '齐观#qiguan', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (203, 'bigdata', 236, '2021-12-29 15:06:39', '2022-01-05 15:13:44', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (204, 'bigdata', 237, '2021-12-29 15:36:52', '2022-01-05 15:17:20', '王颖#wangying', '葱葱#congcong', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (205, 'bigdata', 238, '2021-12-29 17:09:15', '2022-01-05 15:10:26', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (206, 'bigdata', 239, '2021-12-29 19:23:06', '2021-12-29 19:26:53', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (207, 'bigdata', 240, '2021-12-29 19:29:44', '2022-01-04 16:00:11', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (208, 'bigdata', 241, '2021-12-29 20:53:37', '2022-01-05 18:05:11', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (209, 'bigdata', 242, '2021-12-29 20:54:00', '2022-01-05 15:28:30', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (210, 'bigdata', 243, '2021-12-30 11:52:07', '2021-12-31 16:18:35', '葱葱#congcong', '齐观#qiguan', 'day', '1970-01-01', '2031-12-30', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (211, 'bigdata', 244, '2021-12-30 21:24:01', '2022-01-05 15:05:45', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-30', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (212, 'bigdata', 245, '2021-12-30 23:14:40', '2021-12-30 23:15:05', '齐观#qiguan', '齐观#qiguan', 'day', '1970-01-01', '2031-12-30', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (213, 'bigdata', 247, '2021-12-31 11:35:08', '2022-01-06 11:02:59', '齐观#qiguan', '齐观#qiguan', 'day', '1970-01-01', '2031-12-31', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (214, 'bigdata', 248, '2021-12-31 16:04:56', '2021-12-31 20:36:36', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-31', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (215, 'bigdata', 249, '2021-12-31 16:07:56', '2021-12-31 19:43:02', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-31', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (216, 'bigdata', 250, '2021-12-31 16:10:22', '2022-01-04 11:51:27', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2031-12-31', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (217, 'bigdata', 251, '2021-12-31 19:00:37', '2022-01-01 11:12:29', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (218, 'bigdata', 252, '2021-12-31 19:01:14', '2022-01-01 11:12:23', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2031-12-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (219, 'bigdata', 253, '2021-12-31 23:32:10', '2022-01-01 18:26:54', '齐观#qiguan', '齐观#qiguan', 'day', '1970-01-01', '2031-12-31', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (220, 'bigdata', 254, '2022-01-04 16:11:15', '2022-09-10 00:52:18', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2032-01-04', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (221, 'bigdata', 255, '2022-01-04 20:36:36', '2022-01-04 21:02:09', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2032-01-04', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (222, 'bigdata', 256, '2022-01-05 14:40:29', '2022-01-05 17:51:25', '王颖#wangying', '王颖#wangying', 'day', '1970-01-01', '2032-01-04', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (223, 'bigdata', 257, '2022-01-07 11:06:22', '2022-01-08 03:43:26', '葱葱#congcong', '葱葱#congcong', 'day', '1970-01-01', '2032-01-07', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (224, 'bigdata', 258, '2022-03-11 22:51:56', '2022-06-09 11:48:16', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '2032-03-11', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (225, 'bigdata', 259, '2022-07-27 09:58:19', '2022-09-22 22:56:19', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-07-27', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (226, 'bigdata', 260, '2022-07-28 23:48:56', '2022-09-06 16:51:56', '不玄#buxuan', '怀信#huaixin', 'day', '1970-01-01', '2032-07-28', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (227, 'bigdata', 262, '2022-08-01 15:54:38', '2022-08-01 15:57:00', '林庆贤#zerolin', '林庆贤#zerolin', 'day', '1970-01-01', '2032-08-01', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (228, 'bigdata', 263, '2022-08-01 17:30:28', '2022-08-02 18:46:14', '林庆贤#zerolin', '林庆贤#zerolin', 'day', '1970-01-01', '2032-08-01', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (229, 'bigdata', 264, '2022-08-01 18:03:09', '2022-08-01 18:03:43', '林庆贤#zerolin', '林庆贤#zerolin', 'day', '1970-01-01', '2032-08-01', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (230, 'bigdata', 265, '2022-08-06 13:29:32', '2022-08-06 13:33:47', '林庆贤#zerolin', '林庆贤#zerolin', 'day', '1970-01-01', '2032-08-06', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (231, 'aoteledemo', 266, '2022-08-06 13:41:43', '2022-08-10 15:21:12', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-06', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (232, 'aoteledemo', 267, '2022-08-06 13:45:21', '2022-08-10 11:26:02', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-06', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (233, 'aoteledemo', 268, '2022-08-09 14:19:41', '2022-09-28 23:06:18', 'demo#demo', '不玄#buxuan', 'day', '1970-01-01', '2032-08-09', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (234, 'aoteledemo', 269, '2022-08-09 17:55:45', '2022-08-10 10:54:48', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-09', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (235, 'aoteledemo', 270, '2022-08-10 11:20:46', '2022-08-11 15:35:16', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (236, 'aoteledemo', 271, '2022-08-10 13:25:39', '2022-08-10 16:35:21', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (237, 'aoteledemo', 272, '2022-08-10 14:06:49', '2022-08-10 14:47:31', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (238, 'aoteledemo', 273, '2022-08-10 14:48:55', '2022-08-10 14:51:34', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (239, 'aoteledemo', 274, '2022-08-10 14:53:16', '2022-08-10 14:55:38', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (240, 'aoteledemo', 275, '2022-08-10 14:57:01', '2022-08-10 15:00:10', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (241, 'aoteledemo', 277, '2022-08-10 15:08:10', '2022-08-10 15:08:23', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (242, 'aoteledemo', 278, '2022-08-10 15:09:52', '2022-08-10 15:09:55', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (243, 'aoteledemo', 279, '2022-08-10 15:11:38', '2022-08-10 15:11:38', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (244, 'aoteledemo', 280, '2022-08-10 15:12:53', '2022-08-10 15:12:53', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (245, 'aoteledemo', 281, '2022-08-10 15:15:03', '2022-08-11 14:58:53', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (246, 'aoteledemo', 282, '2022-08-10 15:21:14', '2022-08-10 15:21:14', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (247, 'aoteledemo', 283, '2022-08-10 15:58:31', '2022-08-10 15:59:26', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (248, 'aoteledemo', 284, '2022-08-10 16:01:10', '2022-08-10 16:04:34', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (249, 'aoteledemo', 285, '2022-08-10 16:03:04', '2022-08-10 16:03:06', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (250, 'aoteledemo', 286, '2022-08-10 16:06:29', '2022-08-10 16:06:50', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (251, 'aoteledemo', 288, '2022-08-10 16:21:10', '2022-08-10 16:25:29', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (252, 'aoteledemo', 289, '2022-08-10 16:31:28', '2022-08-10 16:31:41', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (253, 'aoteledemo', 287, '2022-08-10 16:43:31', '2022-08-11 14:27:33', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (254, 'aoteledemo', 290, '2022-08-11 10:57:41', '2022-08-11 10:57:41', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (255, 'aoteledemo', 291, '2022-08-11 11:03:53', '2022-08-11 11:03:53', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (256, 'aoteledemo', 292, '2022-08-11 11:04:57', '2022-08-11 11:04:57', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (257, 'aoteledemo', 293, '2022-08-11 11:05:56', '2022-08-11 11:05:56', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (258, 'aoteledemo', 294, '2022-08-11 11:07:19', '2022-08-11 11:07:19', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (259, 'aoteledemo', 295, '2022-08-11 11:07:50', '2022-08-11 11:07:50', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (260, 'aoteledemo', 296, '2022-08-11 11:27:31', '2022-08-11 11:27:31', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (261, 'aoteledemo', 297, '2022-08-11 11:46:10', '2022-08-11 11:46:10', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (262, 'aoteledemo', 298, '2022-08-11 11:48:35', '2022-08-11 11:48:35', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (263, 'aoteledemo', 299, '2022-08-11 11:52:26', '2022-08-11 11:52:26', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (264, 'aoteledemo', 300, '2022-08-11 12:40:47', '2022-08-11 15:09:33', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (265, 'aoteledemo', 301, '2022-08-11 12:42:14', '2022-08-11 12:42:14', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (266, 'aoteledemo', 302, '2022-08-11 12:42:37', '2022-08-11 12:42:37', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (267, 'aoteledemo', 303, '2022-08-11 12:47:33', '2022-08-11 12:47:33', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (268, 'aoteledemo', 304, '2022-08-11 12:48:12', '2022-08-11 12:48:12', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (269, 'aoteledemo', 305, '2022-08-11 12:48:35', '2022-08-11 12:48:35', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (270, 'aoteledemo', 306, '2022-08-11 12:48:51', '2022-08-11 12:48:51', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (271, 'aoteledemo', 307, '2022-08-11 12:49:19', '2022-08-11 12:49:19', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-10', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (272, 'aoteledemo', 308, '2022-08-11 14:27:35', '2022-08-11 14:28:53', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-11', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (273, 'aoteledemo', 309, '2022-08-11 15:11:19', '2022-08-11 15:11:39', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-11', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (274, 'aoteledemo', 310, '2022-08-11 15:20:15', '2022-08-11 15:39:37', 'demo#demo', 'demo#demo', 'day', '1970-01-01', '2032-08-11', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (275, '7or9', 311, '2022-08-12 19:32:09', '2022-08-17 09:21:22', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-12', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (276, '7or9', 312, '2022-08-12 19:49:41', '2022-08-16 13:34:12', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-12', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (277, '7or9', 313, '2022-08-12 20:07:20', '2022-08-12 20:35:57', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-12', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (278, '7or9', 314, '2022-08-13 20:38:32', '2022-08-14 23:42:59', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-08-13', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (279, '7or9', 315, '2022-08-14 18:06:15', '2022-08-16 23:19:04', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-12', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (280, '7or9', 316, '2022-08-14 21:16:23', '2022-08-14 23:17:36', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-14', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (281, '7or9', 317, '2022-08-15 09:12:03', '2022-08-17 11:46:44', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (282, '7or9', 318, '2022-08-15 10:25:40', '2022-08-16 21:59:36', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (283, '7or9', 319, '2022-08-15 11:12:46', '2022-08-16 16:15:50', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (284, '7or9', 320, '2022-08-15 13:16:26', '2022-08-16 11:16:24', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (285, '7or9', 321, '2022-08-15 14:49:08', '2022-08-16 13:45:48', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-15', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (286, '7or9', 322, '2022-08-16 11:41:46', '2022-08-17 13:57:09', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-16', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (287, '7or9', 323, '2022-08-16 14:14:26', '2022-08-17 09:14:41', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-16', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (288, '7or9', 324, '2022-08-17 10:11:59', '2022-08-17 14:13:39', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (289, '7or9', 325, '2022-08-17 10:31:42', '2022-08-17 14:35:03', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (290, '7or9', 326, '2022-08-17 10:56:30', '2022-08-17 14:46:10', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (291, '7or9', 327, '2022-08-17 11:13:56', '2022-08-17 15:08:06', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (292, '7or9', 328, '2022-08-17 11:52:43', '2022-08-17 17:21:50', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (293, '7or9', 329, '2022-08-17 14:06:13', '2022-08-17 14:09:47', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (294, '7or9', 330, '2022-08-17 14:23:35', '2022-08-17 14:23:35', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (295, '7or9', 331, '2022-08-17 14:42:00', '2022-08-17 14:42:00', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (296, '7or9', 332, '2022-08-17 14:52:05', '2022-08-17 14:59:22', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (297, '7or9', 333, '2022-08-17 16:33:21', '2022-08-17 17:30:29', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (298, '7or9', 334, '2022-08-17 17:22:29', '2022-08-17 17:22:29', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-17', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (299, '7or9', 335, '2022-08-18 10:02:44', '2022-08-18 13:36:54', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (300, '7or9', 336, '2022-08-18 10:43:15', '2022-08-18 11:43:13', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (301, '7or9', 337, '2022-08-18 11:56:09', '2022-08-18 14:50:30', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (302, '7or9', 338, '2022-08-18 13:47:10', '2022-08-18 15:27:52', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (303, '7or9', 339, '2022-08-18 14:53:37', '2022-08-18 15:07:50', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (304, '7or9', 340, '2022-08-18 15:25:06', '2022-08-18 15:39:05', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (305, '7or9', 341, '2022-08-18 15:51:45', '2022-08-18 16:13:09', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (306, '7or9', 342, '2022-08-18 15:53:00', '2022-08-18 15:55:37', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (307, '7or9', 343, '2022-08-18 16:16:26', '2022-08-18 16:17:37', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-18', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (308, 'bigdata', 344, '2022-08-24 10:15:23', '2022-08-24 10:22:37', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (309, 'bigdata', 345, '2022-08-24 10:25:04', '2022-08-24 10:27:52', '方楚生#fangchusheng', '方楚生#fangchusheng', 'day', '1970-01-01', '2032-08-24', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (310, 'bigdata', 346, '2022-09-06 16:58:02', '2022-10-15 17:13:40', '怀信#huaixin', '怀信#huaixin', 'day', '2022-10-02', '2022-10-13', '00:00', NULL, '', NULL, NULL, NULL, 24, 2, 1, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (311, 'bigdata', 347, '2022-09-12 16:18:36', '2022-09-28 23:31:54', '阿平#xuanwu', '不玄#buxuan', 'day', '1970-01-01', '2032-09-12', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (312, 'offline_sec', 348, '2022-09-13 16:57:16', '2022-09-13 16:57:16', '阿平#xuanwu', '阿平#xuanwu', 'day', '1970-01-01', '2032-09-13', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (313, 'aoteledemo', 349, '2022-09-21 14:54:44', '2022-09-24 09:28:12', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-21', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (314, 'bigdata', 351, '2022-09-23 11:30:42', '2022-09-23 18:30:08', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (315, 'aoteledemo', 353, '2022-09-23 17:08:52', '2022-09-26 09:44:36', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (316, 'aoteledemo', 352, '2022-09-23 17:15:59', '2022-09-26 09:57:20', '不玄#buxuan', '不玄#buxuan', 'day', '2022-09-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (317, 'aoteledemo', 354, '2022-09-23 17:19:24', '2022-09-23 17:30:41', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (318, 'aoteledemo', 356, '2022-09-23 17:26:43', '2022-09-26 13:51:42', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (319, 'aoteledemo', 357, '2022-09-23 17:28:21', '2022-09-23 17:54:26', '不玄#buxuan', '不玄#buxuan', 'day', '2022-09-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (320, 'aoteledemo', 355, '2022-09-23 17:31:18', '2022-09-23 17:36:15', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (321, 'aoteledemo', 358, '2022-09-23 17:38:45', '2022-09-23 17:39:06', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (322, 'aoteledemo', 359, '2022-09-23 17:39:42', '2022-09-23 17:51:04', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-23', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (323, 'bigdata', 361, '2022-09-29 17:04:24', '2022-09-29 17:04:24', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (324, 'test001', 362, '2022-09-29 17:10:10', '2022-09-30 17:03:33', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-29', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (325, 'test001', 363, '2022-09-30 15:46:22', '2022-09-30 15:47:30', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-30', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (326, 'test001', 364, '2022-09-30 15:48:47', '2022-09-30 15:52:51', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-30', '15:56', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (327, 'test001', 365, '2022-09-30 15:55:53', '2022-09-30 16:18:40', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-30', '04:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (328, 'test001', 366, '2022-09-30 16:22:24', '2022-09-30 16:23:19', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-30', '01:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (329, 'test001', 367, '2022-09-30 16:29:30', '2022-09-30 16:29:55', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-30', '00:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (330, 'test001', 368, '2022-09-30 16:33:23', '2022-09-30 16:33:25', '不玄#buxuan', '不玄#buxuan', 'day', '1970-01-01', '2032-09-30', '01:00', NULL, '', NULL, NULL, '1', NULL, NULL, 0, NULL, NULL);
INSERT INTO `meta_job_scheduler` VALUES (331, 'stream_bigdata', 141, '2022-10-05 16:30:58', '2022-10-05 16:39:50', '怀信#huaixin', '怀信#huaixin', NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 0, 2, '2');
INSERT INTO `meta_job_scheduler` VALUES (332, 'bigdata', 369, '2022-10-08 23:37:53', '2022-10-09 22:47:39', '怀信#huaixin', '怀信#huaixin', 'year', '1970-01-14', '9999-01-12', '00:00', '1,4,5', '1,9', NULL, NULL, NULL, 26, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (333, 'bigdata', 370, '2022-10-09 22:49:43', '2022-10-10 00:02:51', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '9999-01-01', '8:8', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (334, 'bigdata', 371, '2022-10-09 23:28:54', '2022-10-09 23:29:04', '怀信#huaixin', '怀信#huaixin', 'week', '1970-01-01', '9999-01-01', '5:5', NULL, '1,4', '', '', '', 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (335, 'bigdata', 372, '2022-10-09 23:36:44', '2022-10-09 23:40:22', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '9999-01-01', '0:35', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (336, 'bigdata', 373, '2022-10-09 23:47:05', '2022-10-09 23:47:09', '怀信#huaixin', '怀信#huaixin', 'week', '1970-01-01', '9999-01-01', '0:35', NULL, '1,4', '', '', '', 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (337, 'bigdata', 374, '2022-10-12 12:45:54', '2022-10-12 12:46:58', '怀信#huaixin', '怀信#huaixin', 'hour', '1970-01-01', '9999-01-01', '', NULL, '0,7,15', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (338, 'bigdata', 375, '2022-10-12 23:33:48', '2022-10-12 23:33:57', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '9999-01-01', '8:8', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (339, 'bigdata', 376, '2022-10-12 23:36:19', '2022-10-12 23:36:22', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '9999-01-01', '8:8', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (340, 'bigdata', 377, '2022-10-12 23:38:10', '2022-10-12 23:38:14', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '9999-01-01', '8:8', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (341, 'bigdata', 378, '2022-10-12 23:51:23', '2022-10-12 23:51:29', '怀信#huaixin', '怀信#huaixin', 'day', '1970-01-01', '9999-01-01', '8:8', NULL, '', NULL, NULL, NULL, 24, 2, 0, 2, '10');
INSERT INTO `meta_job_scheduler` VALUES (342, 'bigdata', 379, '2022-10-16 09:47:57', '2022-10-16 09:48:03', '怀信#huaixin', '怀信#huaixin', 'day', '2022-10-02', '2022-10-21', '00:00', NULL, '', NULL, NULL, NULL, 24, 2, 1, 2, '10');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_server
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_server`;
CREATE TABLE `meta_job_server` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `version` int(11) DEFAULT '0',
  `server_ip` varchar(100) DEFAULT NULL,
  `server_port` int(11) NOT NULL,
  `driver_type` varchar(45) DEFAULT NULL COMMENT 'thriftServer, driverServer',
  `driver_res_type` varchar(45) DEFAULT NULL COMMENT '作业计算类型：yarn_batch、yarn_stream、k8s_batch、k8s_stream',
  `status` varchar(45) NOT NULL COMMENT 'idle: 空闲状态，可以提交任务\nrunning: 运行中\naccept:提交中',
  `app_id` varchar(64) NOT NULL,
  `cluster_code` varchar(45) NOT NULL,
  `instance_code` varchar(64) DEFAULT NULL COMMENT '运行作业实例Code',
  `expired` tinyint(4) NOT NULL DEFAULT '0' COMMENT '是否过期',
  `log_server` varchar(64) DEFAULT NULL COMMENT 'spark 日志拉取server ip',
  `superior_uri` varchar(255) DEFAULT NULL,
  `instance_count` int(11) DEFAULT '0' COMMENT '运行实例数量',
  `server_cores` int(11) NOT NULL COMMENT 'application占用core数',
  `server_memory` int(11) NOT NULL COMMENT 'Application占用内存大小',
  `session_id` varchar(64) DEFAULT NULL,
  `share_driver` tinyint(1) DEFAULT '0',
  `yarn_queue` varchar(255) DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `gmt_created` datetime NOT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_app_id` (`app_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=16797 DEFAULT CHARSET=utf8mb4 COMMENT='Jobserver 服务注册信息';

-- ----------------------------
-- Records of meta_job_server
-- ----------------------------
BEGIN;
INSERT INTO `meta_job_server` VALUES (16789, 1, 0, '10.0.2.112', 45736, 'thriftServer', 'yarn_batch', 'running', 'application_1665585149227_0006', 'hangzhou-spark-3.2', NULL, 0, NULL, NULL, 0, 1, 1024, NULL, 0, 'default', '', NULL, '2022-10-15 16:56:24', NULL);
INSERT INTO `meta_job_server` VALUES (16791, 1, 9, '10.0.2.112', 36358, 'driverServer', 'yarn_batch', 'idle', 'application_1665585149227_0008', 'hangzhou-spark-3.2', NULL, 0, '10.0.2.112', '10.0.2.112:8181', 9, 4, 3072, NULL, 1, 'default', 'admin', NULL, '2022-10-15 20:14:03', '2022-10-17 00:05:28');
COMMIT;

-- ----------------------------
-- Table structure for meta_job_stream_instance
-- ----------------------------
DROP TABLE IF EXISTS `meta_job_stream_instance`;
CREATE TABLE `meta_job_stream_instance` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `workspace_code` varchar(45) DEFAULT NULL COMMENT '项目code',
  `data_center` varchar(64) DEFAULT NULL COMMENT '数据中心',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `code` varchar(45) NOT NULL COMMENT '实例code',
  `name` varchar(512) DEFAULT NULL COMMENT '实例名称',
  `cluster_code` varchar(64) DEFAULT NULL COMMENT '集群code',
  `yarn_queue` varchar(128) DEFAULT NULL COMMENT '作业运行yarn 队列',
  `job_text` longtext COMMENT '作业内容',
  `job_name` varchar(128) DEFAULT NULL COMMENT 'job名称',
  `job_code` varchar(45) DEFAULT NULL COMMENT '作业code',
  `job_id` int(11) DEFAULT NULL COMMENT '作业id',
  `job_type` varchar(45) DEFAULT NULL COMMENT '作业类型',
  `type` varchar(45) NOT NULL DEFAULT 'test, prod' COMMENT '实例类型',
  `version` int(11) NOT NULL DEFAULT '0' COMMENT 'version',
  `status` varchar(32) NOT NULL DEFAULT '0' COMMENT '1：等待运行，3：等待资源，5：运行中，7：运行失败，9: 停止',
  `run_date` varchar(64) DEFAULT NULL COMMENT '运行日期：yyyy-MM-dd',
  `run_start` datetime DEFAULT NULL COMMENT '运行开始时间',
  `run_end` datetime DEFAULT NULL COMMENT '运行结束时间',
  `runtimes` int(11) DEFAULT '0' COMMENT '运行时间，单位秒',
  `owner` varchar(64) NOT NULL COMMENT 'Owner',
  `proxy_user` varchar(64) DEFAULT NULL COMMENT '代理用户',
  `yarn_application_id` varchar(128) DEFAULT 'spark app id' COMMENT 'yarn app id',
  `last_notify_time` datetime DEFAULT NULL COMMENT '最后一次告警时间',
  `retry_time` datetime DEFAULT NULL COMMENT '重试时间',
  `retry_count` int(11) DEFAULT '0' COMMENT '重试次数',
  `alarm_count` int(11) DEFAULT NULL COMMENT '告警次数',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '更新时间',
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '更新人',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `uk_code` (`code`) USING BTREE,
  KEY `idx_project_code` (`workspace_code`) USING BTREE,
  KEY `idx_job_code` (`job_code`) USING BTREE,
  KEY `idx_type` (`type`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='流作业实例表';

-- ----------------------------
-- Records of meta_job_stream_instance
-- ----------------------------
BEGIN;
COMMIT;

-- ----------------------------
-- Table structure for meta_resource
-- ----------------------------
DROP TABLE IF EXISTS `meta_resource`;
CREATE TABLE `meta_resource` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `workspace_code` varchar(45) NOT NULL COMMENT '项目code',
  `folder_id` int(11) NOT NULL,
  `code` varchar(128) DEFAULT NULL COMMENT '全局唯一code，通过code引用资源',
  `name` varchar(128) NOT NULL,
  `file_path` varchar(512) DEFAULT NULL COMMENT 'hdfs存放路径',
  `type` varchar(45) NOT NULL COMMENT '文件类型：jar，file，archive',
  `size` bigint(20) DEFAULT '0' COMMENT '文件大小',
  `version` varchar(45) DEFAULT NULL,
  `current` smallint(6) DEFAULT '0' COMMENT '0：tree查询可见节点，1：tree查询不可见',
  `status` smallint(6) NOT NULL DEFAULT '0' COMMENT '发布状态，0为发布，1发布，3历史版本状态',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `trash` varchar(45) DEFAULT '0' COMMENT '1：数据引入回收站',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE,
  KEY `fk_dc_resource_dc_folder1_idx` (`folder_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=13 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_resource
-- ----------------------------
BEGIN;
INSERT INTO `meta_resource` VALUES (2, 'bigdata', 6, 'res-4aed1e7b-3609-4f71-9304-09ff44483881', 'dataworker-udf-1.0.0-SNAPSHOT.jar', '/user/datawork/resources/bigdata/2/latest/dataworker-udf-1.0.0-SNAPSHOT.jar', 'jar', 2715331, NULL, 0, 0, '2021-07-12 14:13:25', '2021-08-12 16:58:04', '怀信#huaixin', '怀信#huaixin', '0', 1);
INSERT INTO `meta_resource` VALUES (3, 'bigdata', 12, 'res-a3371a1e-ba92-4cc2-9d19-37816ff80ad5', 'hello.zip', '/user/datawork//resources/bigdata/3/latest/hello.zip', 'archive', 423, NULL, 0, 0, '2021-07-13 16:19:50', '2021-08-23 23:08:54', '怀信#huaixin', '怀信#huaixin', '0', 1);
INSERT INTO `meta_resource` VALUES (6, 'bigdata', 12, 'res-a65d10ab-c0bd-44b3-ba6e-bf7f7aacb233', 'graphframes-0.8.1.zip', '/user/datawork//resources/bigdata/6/latest/graphframes-0.8.1.zip', 'archive', 48643, NULL, 0, 0, '2021-08-19 19:01:01', '2021-08-19 19:01:01', '怀信#huaixin', '怀信#huaixin', '0', 1);
INSERT INTO `meta_resource` VALUES (7, 'bigdata', 7, 'res-4d351da2-03aa-4f71-b71b-a7db97a6650b', 'sql-udf-1.4-SNAPSHOT.jar', '/user/dataworks//resources/bigdata/7/latest/sql-udf-1.1-SNAPSHOT.jar', 'jar', 200702943, NULL, 0, 0, '2021-12-29 14:51:07', '2022-01-01 12:29:41', '齐观#qiguan', '齐观#qiguan', '0', 1);
INSERT INTO `meta_resource` VALUES (8, 'bigdata', 7, 'res-64870f64-0b96-48cb-9851-38dabc8b13cc', 'sql-udf-1.5-SNAPSHOT.jar', '/user/dataworks//resources/bigdata/8/latest/sql-udf-1.5-SNAPSHOT.jar', 'jar', 21953681, NULL, 0, 0, '2022-01-14 14:13:32', '2022-01-14 14:13:32', '齐观#qiguan', '齐观#qiguan', '0', 1);
INSERT INTO `meta_resource` VALUES (12, 'bigdata', 7, 'res-61231b3f-4df5-494f-b8f8-a6eb1c66b10f', 'spark-jobserver-examples-3.2.0-SNAPSHOT.jar', '/user/dataworks//resources/bigdata/12/latest/spark-jobserver-examples-3.2.0-SNAPSHOT.jar', 'jar', 3526, NULL, 0, 0, '2022-05-10 17:58:13', '2022-05-10 17:58:13', '怀信#huaixin', '怀信#huaixin', '0', 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_statistics
-- ----------------------------
DROP TABLE IF EXISTS `meta_statistics`;
CREATE TABLE `meta_statistics` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `catalog` varchar(64) DEFAULT NULL,
  `name` varchar(64) DEFAULT NULL,
  `value` varchar(45) DEFAULT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `data_center` varchar(128) DEFAULT NULL COMMENT '数据中心：hangzhou, Shanghai',
  `data_center_cn` varchar(128) DEFAULT NULL,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE,
  KEY `catalog_UNIQUE` (`catalog`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=285 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_statistics
-- ----------------------------
BEGIN;
INSERT INTO `meta_statistics` VALUES (272, 'tableTotalSize', '2022-09-26', '5663043748', '2022-09-27 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (273, 'tableTotalSize', '2022-09-27', '5663043748', '2022-09-28 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (274, 'tableTotalSize', '2022-09-28', '5663043748', '2022-09-29 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (275, 'tableTotalSize', '2022-09-29', '5663043748', '2022-09-30 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (276, 'tableTotalSize', '2022-09-30', '5663043748', '2022-10-01 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (277, 'tableTotalSize', '2022-10-01', '556726', '2022-10-02 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (278, 'tableTotalSize', '2022-10-02', '556726', '2022-10-03 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (279, 'tableTotalSize', '2022-10-03', '556726', '2022-10-04 07:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (280, 'tableTotalSize', '2022-10-09', '556726', '2022-10-09 23:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (281, 'tableTotalSize', '2022-10-12', '556726', '2022-10-12 23:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (282, 'tableTotalSize', '2022-10-15', '556726', '2022-10-15 23:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (283, 'tableTotalSize', '2022-10-16', '558955', '2022-10-16 23:40:00', NULL, NULL, 1);
INSERT INTO `meta_statistics` VALUES (284, 'tableTotalSize', '2022-10-17', '560441', '2022-10-17 23:40:00', NULL, NULL, 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_table
-- ----------------------------
DROP TABLE IF EXISTS `meta_table`;
CREATE TABLE `meta_table` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `catalog_name` varchar(128) NOT NULL,
  `database_name` varchar(128) NOT NULL COMMENT '数据库名',
  `origin_database_name` varchar(128) DEFAULT NULL,
  `table_name` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `origin_table_name` varchar(128) DEFAULT NULL,
  `lifecycle` int(11) DEFAULT NULL COMMENT '生命周期',
  `data_level` varchar(4) DEFAULT 'P2' COMMENT '数据等级',
  `sec_level` tinyint(4) NOT NULL COMMENT '安全级别:  0级 (不保密, Unclassified), 1级 (保密, Confidential), 2级 (机密, Sensitive), 3级 (高度机密, Highly Sensitive)',
  `is_part_table` tinyint(4) DEFAULT '1' COMMENT '是否分区表：1 是，0 不是',
  `ds_type` varchar(45) DEFAULT 'Hive' COMMENT '数据源类型：hive, MySQL等',
  `type` varchar(45) DEFAULT NULL COMMENT '表类型：table,view',
  `subject1` varchar(45) DEFAULT NULL COMMENT '一级主题',
  `subject2` varchar(45) DEFAULT NULL COMMENT '二级主题',
  `detail` varchar(4096) DEFAULT '',
  `owner` varchar(45) NOT NULL COMMENT '负责人',
  `biz_owner` varchar(45) DEFAULT NULL COMMENT '业务负责人',
  `remove_data_version` varchar(45) DEFAULT '0' COMMENT '乐观锁',
  `sync_status_version` varchar(45) DEFAULT '0' COMMENT '乐观锁',
  `location` varchar(1024) DEFAULT NULL,
  `last_ddl_time` datetime DEFAULT NULL COMMENT 'DDL 修改时间',
  `last_access_time` datetime DEFAULT NULL COMMENT '数据修改时间',
  `last_update_time` datetime DEFAULT NULL COMMENT '数据修改时间',
  `total_number_files` bigint(20) DEFAULT NULL,
  `total_file_size` bigint(20) DEFAULT NULL,
  `num_rows` bigint(20) DEFAULT '-1' COMMENT '记录行数',
  `file_format` varchar(45) DEFAULT 'PARQUET' COMMENT 'Hive 数据文件格式：ORC、PARQUET、delta、iceberg',
  `dw_classification` varchar(64) DEFAULT NULL COMMENT '数仓分类(ADS,DWS,DWM,DIM,ODS,TMP)',
  `version_lock` varchar(45) DEFAULT NULL COMMENT 'lock',
  `view_ddl` longtext COMMENT '视图脚本',
  `last_change_owner` datetime DEFAULT NULL COMMENT '上次修改owner的时间，限制owner一个月只能修改一次。',
  `score` int(11) DEFAULT '0' COMMENT '表质量分数',
  `hudi_type` varchar(45) DEFAULT NULL COMMENT 'hudi 表类型',
  `compression` varchar(45) DEFAULT NULL,
  `access_count` int(11) DEFAULT NULL COMMENT '最近一个月访问次数',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `table_name_UNIQUE` (`table_name`,`database_name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=514 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_table
-- ----------------------------
BEGIN;
INSERT INTO `meta_table` VALUES (392, 1, 'spark_catalog', 'bigdata', NULL, 'test_huid_stream_csv_dt', NULL, 300, 'P2', 1, 1, 'Hive', 'Table', NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '0', '0', 'hdfs://newns:8020/user/hive/warehouse/bigdata.db/test_huid_stream_csv_dt', '2022-07-08 11:07:23', '2022-07-08 11:07:23', '2022-07-08 11:07:23', 0, 0, 0, 'hudi', 'ODS', '20221018', NULL, NULL, NULL, 'mor', 'zstd', NULL, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (448, 1, 'spark_catalog', '7or9', NULL, 'dwd_inventory_details', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '库存明细表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/dwd_inventory_details', '2022-08-15 10:57:19', '2022-08-16 21:31:17', '2022-08-16 21:31:21', 1, 4200, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 42, '2022-08-15 10:57:19', '2022-08-15 10:57:19', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (455, 1, 'spark_catalog', '7or9', NULL, 'ods_inventory_receipt_delivery', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '存货收发汇总表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_inventory_receipt_delivery', '2022-08-16 21:18:43', '2022-08-16 23:19:10', '2022-08-16 21:25:18', 1, 23850, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 75, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (456, 1, 'spark_catalog', '7or9', NULL, 'ads_inventory_df', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '库存表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ads_inventory_df', '2022-08-16 21:32:22', '2022-08-18 11:43:41', '2022-08-16 21:32:49', 1, 4076, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 19, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (458, 1, 'spark_catalog', '7or9', NULL, 'ods_lrb_freight', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '小红书运费表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_lrb_freight', '2022-08-17 10:21:08', '2022-08-17 14:09:46', '2022-08-17 14:09:48', 1, 20346, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 3, '2022-08-17 10:21:08', '2022-08-17 10:21:08', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (459, 1, 'spark_catalog', '7or9', NULL, 'ods_lrb_return_goods', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '小红书退货表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_lrb_return_goods', '2022-08-17 10:51:29', '2022-08-17 14:34:24', '2022-08-17 14:34:26', 1, 12285, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 6, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (460, 1, 'spark_catalog', '7or9', NULL, 'ods_lrb_manual_refund', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '小红书人工退款表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_lrb_manual_refund', '2022-08-17 11:08:10', '2022-08-17 14:45:07', '2022-08-17 14:45:08', 1, 2245, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 1, '2022-08-17 11:08:10', '2022-08-17 11:08:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (462, 1, 'spark_catalog', '7or9', NULL, 'ods_lrb_commodity_sales', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '小红书商品销售表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_lrb_commodity_sales', '2022-08-17 13:29:51', '2022-08-17 13:54:27', '2022-08-17 13:54:30', 1, 31376, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 10, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (463, 1, 'spark_catalog', '7or9', NULL, 'ods_lrb_gps_distribution', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '小红书CPS分销表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_lrb_gps_distribution', '2022-08-17 15:01:24', '2022-08-17 15:06:51', '2022-08-17 15:06:53', 1, 30161, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 5, '2022-08-17 15:01:24', '2022-08-17 15:01:24', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (465, 1, 'spark_catalog', '7or9', NULL, 'ods_gross_profit', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '毛利表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/ods_gross_profit', '2022-08-17 17:12:46', '2022-08-18 11:22:51', '2022-08-17 17:23:32', 1, 374380, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 8, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (467, 1, 'spark_catalog', '7or9', NULL, 'dim_platform_gross_profit', NULL, 300, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, '平台毛利维度表', '方楚生#fangchusheng', '方楚生#fangchusheng', '0', '20220913', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/7or9.db/dim_platform_gross_profit', '2022-08-18 11:20:14', '2022-08-18 13:35:18', '2022-08-18 11:42:32', 1, 53807, 0, 'orc', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', 5, '2022-08-18 11:20:14', '2022-08-18 11:20:14', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table` VALUES (470, 1, 'spark_catalog', 'bigdata', NULL, 'test_hudi_demo', NULL, 300, 'P2', 1, 1, 'Hive', 'Table', NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '0', '0', 'hdfs://cneutascrdvm01.internal.chinacloudapp.cn:8020/user/hive/warehouse/bigdata.db/test_hudi_demo', '2022-09-09 14:55:30', '2022-09-09 14:55:30', '2022-09-09 14:55:30', 0, 0, 0, 'hudi', 'ODS', '20221018', NULL, NULL, NULL, 'cow', 'zstd', NULL, '2022-09-09 14:55:30', '2022-09-09 14:55:30', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (480, 1, 'superior', 'superior_test', 'superior_test', 'meta_cluster_compute', 'meta_cluster_compute', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '计算集群管理', '怀信#huaixin', '怀信#huaixin', '0', '0', NULL, '2022-09-13 21:24:37', '2022-09-13 21:24:37', '2022-09-13 21:24:37', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', 5, '2022-09-13 21:24:37', '2022-09-13 21:24:37', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (482, 1, 'postgres_demo', 'public', 'public', 'accounts', 'accounts', -1, 'P2', 1, 0, 'PostgreSQL', 'Table', NULL, NULL, '测试表', '怀信#huaixin', '怀信#huaixin', '0', '0', NULL, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '2022-09-13 22:16:25', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', 1, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (484, 1, 'superior', 'demo', 'Demo', 'st_user', 'St_User', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '测试', '怀信#huaixin', '怀信#huaixin', '0', '0', NULL, '2022-09-15 21:37:28', '2022-09-15 21:37:28', '2022-09-15 21:37:28', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', NULL, '2022-09-15 21:37:28', '2022-09-15 21:37:28', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (486, 1, 'aotele', 'pevc_reviw', 'pevc_reviw', 'tmp_3', 'tmp_3', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '', '不玄#buxuan', '怀信#huaixin', '0', '0', NULL, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '2022-09-21 14:58:59', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', 11, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (489, 1, 'superior', 'superior_test', 'superior_test', 'meta_job', 'meta_job', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '作业', '怀信#huaixin', '怀信#huaixin', '0', '0', NULL, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '2022-09-21 23:14:48', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', NULL, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (494, 1, 'aotele', 'pevc_reviw', 'pevc_reviw', 'test_table_1', 'test_table_1', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '', '不玄#buxuan', '不玄#buxuan', '0', '0', NULL, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '2022-09-22 13:53:35', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', 3, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (496, 1, 'aotele', 'pevc_reviw', 'pevc_reviw', 'a1', 'a1', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '', '不玄#buxuan', '不玄#buxuan', '0', '0', NULL, '2022-09-22 14:19:05', '2022-09-22 14:19:05', '2022-09-22 14:19:05', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', 1, '2022-09-22 14:19:05', '2022-09-22 14:19:05', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (498, 1, 'aotele', 'pevc_reviw', 'pevc_reviw', 'test_table', 'test_table', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '', '不玄#buxuan', '不玄#buxuan', '0', '0', NULL, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '2022-09-22 14:24:59', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', NULL, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (507, 1, 'new_server', 'ydec', 'ydec', 'test_table', 'test_table', -1, 'P2', 1, 0, 'MySQL', 'Table', NULL, NULL, '', '不玄#buxuan', '不玄#buxuan', '0', '0', NULL, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '2022-09-28 23:25:36', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, '', 2, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (508, 1, 'spark_catalog', 'test001', NULL, 'test_table_dt', NULL, 20, 'P2', 1, 1, 'Hive', 'Table', NULL, NULL, NULL, '不玄#buxuan', '不玄#buxuan', '0', '20221001', 'file:/opt/hadoopHA/tmp/nm-local-dir/usercache/hdfs/appcache/application_1664420582460_0052/container_e05_1664420582460_0052_01_000001/spark-warehouse/test001.db/test_table_dt', '2022-09-29 17:09:57', '2022-09-29 17:09:57', '2022-09-29 17:09:57', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'snappy', 5, '2022-09-29 17:09:57', '2022-09-29 17:09:57', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (509, 1, 'spark_catalog', 'test001', NULL, 'dws_purchase_category1_di', NULL, 20, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, NULL, '不玄#buxuan', '不玄#buxuan', '0', '0', 'file:/opt/hadoopHA/tmp/nm-local-dir/usercache/hdfs/appcache/application_1664420582460_0052/container_e05_1664420582460_0052_01_000001/spark-warehouse/test001.db/dws_purchase_category1_di', '2022-09-30 15:48:19', '2022-09-30 15:48:19', '2022-09-30 15:48:19', 0, 0, 0, 'parquet', 'ODS', '20221018', NULL, NULL, NULL, NULL, 'zstd', NULL, '2022-09-30 15:48:19', '2022-09-30 15:48:19', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table` VALUES (511, 1, 'spark_catalog', 'bigdata', NULL, 'test_demo_dt1', NULL, 10, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '0', '20221018', 'hdfs://cneutascrdvm10:8020/user/hive/warehouse/bigdata.db/test_demo_dt1', '2022-10-15 17:33:49', '2022-10-15 17:33:49', '2022-10-15 17:33:49', 0, 0, 0, 'parquet', NULL, '20221018', NULL, NULL, NULL, NULL, 'snappy', NULL, '2022-10-15 17:33:49', '2022-10-15 17:33:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (512, 1, 'spark_catalog', 'bigdata', NULL, 'test_demo_test1', NULL, 10, 'P2', 1, 0, 'Hive', 'Table', NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '0', '20221018', 'hdfs://cneutascrdvm10:8020/user/hive/warehouse/bigdata.db/test_demo_test1', '2022-10-15 19:12:00', '2022-10-17 05:00:05', '2022-10-15 20:18:47', 2, 1486, 2, 'parquet', NULL, '20221018', NULL, NULL, NULL, NULL, 'zstd', 1, '2022-10-15 19:12:00', '2022-10-15 19:12:00', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table` VALUES (513, 1, 'spark_catalog', 'bigdata', NULL, 'test_demo_dt', NULL, 10, 'P2', 1, 1, 'Hive', 'Table', NULL, NULL, NULL, '怀信#huaixin', '怀信#huaixin', '0', '20221018', 'hdfs://cneutascrdvm10:8020/user/hive/warehouse/bigdata.db/test_demo_dt', '2022-10-15 22:13:41', '2022-10-15 22:13:41', '2022-10-15 22:13:41', 0, 2229, 0, 'parquet', NULL, '20221018', NULL, NULL, NULL, NULL, 'snappy', NULL, '2022-10-15 22:13:41', '2022-10-15 22:13:41', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_table_access_log
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_access_log`;
CREATE TABLE `meta_table_access_log` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) NOT NULL COMMENT '租户ID',
  `user_id` varchar(45) DEFAULT NULL COMMENT '用户id',
  `user_name` varchar(45) DEFAULT NULL COMMENT '用户名',
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) DEFAULT NULL COMMENT '项目code',
  `table_name` varchar(128) DEFAULT NULL COMMENT '表名',
  `visit_date` varchar(32) DEFAULT NULL COMMENT '访问日期',
  `count` int(11) DEFAULT '0' COMMENT '访问数量',
  `gmt_created` datetime DEFAULT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `name_index` (`database_name`,`table_name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=382 DEFAULT CHARSET=utf8mb4 COMMENT='表访问记录';

-- ----------------------------
-- Records of meta_table_access_log
-- ----------------------------
BEGIN;
INSERT INTO `meta_table_access_log` VALUES (377, 1, 'buxuan', '不玄', 'aotele', 'pevc_reviw', 'a1', '2022-09-28', 1, '2022-09-28 23:31:09', '2022-09-28 23:31:09', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_access_log` VALUES (378, 1, 'buxuan', '不玄', 'new_server', 'ydec', 'test_table', '2022-09-28', 1, '2022-09-28 23:31:55', '2022-09-28 23:31:55', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_access_log` VALUES (379, 1, 'buxuan', '不玄', 'new_server', 'ydec', 'test_table', '2022-09-29', 1, '2022-09-29 15:30:22', '2022-09-29 15:30:22', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_access_log` VALUES (380, 1, 'buxuan', '不玄', 'spark_catalog', 'test001', 'test_table_dt', '2022-09-30', 5, '2022-09-30 15:29:04', '2022-09-30 17:04:55', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_access_log` VALUES (381, 1, 'huaixin', '怀信', 'spark_catalog', 'bigdata', 'test_demo_test1', '2022-10-15', 1, '2022-10-15 19:12:50', '2022-10-15 19:12:50', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_table_apply_flow
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_apply_flow`;
CREATE TABLE `meta_table_apply_flow` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `sec_table_id` varchar(45) NOT NULL COMMENT 'dc_table_privs 表主键',
  `obj_id` varchar(45) NOT NULL COMMENT '用户/角色 的id或者code',
  `flow_no` varchar(45) DEFAULT NULL COMMENT '审批流程编号',
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) NOT NULL COMMENT '数据库名(projectCode)',
  `table_name` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `read_priv` tinyint(4) DEFAULT '0',
  `write_priv` tinyint(4) DEFAULT '0',
  `alter_priv` tinyint(4) DEFAULT '0',
  `drop_priv` tinyint(4) DEFAULT '0',
  `lifecycle` int(11) DEFAULT '0',
  `status` tinyint(4) DEFAULT '0' COMMENT '0: 新创建，1：审批中，2：被终止,  3：完成，4：取消',
  `owner` varchar(45) NOT NULL,
  `detail` varchar(1024) DEFAULT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_table_id` (`sec_table_id`) USING BTREE,
  KEY `idx_status` (`status`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='审批流程表';

-- ----------------------------
-- Records of meta_table_apply_flow
-- ----------------------------
BEGIN;
COMMIT;

-- ----------------------------
-- Table structure for meta_table_column
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_column`;
CREATE TABLE `meta_table_column` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `catalog_name` varchar(128) NOT NULL,
  `database_name` varchar(128) NOT NULL COMMENT '数据库名',
  `table_name` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `name` varchar(128) NOT NULL COMMENT '数据库名',
  `origin_name` varchar(128) DEFAULT NULL COMMENT '关系数据库原始字段名称，区分大小写',
  `data_type` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `data_kind` varchar(128) DEFAULT NULL COMMENT '数据类型分类',
  `detail` varchar(4096) DEFAULT NULL COMMENT '备注',
  `sec_level` tinyint(4) NOT NULL DEFAULT '1' COMMENT '安全级别:  0级 (不保密, Unclassified), 1级 (保密, Confidential), 2级 (机密, Sensitive), 3级 (高度机密, Highly Sensitive)',
  `mask` tinyint(4) DEFAULT '0' COMMENT '1：脱敏',
  `is_partition` tinyint(4) DEFAULT '0' COMMENT '0：columun 1: partition column',
  `first_category` varchar(128) DEFAULT NULL,
  `second_category` varchar(128) DEFAULT NULL,
  `third_category` varchar(256) DEFAULT NULL,
  `index_field` tinyint(4) DEFAULT '0' COMMENT '是否索引:0否，1是',
  `pk_field` tinyint(4) DEFAULT '0' COMMENT '是否主键:0否，1是',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `column_name_UNIQUE` (`table_name`,`database_name`,`name`) USING BTREE,
  KEY `tabale_name_unqiue` (`database_name`,`table_name`) USING BTREE,
  KEY `idx_database_name` (`database_name`) USING BTREE,
  KEY `idx_table_name` (`table_name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=4613 DEFAULT CHARSET=utf8mb4 COMMENT='表字段信息';

-- ----------------------------
-- Records of meta_table_column
-- ----------------------------
BEGIN;
INSERT INTO `meta_table_column` VALUES (2507, 1, 'spark_catalog', 'bigdata', 'test_huid_stream_csv_dt', 'id', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (2508, 1, 'spark_catalog', 'bigdata', 'test_huid_stream_csv_dt', 'userid', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (2509, 1, 'spark_catalog', 'bigdata', 'test_huid_stream_csv_dt', 'city', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (2510, 1, 'spark_catalog', 'bigdata', 'test_huid_stream_csv_dt', 'kafka_topic', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (2511, 1, 'spark_catalog', 'bigdata', 'test_huid_stream_csv_dt', 'kafka_timestamp', NULL, 'timestamp', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (2512, 1, 'spark_catalog', 'bigdata', 'test_huid_stream_csv_dt', 'ds', NULL, 'string', NULL, NULL, 1, 0, 1, '', '', '', 0, 0, '2022-07-08 11:07:23', '2022-07-08 11:07:23', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (3822, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'shoe_type', NULL, 'string', NULL, '鞋子类型', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3823, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'shoe_name', NULL, 'string', NULL, '鞋子名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3824, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'year', NULL, 'string', NULL, '年', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3825, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'month', NULL, 'string', NULL, '月', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3826, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'inventory_quantity', NULL, 'string', NULL, '期末结存的数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3827, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'amount_of_money', NULL, 'string', NULL, '期末结存的金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3828, 1, 'spark_catalog', '7or9', 'dwd_inventory_details', 'delivery_quantity', NULL, 'string', NULL, '本期发出的数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-15 10:57:22', '2022-08-15 10:57:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3929, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'material_code', NULL, 'string', NULL, '物料编码', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3930, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'material_name', NULL, 'string', NULL, '物料名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3931, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'material_properties', NULL, 'string', NULL, '物料属性', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3932, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'inventory_category', NULL, 'string', NULL, '存货类别', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3933, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'material_grouping', NULL, 'string', NULL, '物料分组', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3934, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'specification_model', NULL, 'string', NULL, '规格型号', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3935, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'inventory_status', NULL, 'string', NULL, '库存状态', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3936, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'warehouse', NULL, 'string', NULL, '仓库', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3937, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'accounting_range_code', NULL, 'string', NULL, '核算范围编码', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3938, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'accounting_range_name', NULL, 'string', NULL, '核算范围名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3939, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'opening_balance_quantity', NULL, 'string', NULL, '期初结存数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3940, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'opening_balance_unit_price', NULL, 'string', NULL, '期初结存单价', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3941, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'opening_balance_amount', NULL, 'string', NULL, '期初结存金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3942, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'revenue_quantity', NULL, 'string', NULL, '本期收入数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3943, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'revenue_unit_price', NULL, 'string', NULL, '本期收入单价', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3944, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'revenue_amount', NULL, 'string', NULL, '本期收入金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3945, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'issued_quantity', NULL, 'string', NULL, '本期发出数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3946, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'issued_unit_price', NULL, 'string', NULL, '本期发出单价 ', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3947, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'issued_amount', NULL, 'string', NULL, '本期发出金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3948, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'balance_quantity', NULL, 'string', NULL, '期末结存数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3949, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'balance_unit_price', NULL, 'string', NULL, '期末结存单价', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3950, 1, 'spark_catalog', '7or9', 'ods_inventory_receipt_delivery', 'balance_amount', NULL, 'string', NULL, '期末结存金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:18:43', '2022-08-16 21:18:43', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3951, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'shoe_type', NULL, 'string', NULL, '鞋子类型', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3952, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'shoe_name', NULL, 'string', NULL, '鞋子名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3953, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'year_last_one_month', NULL, 'string', NULL, '时间_每年最近的第一个月', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3954, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'year_last_two_month', NULL, 'string', NULL, '时间_每年最近的第二个月', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3955, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'year_last_three_month', NULL, 'string', NULL, '时间_每年最近的第三个月', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3956, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'delivery_quantity', NULL, 'string', NULL, '本期发出数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3957, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'year_last_month', NULL, 'string', NULL, '时间_每年的最后一个月份', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3958, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'inventory_quantity', NULL, 'string', NULL, '期末结存的数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3959, 1, 'spark_catalog', '7or9', 'ads_inventory_df', 'amount_of_money', NULL, 'string', NULL, '期末结存的金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-16 21:32:22', '2022-08-16 21:32:22', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3989, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'entry_force_time', NULL, 'string', NULL, '生效时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3990, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'user_order_time', NULL, 'string', NULL, '用户下单时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3991, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'delivery_time', NULL, 'string', NULL, '发货时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3992, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'order_number', NULL, 'string', NULL, '订单号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3993, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'package_number', NULL, 'string', NULL, '包裹号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3994, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'freight_po', NULL, 'string', NULL, '运费宝单号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3995, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'policy_amount', NULL, 'string', NULL, '保单金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3996, 1, 'spark_catalog', '7or9', 'ods_lrb_freight', 'settlement_account', NULL, 'string', NULL, '结算账户', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:21:09', '2022-08-17 10:21:09', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3997, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'refund_time', NULL, 'string', NULL, '退款时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3998, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'product_name', NULL, 'string', NULL, '商品名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (3999, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'commodity_type', NULL, 'string', NULL, '商品类型', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4000, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'total_expenditure', NULL, 'string', NULL, '支出总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4001, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'settlement_account', NULL, 'string', NULL, '结算账户', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4002, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'quantity_returned_goods', NULL, 'string', NULL, '退货商品数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4003, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'total_paid_sales', NULL, 'string', NULL, '销售实付总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4004, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'total_sales_settlement', NULL, 'string', NULL, '销售结算总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:29', '2022-08-17 10:51:29', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4005, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'total_sales_commission', NULL, 'string', NULL, '销售佣金总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4006, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'total_amount_actually_returned', NULL, 'string', NULL, '实退总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4007, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'total_return_commission', NULL, 'string', NULL, '退货佣金总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4008, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'payment_channel_fee_return', NULL, 'string', NULL, '支付渠道费退货', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4009, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'item_id', NULL, 'string', NULL, '商品id', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4010, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'lrb_code', NULL, 'string', NULL, '小红书编码', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4011, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'package_number', NULL, 'string', NULL, '包裹号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4012, 1, 'spark_catalog', '7or9', 'ods_lrb_return_goods', 'return_no', NULL, 'string', NULL, '退货单号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 10:51:30', '2022-08-17 10:51:30', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4013, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'refund_time', NULL, 'string', NULL, '退款时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:10', '2022-08-17 11:08:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4014, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'expenditure_amount', NULL, 'string', NULL, '支出金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:10', '2022-08-17 11:08:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4015, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'settlement_account', NULL, 'string', NULL, '结算账户', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:10', '2022-08-17 11:08:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4016, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'refund_settlement_amount', NULL, 'string', NULL, '退款结算金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:10', '2022-08-17 11:08:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4017, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'commission_amount', NULL, 'string', NULL, '佣金金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:10', '2022-08-17 11:08:10', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4018, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'actual_refund_amount', NULL, 'string', NULL, '实退金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:11', '2022-08-17 11:08:11', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4019, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'paid_amount', NULL, 'string', NULL, '实付金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:11', '2022-08-17 11:08:11', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4020, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'settlement_amount', NULL, 'string', NULL, '结算金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:11', '2022-08-17 11:08:11', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4021, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'package_number', NULL, 'string', NULL, '包裹号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:11', '2022-08-17 11:08:11', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4022, 1, 'spark_catalog', '7or9', 'ods_lrb_manual_refund', 'refund_reason', NULL, 'string', NULL, '退款原因', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 11:08:11', '2022-08-17 11:08:11', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4042, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'order_completion_time', NULL, 'string', NULL, '订单完成时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4043, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'user_order_time', NULL, 'string', NULL, '用户下单时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4044, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'order_number', NULL, 'string', NULL, '订单号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4045, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'package_number', NULL, 'string', NULL, '包裹号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4046, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'order_type', NULL, 'string', NULL, '订单类型', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4047, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'item_name', NULL, 'string', NULL, '商品名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4048, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'item_id', NULL, 'string', NULL, '商品id', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4049, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'lrb_code', NULL, 'string', NULL, '小红书编码', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4050, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'commodity_type', NULL, 'string', NULL, '商品类型', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4051, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'member_product_name', NULL, 'string', NULL, '成员商品名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4052, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'member_commodity_lrb_code', NULL, 'string', NULL, '成员商品小红书编码', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4053, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_revenue', NULL, 'string', NULL, '收入总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4054, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'settlement_account', NULL, 'string', NULL, '结算账户', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4055, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'commodity_quantity', NULL, 'string', NULL, '商品数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4056, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_settlement', NULL, 'string', NULL, '结算总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4057, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_paid', NULL, 'string', NULL, '实付总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4058, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'payment_channel_fee_commodity', NULL, 'string', NULL, '支付渠道费(商品)', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4059, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_deposit', NULL, 'string', NULL, '定金总额 ', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4060, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_discount_merchants', NULL, 'string', NULL, '商家优惠总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4061, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'lrb_discount_total', NULL, 'string', NULL, '小红书优惠总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4062, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'commission_rate', NULL, 'string', NULL, '佣金率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4063, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_commission', NULL, 'string', NULL, '佣金总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4064, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'taxable_price_including_tax', NULL, 'string', NULL, '计税价格(含税)', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4065, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'taxable_price_before_tax', NULL, 'string', NULL, '计税价格(未税)', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4066, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'tax_category', NULL, 'string', NULL, '税种', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4067, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'tax_rate', NULL, 'string', NULL, '税率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4068, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'tax_rate_cross_border_tax_payment', NULL, 'string', NULL, '跨境税代缴', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4069, 1, 'spark_catalog', '7or9', 'ods_lrb_commodity_sales', 'total_tax_commodity', NULL, 'string', NULL, '税金总额(商品)', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 13:29:51', '2022-08-17 13:29:51', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4070, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'settlement_time', NULL, 'string', NULL, '结算时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4071, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'business_type', NULL, 'string', NULL, '业务类型', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4072, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'order_completion_refund_time', NULL, 'string', NULL, '订单完成时间/退款时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4073, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'user_order_time', NULL, 'string', NULL, '用户下单时间', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4074, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'order_number', NULL, 'string', NULL, '订单号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4075, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'package_number', NULL, 'string', NULL, '包裹号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4076, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'item_name', NULL, 'string', NULL, '商品名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4077, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'item_id', NULL, 'string', NULL, '商品id', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4078, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'commodity_quantity', NULL, 'string', NULL, '商品数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4079, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'total_paid_refunded', NULL, 'string', NULL, '实付总额/退款总额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4080, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'taxation', NULL, 'string', NULL, '税费', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4081, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'carrying_amount', NULL, 'string', NULL, '带货金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4082, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'commodity_cps_commission_rate', NULL, 'string', NULL, '商品CPS佣金率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4083, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'platform_subsidy_commission_rate', NULL, 'string', NULL, '平台补贴佣金率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4084, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'cps_commission_rate_seller', NULL, 'string', NULL, '卖家CPS佣金率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4085, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'distribution_commission_expense', NULL, 'string', NULL, '分销佣金支出', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4086, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'settlement_account', NULL, 'string', NULL, '结算账户', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4087, 1, 'spark_catalog', '7or9', 'ods_lrb_gps_distribution', 'talent_id', NULL, 'string', NULL, '达人id', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 15:01:25', '2022-08-17 15:01:25', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4096, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'business_date', NULL, 'string', NULL, '业务日期', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4097, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'document_no', NULL, 'string', NULL, '单据编号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4098, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'document_status', NULL, 'string', NULL, '单据状态', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4099, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'sales_order_no', NULL, 'string', NULL, '销售订单号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4100, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'customer', NULL, 'string', NULL, '客户', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4101, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'currency', NULL, 'string', NULL, '币别', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4102, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'due_date', NULL, 'string', NULL, '到期日', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4103, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'material_code', NULL, 'string', NULL, '物料编码', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4104, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'material_name', NULL, 'string', NULL, '物料名称', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4105, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'specification_model', NULL, 'string', NULL, '规格型号', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4106, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'pricing_unit', NULL, 'string', NULL, '计价单位', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4107, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'pricing_quantity', NULL, 'string', NULL, '计价数量', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4108, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'unit_price_including_tax', NULL, 'string', NULL, '含税单价', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4109, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'tax_rate', NULL, 'string', NULL, '税率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4110, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'amount_excluding_tax', NULL, 'string', NULL, '不含税金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4111, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'tax_amount', NULL, 'string', NULL, '税额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4112, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'gift', NULL, 'string', NULL, '赠品', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4113, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'cost_amount', NULL, 'string', NULL, '成本金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4114, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'gross_profit', NULL, 'string', NULL, '毛利', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4115, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'gross_profit_margin', NULL, 'string', NULL, '毛利率', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4116, 1, 'spark_catalog', '7or9', 'ods_gross_profit', 'category', NULL, 'string', NULL, '类别', 1, 0, 0, '', '', '', 0, 0, '2022-08-17 17:12:46', '2022-08-17 17:12:46', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4123, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'year', NULL, 'string', NULL, '年', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4124, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'month', NULL, 'string', NULL, '月', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4125, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'customer', NULL, 'string', NULL, '平台', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4126, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'amount_excluding_tax', NULL, 'string', NULL, '不含税金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4127, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'cost_amount', NULL, 'string', NULL, '成本金额', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4128, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'gross_profit', NULL, 'string', NULL, '毛利', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4129, 1, 'spark_catalog', '7or9', 'dim_platform_gross_profit', 'category', NULL, 'string', NULL, '类别', 1, 0, 0, '', '', '', 0, 0, '2022-08-18 11:20:15', '2022-08-18 11:20:15', '方楚生#fangchusheng', '方楚生#fangchusheng');
INSERT INTO `meta_table_column` VALUES (4133, 1, 'spark_catalog', 'bigdata', 'test_hudi_demo', 'id', NULL, 'int', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-09 14:55:33', '2022-09-09 14:55:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4134, 1, 'spark_catalog', 'bigdata', 'test_hudi_demo', 'name', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-09 14:55:33', '2022-09-09 14:55:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4135, 1, 'spark_catalog', 'bigdata', 'test_hudi_demo', 'price', NULL, 'double', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-09 14:55:33', '2022-09-09 14:55:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4136, 1, 'spark_catalog', 'bigdata', 'test_hudi_demo', 'ds', NULL, 'string', NULL, NULL, 1, 0, 1, '', '', '', 0, 0, '2022-09-09 14:55:33', '2022-09-09 14:55:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4235, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'id', NULL, 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 1, 1, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4236, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'tenant_id', NULL, 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4237, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'code', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4238, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'name', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4239, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'storage_code', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4240, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'jobs', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4241, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'compute_type', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4242, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'scheduler_type', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4243, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'cluster_type', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4244, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'compute_version', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4245, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'jobserver_config', NULL, 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4246, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'spark_config', NULL, 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4247, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'thriftserver_config', NULL, 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4248, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'yarn_config', NULL, 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4249, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'mapred_config', NULL, 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4250, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'k8s_config', NULL, 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4251, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'default_cluster', NULL, 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4252, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'status', NULL, 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4253, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'thrift_server_count', NULL, 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4254, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'thrift_server_enabled', NULL, 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4255, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'creater', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4256, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'modifier', NULL, 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4257, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'gmt_created', NULL, 'DATETIME', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4258, 1, 'superior', 'superior_test', 'meta_cluster_compute', 'gmt_modified', NULL, 'DATETIME', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 1, 0, '2022-09-13 21:24:50', '2022-09-13 21:24:50', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4263, 1, 'postgres_demo', 'public', 'accounts', 'user_id', NULL, 'serial', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 1, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4264, 1, 'postgres_demo', 'public', 'accounts', 'username', NULL, 'varchar', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4265, 1, 'postgres_demo', 'public', 'accounts', 'password', NULL, 'varchar', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4266, 1, 'postgres_demo', 'public', 'accounts', 'email', NULL, 'varchar', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4267, 1, 'postgres_demo', 'public', 'accounts', 'created_on', NULL, 'timestamp', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4268, 1, 'postgres_demo', 'public', 'accounts', 'last_login', NULL, 'timestamp', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-13 22:16:25', '2022-09-13 22:16:25', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4293, 1, 'superior', 'Demo', 'St_User', 'id', 'ID', 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 1, '2022-09-15 21:37:28', '2022-09-15 21:37:28', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4294, 1, 'superior', 'Demo', 'St_User', 'name', 'Name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-15 21:37:28', '2022-09-15 21:37:28', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4295, 1, 'superior', 'Demo', 'St_User', 'st age', 'ST age', 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-15 21:37:28', '2022-09-15 21:37:28', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4299, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'date_col', 'date_col', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4300, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'year_col', 'year_col', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4301, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'month_col', 'month_col', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4302, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'store_type', 'store_type', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4303, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'store_code', 'store_code', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4304, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'matnr', 'matnr', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4305, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'province_name', 'province_name', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4306, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'city_area_name', 'city_area_name', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4307, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'district_name', 'district_name', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4308, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'purchase_category1', 'purchase_category1', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4309, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'sale_tax', 'sale_tax', 'DOUBLE', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4310, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'sale_untax', 'sale_untax', 'DOUBLE', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4311, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'cost_tax', 'cost_tax', 'DOUBLE', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4312, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'cost_untax', 'cost_untax', 'DOUBLE', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4313, 1, 'aotele', 'pevc_reviw', 'tmp_3', 'sale_num', 'sale_num', 'DOUBLE', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 14:58:59', '2022-09-21 14:58:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4314, 1, 'superior', 'superior_test', 'meta_job', 'id', 'id', 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 1, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4315, 1, 'superior', 'superior_test', 'meta_job', 'workspace_code', 'workspace_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4316, 1, 'superior', 'superior_test', 'meta_job', 'tenant_id', 'tenant_id', 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4317, 1, 'superior', 'superior_test', 'meta_job', 'folder_id', 'folder_id', 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4318, 1, 'superior', 'superior_test', 'meta_job', 'name', 'name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4319, 1, 'superior', 'superior_test', 'meta_job', 'code', 'code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4320, 1, 'superior', 'superior_test', 'meta_job', 'cluster_code', 'cluster_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4321, 1, 'superior', 'superior_test', 'meta_job', 'detail', 'detail', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4322, 1, 'superior', 'superior_test', 'meta_job', 'content', 'content', 'LONGTEXT', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4323, 1, 'superior', 'superior_test', 'meta_job', 'type', 'type', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4324, 1, 'superior', 'superior_test', 'meta_job', 'params', 'params', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4325, 1, 'superior', 'superior_test', 'meta_job', 'version', 'version', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4326, 1, 'superior', 'superior_test', 'meta_job', 'auditor', 'auditor', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4327, 1, 'superior', 'superior_test', 'meta_job', 'owner', 'owner', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4328, 1, 'superior', 'superior_test', 'meta_job', 'proxy_user', 'proxy_user', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4329, 1, 'superior', 'superior_test', 'meta_job', 'current', 'current', 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:48', '2022-09-21 23:14:48', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4330, 1, 'superior', 'superior_test', 'meta_job', 'status', 'status', 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4331, 1, 'superior', 'superior_test', 'meta_job', 'publish_time', 'publish_time', 'DATETIME', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4332, 1, 'superior', 'superior_test', 'meta_job', 'retry_enabled', 'retry_enabled', 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4333, 1, 'superior', 'superior_test', 'meta_job', 'immediately_schedule', 'immediately_schedule', 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4334, 1, 'superior', 'superior_test', 'meta_job', 'dep_last_period', 'dep_last_period', 'TINYINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4335, 1, 'superior', 'superior_test', 'meta_job', 'schedule_type', 'schedule_type', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4336, 1, 'superior', 'superior_test', 'meta_job', 'history', 'history', 'TINYINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4337, 1, 'superior', 'superior_test', 'meta_job', 'trash', 'trash', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4338, 1, 'superior', 'superior_test', 'meta_job', 'format', 'format', 'SMALLINT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4339, 1, 'superior', 'superior_test', 'meta_job', 'run_level', 'run_level', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4340, 1, 'superior', 'superior_test', 'meta_job', 'auth_users', 'auth_users', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4341, 1, 'superior', 'superior_test', 'meta_job', 'schedule_mode', 'schedule_mode', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4342, 1, 'superior', 'superior_test', 'meta_job', 'gmt_created', 'gmt_created', 'DATETIME', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4343, 1, 'superior', 'superior_test', 'meta_job', 'gmt_modified', 'gmt_modified', 'DATETIME', 'TIMESTAMP', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4344, 1, 'superior', 'superior_test', 'meta_job', 'creater', 'creater', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4345, 1, 'superior', 'superior_test', 'meta_job', 'modifier', 'modifier', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-21 23:14:49', '2022-09-21 23:14:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4378, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'date_col', 'date_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4379, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'year_col', 'year_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4380, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'month_col', 'month_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4381, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'day_col', 'day_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4382, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'store_type', 'store_type', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4383, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'store_code', 'store_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4384, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'matnr', 'matnr', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4385, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'ware_name', 'ware_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4386, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'supplier_code', 'supplier_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4387, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'province_name', 'province_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4388, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'city_area_name', 'city_area_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4389, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'district_name', 'district_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4390, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'sale_tax', 'sale_tax', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4391, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'sale_no', 'sale_no', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4392, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'cost_tax', 'cost_tax', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4393, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'cost_no', 'cost_no', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4394, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'sale_num', 'sale_num', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4395, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'purchase_category1', 'purchase_category1', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4396, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'supplier_name', 'supplier_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4397, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'brand_class', 'brand_class', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4398, 1, 'aotele', 'pevc_reviw', 'test_table_1', 'region_class', 'region_class', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 13:53:35', '2022-09-22 13:53:35', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4401, 1, 'aotele', 'pevc_reviw', 'a1', 'sj', 'sj', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:19:05', '2022-09-22 14:19:05', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4402, 1, 'aotele', 'pevc_reviw', 'a1', 'gmv', 'gmv', 'DOUBLE', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:19:05', '2022-09-22 14:19:05', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4405, 1, 'aotele', 'pevc_reviw', 'test_table', 'time_col', 'time_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4406, 1, 'aotele', 'pevc_reviw', 'test_table', 'year_col', 'year_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4407, 1, 'aotele', 'pevc_reviw', 'test_table', 'month_col', 'month_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4408, 1, 'aotele', 'pevc_reviw', 'test_table', 'day_col', 'day_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4409, 1, 'aotele', 'pevc_reviw', 'test_table', 'store_type', 'store_type', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4410, 1, 'aotele', 'pevc_reviw', 'test_table', 'store_code', 'store_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4411, 1, 'aotele', 'pevc_reviw', 'test_table', 'matnr', 'matnr', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4412, 1, 'aotele', 'pevc_reviw', 'test_table', 'ware_name', 'ware_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4413, 1, 'aotele', 'pevc_reviw', 'test_table', 'supplier_code', 'supplier_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4414, 1, 'aotele', 'pevc_reviw', 'test_table', 'province_name', 'province_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4415, 1, 'aotele', 'pevc_reviw', 'test_table', 'city_area_name', 'city_area_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4416, 1, 'aotele', 'pevc_reviw', 'test_table', 'district_name', 'district_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4417, 1, 'aotele', 'pevc_reviw', 'test_table', 'sale_have', 'sale_have', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4418, 1, 'aotele', 'pevc_reviw', 'test_table', 'sale_no', 'sale_no', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4419, 1, 'aotele', 'pevc_reviw', 'test_table', 'cost_have', 'cost_have', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4420, 1, 'aotele', 'pevc_reviw', 'test_table', 'cost_no', 'cost_no', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4421, 1, 'aotele', 'pevc_reviw', 'test_table', 'sale_num', 'sale_num', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4422, 1, 'aotele', 'pevc_reviw', 'test_table', 'purchase_category1', 'purchase_category1', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4423, 1, 'aotele', 'pevc_reviw', 'test_table', 'supplier_name', 'supplier_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4424, 1, 'aotele', 'pevc_reviw', 'test_table', 'brand_class', 'brand_class', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-22 14:24:59', '2022-09-22 14:24:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4561, 1, 'new_server', 'ydec', 'test_table', 'time_col', 'time_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4562, 1, 'new_server', 'ydec', 'test_table', 'year_col', 'year_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4563, 1, 'new_server', 'ydec', 'test_table', 'month_col', 'month_col', 'INT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4564, 1, 'new_server', 'ydec', 'test_table', 'day_col', 'day_col', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4565, 1, 'new_server', 'ydec', 'test_table', 'store_type', 'store_type', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4566, 1, 'new_server', 'ydec', 'test_table', 'store_code', 'store_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4567, 1, 'new_server', 'ydec', 'test_table', 'matnr', 'matnr', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4568, 1, 'new_server', 'ydec', 'test_table', 'ware_name', 'ware_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4569, 1, 'new_server', 'ydec', 'test_table', 'supplier_code', 'supplier_code', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4570, 1, 'new_server', 'ydec', 'test_table', 'province_name', 'province_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4571, 1, 'new_server', 'ydec', 'test_table', 'city_area_name', 'city_area_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4572, 1, 'new_server', 'ydec', 'test_table', 'district_name', 'district_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4573, 1, 'new_server', 'ydec', 'test_table', 'sale_have', 'sale_have', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4574, 1, 'new_server', 'ydec', 'test_table', 'sale_no', 'sale_no', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4575, 1, 'new_server', 'ydec', 'test_table', 'cost_have', 'cost_have', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4576, 1, 'new_server', 'ydec', 'test_table', 'cost_no', 'cost_no', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4577, 1, 'new_server', 'ydec', 'test_table', 'sale_num', 'sale_num', 'FLOAT', 'NUMERIC', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4578, 1, 'new_server', 'ydec', 'test_table', 'purchase_category1', 'purchase_category1', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4579, 1, 'new_server', 'ydec', 'test_table', 'supplier_name', 'supplier_name', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4580, 1, 'new_server', 'ydec', 'test_table', 'brand_class', 'brand_class', 'VARCHAR', 'VARCHAR', NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-28 23:25:36', '2022-09-28 23:25:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4581, 1, 'spark_catalog', 'test001', 'test_table_dt', 'time_col', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4582, 1, 'spark_catalog', 'test001', 'test_table_dt', 'year_col', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4583, 1, 'spark_catalog', 'test001', 'test_table_dt', 'month_col', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4584, 1, 'spark_catalog', 'test001', 'test_table_dt', 'day_col', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4585, 1, 'spark_catalog', 'test001', 'test_table_dt', 'store_type', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4586, 1, 'spark_catalog', 'test001', 'test_table_dt', 'store_code', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4587, 1, 'spark_catalog', 'test001', 'test_table_dt', 'matnr', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4588, 1, 'spark_catalog', 'test001', 'test_table_dt', 'ware_name', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4589, 1, 'spark_catalog', 'test001', 'test_table_dt', 'supplier_code', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4590, 1, 'spark_catalog', 'test001', 'test_table_dt', 'province_name', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4591, 1, 'spark_catalog', 'test001', 'test_table_dt', 'city_area_name', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4592, 1, 'spark_catalog', 'test001', 'test_table_dt', 'district_name', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4593, 1, 'spark_catalog', 'test001', 'test_table_dt', 'sale_have', NULL, 'float', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4594, 1, 'spark_catalog', 'test001', 'test_table_dt', 'sale_no', NULL, 'float', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4595, 1, 'spark_catalog', 'test001', 'test_table_dt', 'cost_have', NULL, 'float', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4596, 1, 'spark_catalog', 'test001', 'test_table_dt', 'cost_no', NULL, 'float', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4597, 1, 'spark_catalog', 'test001', 'test_table_dt', 'sale_num', NULL, 'float', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4598, 1, 'spark_catalog', 'test001', 'test_table_dt', 'purchase_category1', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4599, 1, 'spark_catalog', 'test001', 'test_table_dt', 'supplier_name', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4600, 1, 'spark_catalog', 'test001', 'test_table_dt', 'brand_class', NULL, 'varchar(255)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4601, 1, 'spark_catalog', 'test001', 'test_table_dt', 'ds', NULL, 'string', NULL, NULL, 1, 0, 1, '', '', '', 0, 0, '2022-09-29 17:09:58', '2022-09-29 17:09:58', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4602, 1, 'spark_catalog', 'test001', 'dws_purchase_category1_di', 'purchase_category1', NULL, 'varchar(10)', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-30 15:48:21', '2022-09-30 15:48:21', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4603, 1, 'spark_catalog', 'test001', 'dws_purchase_category1_di', 'gmv', NULL, 'float', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-09-30 15:48:21', '2022-09-30 15:48:21', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_column` VALUES (4606, 1, 'spark_catalog', 'bigdata', 'test_demo_dt1', 'name', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-10-15 17:33:49', '2022-10-15 17:33:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4607, 1, 'spark_catalog', 'bigdata', 'test_demo_dt1', 'age', NULL, 'int', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-10-15 17:33:49', '2022-10-15 17:33:49', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4608, 1, 'spark_catalog', 'bigdata', 'test_demo_test1', 'name', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-10-15 19:12:01', '2022-10-15 19:12:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4609, 1, 'spark_catalog', 'bigdata', 'test_demo_test1', 'age', NULL, 'int', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-10-15 19:12:01', '2022-10-15 19:12:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4610, 1, 'spark_catalog', 'bigdata', 'test_demo_dt', 'name', NULL, 'string', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-10-15 22:13:42', '2022-10-15 22:13:42', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4611, 1, 'spark_catalog', 'bigdata', 'test_demo_dt', 'age', NULL, 'int', NULL, NULL, 1, 0, 0, '', '', '', 0, 0, '2022-10-15 22:13:42', '2022-10-15 22:13:42', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_table_column` VALUES (4612, 1, 'spark_catalog', 'bigdata', 'test_demo_dt', 'ds', NULL, 'string', NULL, NULL, 1, 0, 1, '', '', '', 0, 0, '2022-10-15 22:13:42', '2022-10-15 22:13:42', '怀信#huaixin', '怀信#huaixin');
COMMIT;

-- ----------------------------
-- Table structure for meta_table_column_privs
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_column_privs`;
CREATE TABLE `meta_table_column_privs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `sec_table_id` varchar(45) NOT NULL COMMENT 'dc_table_privs 表主键',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `database_name` varchar(128) NOT NULL COMMENT '数据库名',
  `table_name` varchar(256) NOT NULL COMMENT '表名，可以是表达式',
  `column_name` varchar(128) NOT NULL COMMENT '表列名',
  `sec_type` varchar(45) NOT NULL COMMENT '授权类型：user、group、role',
  `obj_id` varchar(45) NOT NULL,
  `obj_name` varchar(45) NOT NULL COMMENT '用户/角色 的中文名称',
  `sec_level` tinyint(4) DEFAULT NULL,
  `lifecycle` int(11) DEFAULT NULL,
  `mark` tinyint(4) DEFAULT '0' COMMENT '1：脱敏',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL COMMENT '创建人',
  `modifier` varchar(45) DEFAULT NULL COMMENT '修改人',
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  PRIMARY KEY (`id`) USING BTREE,
  KEY `idx_table_id` (`sec_table_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=380 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_table_column_privs
-- ----------------------------
BEGIN;
INSERT INTO `meta_table_column_privs` VALUES (376, '32', 1, 'bigdata', 'test_user12_dt', 'name', 'user', 'huaixin', '怀信', 1, 365, 0, '2022-07-27 11:18:45', '2022-07-27 11:18:45', '怀信#huaixin', '怀信#huaixin', 'spark_catalog');
INSERT INTO `meta_table_column_privs` VALUES (377, '32', 1, 'bigdata', 'test_user12_dt', 'num', 'user', 'huaixin', '怀信', 1, 365, 0, '2022-07-27 11:18:45', '2022-07-27 11:18:45', '怀信#huaixin', '怀信#huaixin', 'spark_catalog');
INSERT INTO `meta_table_column_privs` VALUES (378, '33', 1, 'bigdata', 'test_user11_dt', 'name', 'user', 'buxuan', '不玄', 1, 365, 0, '2022-07-29 00:06:46', '2022-07-29 00:06:46', '不玄#buxuan', '不玄#buxuan', 'spark_catalog');
INSERT INTO `meta_table_column_privs` VALUES (379, '33', 1, 'bigdata', 'test_user11_dt', 'num', 'user', 'buxuan', '不玄', 1, 365, 0, '2022-07-29 00:06:46', '2022-07-29 00:06:46', '不玄#buxuan', '不玄#buxuan', 'spark_catalog');
COMMIT;

-- ----------------------------
-- Table structure for meta_table_lineage
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_lineage`;
CREATE TABLE `meta_table_lineage` (
  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `workspace_code` varchar(64) DEFAULT NULL COMMENT '作业所属项目',
  `type` varchar(64) DEFAULT NULL COMMENT '数据来源,自动解析(auto),人工填写(manual)',
  `source_catalog` varchar(128) DEFAULT 'spark_catalog',
  `source_database` varchar(64) DEFAULT NULL COMMENT 'source db',
  `source_table_name` varchar(128) DEFAULT NULL COMMENT 'source table',
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) DEFAULT NULL COMMENT 'database',
  `table_name` varchar(128) DEFAULT NULL COMMENT 'table name',
  `job_code` varchar(128) DEFAULT NULL COMMENT '作业code',
  `count` int(11) DEFAULT '1' COMMENT '调用次数',
  `job_status` smallint(6) DEFAULT '0' COMMENT '作业是否被删除，1：删除，0：未删除',
  `creater` varchar(64) NOT NULL COMMENT '创建人',
  `modifier` varchar(64) DEFAULT NULL COMMENT '修改人',
  `gmt_created` datetime NOT NULL COMMENT '创建时间',
  `gmt_modified` datetime DEFAULT NULL COMMENT '修改时间',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='表血缘关系';

-- ----------------------------
-- Records of meta_table_lineage
-- ----------------------------
BEGIN;
COMMIT;

-- ----------------------------
-- Table structure for meta_table_oper_log
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_oper_log`;
CREATE TABLE `meta_table_oper_log` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) NOT NULL,
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) NOT NULL COMMENT '数据库名',
  `table_name` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `type` varchar(45) DEFAULT NULL,
  `content` longtext,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `table_name_index` (`database_name`,`table_name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=1423 DEFAULT CHARSET=utf8mb4 COMMENT='表schema 操作日志';

-- ----------------------------
-- Records of meta_table_oper_log
-- ----------------------------
BEGIN;
INSERT INTO `meta_table_oper_log` VALUES (1415, 1, 'spark_catalog', 'aoteledemo', 'test_table_dt', 'DROP_TABLE', 'drop table if exists aoteledemo.test_table_dt', '2022-09-29 17:01:59', '2022-09-29 17:01:59', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_table_oper_log` VALUES (1416, 1, 'spark_catalog', 'test001', 'test_table_dt', 'CREATE_TABLE', 'create table test001.test_table_dt (\n  time_col varchar(255) comment \'\',\n  year_col varchar(255) comment \'\',\n  month_col varchar(255) comment \'\',\n  day_col varchar(255) comment \'\',\n  store_type varchar(255) comment \'\',\n  store_code varchar(255) comment \'\',\n  matnr varchar(255) comment \'\',\n  ware_name varchar(255) comment \'\',\n  supplier_code varchar(255) comment \'\',\n  province_name varchar(255) comment \'\',\n  city_area_name varchar(255) comment \'\',\n  district_name varchar(255) comment \'\',\n  sale_have float comment \'\',\n  sale_no float comment \'\',\n  cost_have float comment \'\',\n  cost_no float comment \'\',\n  sale_num float comment \'\',\n  purchase_category1 varchar(255) comment \'\',\n  supplier_name varchar(255) comment \'\',\n  brand_class varchar(255) comment \'\'\n)\nPARTITIONED BY (\n  ds string comment \'\'\n)\nSTORED AS parquet\nTBLPROPERTIES (\'parquet.block.size\'=\'268435456\', \'parquet.compression\'=\'zstd\', \'fileFormat\'=\'parquet\')\n', '2022-09-29 17:09:58', NULL, '不玄#buxuan', NULL);
INSERT INTO `meta_table_oper_log` VALUES (1417, 1, 'spark_catalog', 'test001', 'dws_purchase_category1_di', 'CREATE_TABLE', 'create table test001.dws_purchase_category1_di (\n  purchase_category1 varchar(10) comment \'\',\n  gmv float comment \'\'\n)\nSTORED AS parquet\nTBLPROPERTIES (\'parquet.block.size\'=\'268435456\', \'parquet.compression\'=\'zstd\', \'fileFormat\'=\'parquet\')\n', '2022-09-30 15:48:21', NULL, '不玄#buxuan', NULL);
INSERT INTO `meta_table_oper_log` VALUES (1418, 1, 'spark_catalog', 'bigdata', 'test_demo_dt', 'CREATE_TABLE', 'create table bigdata.test_demo_dt (\n  name string comment \'\',\n  age int comment \'\'\n) USING parquet\nOPTIONS (\'compression\'=\'zstd\', \'parquet.compression\'=\'zstd\')\n', '2022-10-15 16:58:29', NULL, '怀信#huaixin', NULL);
INSERT INTO `meta_table_oper_log` VALUES (1419, 1, 'spark_catalog', 'bigdata', 'test_demo_dt1', 'CREATE_TABLE', 'create table bigdata.test_demo_dt1 (\n  name string comment \'\',\n  age int comment \'\'\n) USING parquet\nOPTIONS (\'compression\'=\'zstd\', \'parquet.compression\'=\'zstd\')\n', '2022-10-15 17:33:49', NULL, '怀信#huaixin', NULL);
INSERT INTO `meta_table_oper_log` VALUES (1420, 1, 'spark_catalog', 'bigdata', 'test_demo_test1', 'CREATE_TABLE', 'create table bigdata.test_demo_test1 (\n  name string comment \'\',\n  age int comment \'\'\n) USING parquet\nOPTIONS (\'compression\'=\'zstd\', \'parquet.compression\'=\'zstd\')\n', '2022-10-15 19:12:01', NULL, '怀信#huaixin', NULL);
INSERT INTO `meta_table_oper_log` VALUES (1421, 1, 'spark_catalog', 'bigdata', 'test_demo_dt', 'DROP_TABLE', 'drop table if exists test_demo_dt', '2022-10-15 22:13:34', NULL, '怀信#huaixin', NULL);
INSERT INTO `meta_table_oper_log` VALUES (1422, 1, 'spark_catalog', 'bigdata', 'test_demo_dt', 'CREATE_TABLE', 'create table bigdata.test_demo_dt (\n  name string comment \'\',\n  age int comment \'\',\n  ds String comment \'\'\n) USING parquet\nOPTIONS (\'compression\'=\'zstd\', \'parquet.compression\'=\'zstd\')\nPARTITIONED BY (ds)\n', '2022-10-15 22:13:42', NULL, '怀信#huaixin', NULL);
COMMIT;

-- ----------------------------
-- Table structure for meta_table_partition
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_partition`;
CREATE TABLE `meta_table_partition` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) NOT NULL,
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) NOT NULL DEFAULT '' COMMENT '数据库',
  `table_name` varchar(128) NOT NULL DEFAULT '' COMMENT '表名',
  `partition_spec` varchar(128) NOT NULL DEFAULT '' COMMENT '分区值',
  `location` varchar(1024) DEFAULT NULL COMMENT '分区存放位置',
  `last_access_time` datetime DEFAULT NULL COMMENT '数据修改时间',
  `last_update_time` datetime DEFAULT NULL COMMENT '数据修改时间',
  `total_number_files` bigint(20) DEFAULT '0' COMMENT '分区文件数量',
  `total_file_size` bigint(20) DEFAULT '0' COMMENT '分区存储大小',
  `num_rows` bigint(20) DEFAULT '0' COMMENT '分区记录条数',
  `compression` varchar(45) DEFAULT NULL COMMENT '数据文件压缩编码',
  `gmt_created` datetime DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `database_name_UNIQUE` (`database_name`) USING BTREE,
  KEY `table_name_UNIQUE` (`table_name`) USING BTREE,
  KEY `partition_spec_UNIQUE` (`partition_spec`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_table_partition
-- ----------------------------
BEGIN;
COMMIT;

-- ----------------------------
-- Table structure for meta_table_privs
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_privs`;
CREATE TABLE `meta_table_privs` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `database_name` varchar(128) NOT NULL COMMENT '数据库名(projectCode)',
  `table_name` varchar(128) NOT NULL COMMENT '表名，可以是表达式',
  `auth_type` varchar(45) NOT NULL COMMENT '授权类型：user、group、role',
  `obj_id` varchar(45) NOT NULL COMMENT '用户/角色 的id或者code',
  `obj_name` varchar(45) NOT NULL COMMENT '用户/角色 的中文名称',
  `read_priv` tinyint(4) DEFAULT '0',
  `write_priv` tinyint(4) DEFAULT '0',
  `alter_priv` tinyint(4) DEFAULT '0',
  `drop_priv` tinyint(4) DEFAULT '0',
  `lifecycle` int(11) DEFAULT '0',
  `status` tinyint(4) DEFAULT '0' COMMENT '0: 权限审批中，1：审批通过，3：审批不通过,  5：权限收回（负责人），7：撤销申请（申请人），9：申请过期, 11：释放权限',
  `owner` varchar(45) NOT NULL,
  `detail` varchar(1024) DEFAULT NULL,
  `expire_date` datetime NOT NULL,
  `pattern` varchar(45) DEFAULT 'single' COMMENT 'single： 单表匹配，like：批量申请表',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  PRIMARY KEY (`id`) USING BTREE,
  KEY `table_name_index` (`database_name`,`table_name`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=34 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_table_privs
-- ----------------------------
BEGIN;
INSERT INTO `meta_table_privs` VALUES (32, 1, 'bigdata', 'test_user12_dt', 'user', 'huaixin', '怀信', 1, 0, 0, 0, 365, 1, '不玄#buxuan', '22', '2023-07-27 11:18:45', 'single', '2022-07-27 11:18:45', '2022-07-27 11:18:45', '怀信#huaixin', '怀信#huaixin', 'spark_catalog');
INSERT INTO `meta_table_privs` VALUES (33, 1, 'bigdata', 'test_user11_dt', 'user', 'buxuan', '不玄', 1, 0, 0, 0, 365, 1, '怀信#huaixin', '需要查看', '2023-07-29 00:06:45', 'single', '2022-07-29 00:06:46', '2022-07-29 00:06:46', '不玄#buxuan', '不玄#buxuan', 'spark_catalog');
COMMIT;

-- ----------------------------
-- Table structure for meta_table_subject
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_subject`;
CREATE TABLE `meta_table_subject` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `code` varchar(45) NOT NULL,
  `parent_code` varchar(45) DEFAULT NULL COMMENT '父主题ID',
  `subject` varchar(64) NOT NULL COMMENT '主题',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COMMENT='表主题域';

-- ----------------------------
-- Records of meta_table_subject
-- ----------------------------
BEGIN;
INSERT INTO `meta_table_subject` VALUES (1, 'nFEige', NULL, '成果库', '2022-09-12 16:12:27', '2022-09-12 16:12:27', '阿平#xuanwu', '阿平#xuanwu', 1);
INSERT INTO `meta_table_subject` VALUES (2, 'hfcD5s', 'nFEige', '云端安全主题库', '2022-09-12 16:13:04', '2022-09-12 16:13:04', '阿平#xuanwu', '阿平#xuanwu', 1);
INSERT INTO `meta_table_subject` VALUES (3, 'U7fhum', 'nFEige', '政务外网主题库', '2022-09-12 16:13:15', '2022-09-12 16:13:15', '阿平#xuanwu', '阿平#xuanwu', 1);
INSERT INTO `meta_table_subject` VALUES (4, 'WNGpSc', 'nFEige', '终端资产主题库', '2022-09-14 10:23:43', '2022-09-14 10:23:59', '阿平#xuanwu', '阿平#xuanwu', 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_table_tag
-- ----------------------------
DROP TABLE IF EXISTS `meta_table_tag`;
CREATE TABLE `meta_table_tag` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `tag_type` smallint(6) DEFAULT '0' COMMENT '0：用户自定义标签\n1：数据源\n2：数据层\n3：数据集市\n4：更新周期\n',
  `name` varchar(64) NOT NULL COMMENT '标签名称',
  `table_id` int(11) NOT NULL,
  `catalog_name` varchar(128) DEFAULT 'spark_catalog',
  `database_name` varchar(128) NOT NULL,
  `table_name` varchar(128) NOT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `name_UNIQUE` (`name`,`database_name`,`table_name`) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='表标签信息';

-- ----------------------------
-- Records of meta_table_tag
-- ----------------------------
BEGIN;
COMMIT;

-- ----------------------------
-- Table structure for meta_tenant_info
-- ----------------------------
DROP TABLE IF EXISTS `meta_tenant_info`;
CREATE TABLE `meta_tenant_info` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_code` varchar(128) NOT NULL COMMENT '租户账号',
  `tenant_name` varchar(45) NOT NULL COMMENT '租户名称',
  `enabled` tinyint(1) DEFAULT '1' COMMENT '表示是否可用，0 无效，1 有效',
  `register_date` datetime DEFAULT NULL COMMENT '租户开通时间',
  `expired_date` datetime DEFAULT NULL COMMENT '租户过期时间',
  `remark` varchar(4096) DEFAULT NULL COMMENT '备注说明',
  `header` varchar(255) DEFAULT NULL,
  `logo` longblob COMMENT 'logo',
  `yarn_queue` varchar(128) DEFAULT NULL,
  `config` varchar(4096) DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `tenant_code_UNIQUE` (`tenant_code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=33 DEFAULT CHARSET=utf8mb4 COMMENT='租户表';

-- ----------------------------
-- Records of meta_tenant_info
-- ----------------------------
BEGIN;
INSERT INTO `meta_tenant_info` VALUES (1, 'aloudata', 'Superior', 1, '2021-09-01 00:00:00', '2099-09-01 00:00:00', 'Superior', 'Superior数据中台', NULL, 'default', 'tenant.hiveDbName = hive\r\ntenant.yarnProxyUrls = http://40.72.114.55:8088\r\ntenant.thriftServerUrls = 10.5.20.12:10000', '怀信#huaixin', '不玄#buxuan', '2021-09-16 15:33:50', '2022-09-28 22:27:34');
INSERT INTO `meta_tenant_info` VALUES (32, '6cFLE2Lx', '安全', 0, '2022-09-13 00:00:00', '2022-11-30 00:00:00', '', '安全数据中台', NULL, 'root.users.hdfs', 'tenant.hiveDbName = hive\r\ntenant.yarnProxyUrls = http://40.72.114.55:8088\r\ntenant.thriftServerUrls = 10.5.20.12:10000', '阿平#xuanwu', '怀信#huaixin', '2022-09-13 18:37:58', '2022-09-21 12:49:07');
COMMIT;

-- ----------------------------
-- Table structure for meta_thrift_server
-- ----------------------------
DROP TABLE IF EXISTS `meta_thrift_server`;
CREATE TABLE `meta_thrift_server` (
  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `tenant_id` int(11) DEFAULT NULL,
  `cluster_code` varchar(64) NOT NULL COMMENT 'cluster code',
  `server_ip` varchar(45) DEFAULT NULL COMMENT 'server ip',
  `server_port` varchar(45) DEFAULT NULL COMMENT 'server port',
  `job_server_id` int(11) NOT NULL COMMENT 'job server id',
  `app_id` varchar(64) DEFAULT NULL COMMENT 'spark app id',
  `status` varchar(45) DEFAULT NULL COMMENT '运行状态，accept, running',
  `creater` varchar(45) DEFAULT NULL COMMENT 'creater',
  `modifier` varchar(45) DEFAULT NULL COMMENT 'modifier',
  `gmt_created` datetime DEFAULT NULL COMMENT 'gmt_created',
  `gmt_modified` datetime DEFAULT NULL COMMENT 'gmt_modified',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=6151 DEFAULT CHARSET=utf8 COMMENT='thrift server';

-- ----------------------------
-- Records of meta_thrift_server
-- ----------------------------
BEGIN;
INSERT INTO `meta_thrift_server` VALUES (6150, 1, 'hangzhou-spark-3.2', '10.0.2.112', '51242', 16789, 'application_1665585149227_0006', 'running', NULL, NULL, '2022-10-15 16:56:24', '2022-10-15 16:57:08');
COMMIT;

-- ----------------------------
-- Table structure for meta_user_info
-- ----------------------------
DROP TABLE IF EXISTS `meta_user_info`;
CREATE TABLE `meta_user_info` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `user_id` varchar(128) NOT NULL COMMENT '用户账号',
  `cn_name` varchar(45) NOT NULL COMMENT '用户中文名称',
  `password` varchar(256) DEFAULT NULL COMMENT '账号密码',
  `email` varchar(128) DEFAULT NULL,
  `mobile` varchar(32) DEFAULT NULL,
  `appkey` varchar(45) NOT NULL,
  `appsecret` varchar(45) NOT NULL,
  `score` int(11) DEFAULT '100' COMMENT '个人的平台数据质量分',
  `status` smallint(6) DEFAULT '0' COMMENT '连续第几次个人的平台数据质量分不达标',
  `gitlab_token` varchar(45) DEFAULT NULL,
  `account_type` varchar(8) DEFAULT 'user' COMMENT '账号类型user & app',
  `rela_user_id` varchar(45) DEFAULT NULL COMMENT '应用账号管理的用户账号',
  `admin` smallint(6) DEFAULT '0' COMMENT '是否管理员,1是，0否',
  `role` varchar(45) DEFAULT 'default' COMMENT '角色: superadmin, default',
  `sec_enabled` tinyint(1) DEFAULT '1' COMMENT '表示是否可用，0 无效，1 有效',
  `sec_account_expired_date` datetime DEFAULT NULL COMMENT '账号过期时间',
  `sec_credentials_expired_date` datetime DEFAULT NULL COMMENT '密码过期时间',
  `sec_locked_date` datetime DEFAULT NULL COMMENT '账号锁定到期时间',
  `sec_non_update_pw` tinyint(1) DEFAULT '1' COMMENT '系统分配默认账号，或者重置密码，首次登录需要强制修改密码， 0 需要更新密码，1 不需要更新密码，',
  `sec_attempts` int(11) DEFAULT '0' COMMENT '密码尝试登录次数, 找过一定次数，锁定一段时间',
  `sec_login_date` datetime DEFAULT NULL COMMENT '最近登录时间',
  `sec_confirm` tinyint(1) DEFAULT '1' COMMENT '账号是否验证通过，0 未验证，1 已验证',
  `sec_comfirm_token` varchar(256) DEFAULT NULL COMMENT '账号验证token',
  `sec_comfirm_expired_date` datetime DEFAULT NULL COMMENT '账号验证token过期时间',
  `modifier` varchar(45) DEFAULT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `ding_uid` varchar(32) DEFAULT NULL COMMENT '钉钉userId',
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `appkey_UNIQUE` (`appkey`) USING BTREE,
  UNIQUE KEY `appsecret_UNIQUE` (`appsecret`) USING BTREE,
  UNIQUE KEY `user_id_UNIQUE` (`user_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=76 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_user_info
-- ----------------------------
BEGIN;
INSERT INTO `meta_user_info` VALUES (1, 'admin', '管理员', 'f3b905574c8e4dd9f4f56f847af0f765e279f1aac0df51955e1d1ed035739822a6d76bcbb785dae8', 'admin@dataworker.com', '18963791949', 'xBLYFLigDRCOZprC', 'g6Yn8mrrdTr1Wj0mszszpZ2IXGCbekZ7', 100, 0, NULL, 'user', NULL, NULL, 'superadmin', 1, NULL, NULL, '2022-10-04 05:09:49', 1, 6, '2022-07-31 19:48:58', 1, NULL, NULL, '管理员#admin', '2017-04-19 17:50:32', '2020-05-24 22:30:45', '管理员#admin', '16237201874363391', 1);
INSERT INTO `meta_user_info` VALUES (6, 'huaixin', '怀信', 'b0aae56040cd3a4cd47db583813abfef49761e9c9cb28510e084ce77b628a6900a4e02b42bcef819', 'huaixin.li@aloudata.com', '18963791949', 'IMSd5CCBsOwjuzrR', 'InJ6y0grpQZ3iNDfRwIhKZnnF7IZhbVL', 97, 0, '', 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, '2022-10-15 16:59:59', 1, NULL, NULL, '怀信#huaixin', '2021-07-01 09:06:26', '2021-12-03 23:23:30', '怀信#huaixin', '16237201874363391', 1);
INSERT INTO `meta_user_info` VALUES (60, 'buxuan', '不玄', '5e6cf1d697e907f57e09f73b90a8af0115d40188498c0f83bd8b620933294c4d7f2fa0cb54f67502', NULL, NULL, 'ysTv9TeGowgx2PeR', 'kEeDLvCfLRYzdvnt1CgYl9FRxKsgo1JA', 97, 0, NULL, 'user', NULL, 0, 'systemadmin', 1, NULL, NULL, NULL, 1, 0, '2022-09-29 16:43:37', 1, NULL, NULL, '怀信#huaixin', '2022-07-27 09:37:33', '2022-07-27 09:37:33', '怀信#huaixin', NULL, 1);
INSERT INTO `meta_user_info` VALUES (62, 'tankchen', '陈远', '1e6577f4bae0fdf39efedbe48722709a16cb47c19b850347c484247a7fef20aa9afaf0411222cd8d', NULL, NULL, 'DeyUmMtfcTTO3Klc', 'C01vkhKRMwQ9UlDwPFpd9km0puCyWyGK', 100, 0, NULL, 'user', NULL, 0, 'systemadmin', 1, NULL, NULL, NULL, 1, 0, '2022-08-12 09:42:06', 1, NULL, NULL, '不玄#buxuan', '2022-08-01 15:36:25', '2022-08-08 10:30:38', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (63, 'zerolin', '林庆贤', 'd5ac3fcc5ff9734291ad6de73ebcd5dcca895ff7435a16049eadb6bfee810b48c774faab4be95d73', NULL, NULL, 'cveDdClc6mWbEvvV', 'wbH43GMabeyput0VYVEseRYasYKv3zDM', 95, 0, NULL, 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, '2022-08-10 16:15:36', 1, NULL, NULL, '不玄#buxuan', '2022-08-01 15:39:16', '2022-08-01 15:39:16', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (69, 'wangkai', '王凯', '87d4250c1dec1c0e2e8f303f9319cc881c79a524100b762935ca74a8d088cf6bd212a2315dbd1428', NULL, NULL, 'jP5i5FxKlIKx6TMe', 'WUYHxnMwrVSdLFgVrWlJJfk6sbxUOcTb', 100, 0, NULL, 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, '2022-09-23 18:09:48', 1, NULL, NULL, '不玄#buxuan', '2022-08-01 15:41:26', '2022-08-01 15:41:26', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (70, 'shiyang', '施杨', '8da8c7b8088644db5c66eccda0d149e93ca65a14958a6996abfa3ca7cb81dc615d28731dd837724d', NULL, NULL, 'CBkXewpzoGrIPvta', 'W14L49jKQsaSoTkzXD5z5JUDKkejC4Np', 100, 0, NULL, 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, NULL, 1, NULL, NULL, '不玄#buxuan', '2022-08-01 15:42:36', '2022-08-01 15:42:36', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (71, 'demo', 'demo', 'e532fd294bef62571f021774d164b8a96cfc2ff7b88d46afd942dc8cccfed1e2e2117596035f8aef', NULL, NULL, 'dDFbOcxbpN1AhfEd', 'eb6vBZiNifvQhNYpohYj3mXeuxubnZfc', 100, 0, NULL, 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, '2022-08-12 19:27:12', 1, NULL, NULL, '不玄#buxuan', '2022-08-06 13:40:00', '2022-08-06 13:40:00', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (72, 'fangchusheng', '方楚生', '20e39001b4431ab9595559be8deef301ae48b78f2ca0aa761a44e90e0005020a82289eda06ce9f7f', NULL, NULL, '0pBLDe1lq66MQRTC', 'vWvssH5GdjhtYfV4Sn6qBryG6tExD5lf', 100, 0, NULL, 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, '2022-09-02 14:44:26', 1, NULL, NULL, '不玄#buxuan', '2022-08-09 17:47:14', '2022-08-09 17:47:14', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (73, 'demo1', 'demo1', '49cc0e9302274de9fe3183ffa8532ab6ee860c98d54026670cc2dc5ba91887254b4247128b432886', NULL, NULL, 'kdzRAWu0WhB3mX2j', 'sTQkaM1dugTiXmb6zu75zKB1Yi3uXYID', 100, 0, NULL, 'user', NULL, 0, 'default', 1, NULL, NULL, NULL, 1, 0, NULL, 1, NULL, NULL, '不玄#buxuan', '2022-08-10 13:17:36', '2022-08-10 13:17:36', '不玄#buxuan', NULL, 1);
INSERT INTO `meta_user_info` VALUES (74, 'suzhi', '阿苏', '7e52fabbbc7c4468dd80c7a34751c62d41426f594ebc3a659ce24bf048cadafaba0b80a2746ba854', NULL, NULL, 'WgYO5FIlhfbAep2g', 'z6bEjP2ZOSI4noBAc7laKZSAQBAdrw5j', 100, 0, NULL, 'user', NULL, 0, 'systemadmin', 1, NULL, NULL, NULL, 1, 0, '2022-08-21 22:38:07', 1, NULL, NULL, '怀信#huaixin', '2022-08-21 22:36:12', '2022-08-21 22:36:12', '怀信#huaixin', NULL, 1);
INSERT INTO `meta_user_info` VALUES (75, 'xuanwu', '阿平', 'cf3a71935d725d5e465ab3807b061245f9efd6093dc5fbf0a733507dd9ab93b276011a9aaf75c95a', NULL, NULL, 'rBoTbBHyhzo6s7NL', 'eM4jR1oBOm10PJasuj3fjGu0yCl7HluQ', 100, 0, NULL, 'user', NULL, 0, 'systemadmin', 1, NULL, NULL, NULL, 1, 0, '2022-09-15 18:07:03', 1, NULL, NULL, '阿平#xuanwu', '2022-08-26 10:52:22', '2022-09-13 18:40:50', '怀信#huaixin', NULL, 1);
COMMIT;

-- ----------------------------
-- Table structure for meta_workspace
-- ----------------------------
DROP TABLE IF EXISTS `meta_workspace`;
CREATE TABLE `meta_workspace` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `name` varchar(45) NOT NULL,
  `code` varchar(45) NOT NULL,
  `auth_types` varchar(128) NOT NULL COMMENT '授权的作业类型，逗号分类',
  `table_sec_level` varchar(1) NOT NULL COMMENT '项目空间表默认安全级别\n0级 (不保密, Unclassified), 1级 (秘密, Confidential), 2级 (机密, Sensitive), 3级 (高度机密, Highly Sensitive)',
  `is_sec_shared` smallint(6) NOT NULL DEFAULT '0' COMMENT '该项目是否内部共享表权限，0：不共享，1，共享',
  `sec_level_shared` varchar(11) DEFAULT NULL COMMENT '项目内部表可共享的安全等级',
  `lifecycle` int(11) DEFAULT '0' COMMENT '表最大生命周期',
  `job_schedule` smallint(6) DEFAULT '1' COMMENT '项目下作业是否支持调度，1：支持，0，不支持',
  `job_catalog` varchar(45) DEFAULT 'offline' COMMENT '作业分类：offline(离线作业)，stream(实时流作业)',
  `readonly` smallint(6) DEFAULT '0' COMMENT '是否只读，0否，1是',
  `yarn_queue` varchar(128) DEFAULT NULL,
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  UNIQUE KEY `code_UNIQUE` (`code`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=70 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_workspace
-- ----------------------------
BEGIN;
INSERT INTO `meta_workspace` VALUES (9, 1, '大数据平台', 'bigdata', 'spark_sql,spark_jar,spark_python', '1', 1, '0,1,2,3,4', 365, 1, 'offline', 0, '', '2021-06-22 20:33:25', '2022-01-01 12:38:26', '管理员#admin', '齐观#qiguan');
INSERT INTO `meta_workspace` VALUES (11, 1, '[实时计算]流计算任务', 'stream_bigdata', 'spark_stream_sql,spark_stream_python,spark_stream_jar', '1', 0, '0,1,2,3,4', 365, 1, 'stream', 0, '', '2021-09-10 17:57:11', '2021-09-10 21:41:22', '千潇#qianxiao', '千潇#qianxiao');
INSERT INTO `meta_workspace` VALUES (59, 1, '奥特乐demo', 'aoteledemo', 'spark_sql,spark_jar,spark_python', '1', 1, '0,1,2,3,4', 365, 1, 'offline', 0, '', '2022-08-05 10:17:55', '2022-08-06 13:37:16', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace` VALUES (60, 1, '7OR9demo', '7or9', 'spark_sql,spark_jar,spark_python', '1', 1, '0,1,2,3,4', 365, 1, 'offline', 0, '', '2022-08-11 15:15:57', '2022-09-05 22:17:14', '不玄#buxuan', '怀信#huaixin');
INSERT INTO `meta_workspace` VALUES (62, 1, '[实时计算]安全分析', 'stream_sec', 'spark_stream_sql,spark_stream_jar,spark_stream_python', '1', 0, NULL, 365, 1, 'stream', 0, '', '2022-09-12 16:09:21', '2022-09-12 16:09:21', '阿平#xuanwu', '阿平#xuanwu');
INSERT INTO `meta_workspace` VALUES (63, 1, '安全离线分析', 'sec', 'spark_sql,spark_jar,spark_python', '1', 0, '2', 365, 1, 'offline', 0, '', '2022-09-12 16:09:54', '2022-09-12 16:09:54', '阿平#xuanwu', '阿平#xuanwu');
INSERT INTO `meta_workspace` VALUES (64, 1, '[离线计算]安全分析', 'offline_sec', 'spark_sql,spark_jar,spark_python', '1', 0, '2', 365, 1, 'offline', 0, '', '2022-09-12 16:23:43', '2022-09-12 16:23:43', '阿平#xuanwu', '阿平#xuanwu');
INSERT INTO `meta_workspace` VALUES (69, 1, 'TEST_DW', 'test001', 'spark_sql,spark_jar,spark_python', '1', 0, NULL, 365, 1, 'offline', 0, '', '2022-09-29 17:08:24', '2022-09-29 17:08:24', '不玄#buxuan', '不玄#buxuan');
COMMIT;

-- ----------------------------
-- Table structure for meta_workspace_member
-- ----------------------------
DROP TABLE IF EXISTS `meta_workspace_member`;
CREATE TABLE `meta_workspace_member` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `tenant_id` int(11) DEFAULT NULL COMMENT '租户ID',
  `workspace_id` int(11) NOT NULL,
  `workspace_code` varchar(45) NOT NULL,
  `user_id` varchar(45) DEFAULT NULL,
  `user_name` varchar(45) DEFAULT NULL,
  `role` varchar(45) DEFAULT NULL COMMENT '角色类型：admin、pubilc',
  `gmt_created` datetime DEFAULT NULL,
  `gmt_modified` datetime DEFAULT NULL,
  `creater` varchar(45) DEFAULT NULL,
  `modifier` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  KEY `fk_dc_project_member_dc_project1_idx` (`workspace_id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=87 DEFAULT CHARSET=utf8mb4;

-- ----------------------------
-- Records of meta_workspace_member
-- ----------------------------
BEGIN;
INSERT INTO `meta_workspace_member` VALUES (3, 1, 9, 'bigdata', 'admin', '管理员', 'admin', '2021-06-22 20:35:18', '2021-09-22 19:49:56', '管理员#admin', '管理员#admin');
INSERT INTO `meta_workspace_member` VALUES (7, 1, 9, 'bigdata', 'huaixin', '怀信', 'admin', '2021-07-01 09:09:49', '2021-07-01 09:09:49', '管理员#admin', '管理员#admin');
INSERT INTO `meta_workspace_member` VALUES (39, 1, 11, 'stream_bigdata', 'huaixin', '怀信', 'admin', '2021-11-30 11:27:01', '2021-11-30 11:27:01', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (59, 1, 9, 'bigdata', 'buxuan', '不玄', 'public', '2022-07-27 09:37:33', '2022-07-27 09:37:33', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (61, 1, 9, 'bigdata', 'tankchen', '陈远', 'public', '2022-08-01 15:36:25', '2022-08-01 15:36:25', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (62, 1, 9, 'bigdata', 'zerolin', '林庆贤', 'public', '2022-08-01 15:39:16', '2022-08-01 15:39:16', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (63, 1, 9, 'bigdata', 'wangkai', '王凯', 'public', '2022-08-01 15:41:26', '2022-08-01 15:41:26', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (64, 1, 9, 'bigdata', 'shiyang', '施杨', 'public', '2022-08-01 15:42:36', '2022-08-01 15:42:36', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (65, 1, 59, 'aoteledemo', 'demo', 'demo', 'public', '2022-08-06 13:40:00', '2022-08-06 13:40:00', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (66, 1, 9, 'bigdata', 'fangchusheng', '方楚生', 'public', '2022-08-09 17:47:14', '2022-08-09 17:47:14', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (68, 1, 59, 'aoteledemo', 'buxuan', '不玄', 'admin', '2022-08-10 14:38:02', '2022-08-10 14:38:02', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (69, 1, 59, 'aoteledemo', 'zerolin', '林庆贤', 'admin', '2022-08-10 14:38:33', '2022-08-10 14:38:33', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (70, 1, 59, 'aoteledemo', 'fangchusheng', '方楚生', 'public', '2022-08-10 14:38:51', '2022-08-10 14:38:51', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (71, 1, 59, 'aoteledemo', 'wangkai', '王凯', 'public', '2022-08-10 14:39:07', '2022-08-10 14:39:07', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (72, 1, 59, 'aoteledemo', 'tankchen', '陈远', 'public', '2022-08-10 14:39:14', '2022-08-10 14:39:14', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (73, 1, 60, '7or9', 'buxuan', '不玄', 'admin', '2022-08-11 15:16:17', '2022-08-11 15:16:17', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (74, 1, 60, '7or9', 'zerolin', '林庆贤', 'public', '2022-08-11 15:16:38', '2022-08-11 15:16:38', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (75, 1, 60, '7or9', 'fangchusheng', '方楚生', 'admin', '2022-08-11 15:16:56', '2022-08-11 15:16:56', '不玄#buxuan', '不玄#buxuan');
INSERT INTO `meta_workspace_member` VALUES (76, 1, 9, 'bigdata', 'suzhi', '阿苏', 'public', '2022-08-21 22:36:12', '2022-08-21 22:36:12', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (77, 1, 9, 'bigdata', 'xuanwu', '阿平', 'public', '2022-08-26 10:53:03', '2022-08-26 10:53:03', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (80, 1, 64, 'offline_sec', 'xuanwu', '阿平', 'public', '2022-09-12 19:51:47', '2022-09-12 19:51:47', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (81, 1, 62, 'stream_sec', 'xuanwu', '阿平', 'public', '2022-09-12 19:52:03', '2022-09-12 19:52:03', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (82, 1, 63, 'sec', 'xuanwu', '阿平', 'public', '2022-09-12 19:52:10', '2022-09-12 19:52:10', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (85, 1, 11, 'stream_bigdata', 'xuanwu', '阿平', 'public', '2022-09-12 21:44:05', '2022-09-12 21:44:05', '怀信#huaixin', '怀信#huaixin');
INSERT INTO `meta_workspace_member` VALUES (86, 1, 69, 'test001', 'buxuan', '不玄', 'admin', '2022-09-29 17:09:05', '2022-09-29 17:09:05', '不玄#buxuan', '不玄#buxuan');
COMMIT;

SET FOREIGN_KEY_CHECKS = 1;
